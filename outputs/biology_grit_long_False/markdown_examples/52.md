# Query `52`

*Are two eyes necessary for 3D vision?
It has always been my understanding that humans have two eyes so that we can have 3D vision: the left eye sees more of the left side of an object than the right eye and vice versa. This helps us to estimate depth among other things.
Now when I close one eye, I still am able to perceive depth. I assume this is because my brain fills in the blanks For how long does this work? Do people eventually lose the depth perception (or at least it diminishes significantly) when they lose a single eye?
If so, how low does it take? If not, clearly we are capable of perceiving everything with one eye. Why do we then have two (besides redundancy and a larger field of view)? What is considering the evolution of man better in having two eyes as opposed to one or three, or four,..?*

### Metrics

```
recip_rank: 0.0476
P_1: 0.0000
P_5: 0.0000
P_10: 0.0000
P_25: 0.0400
P_50: 0.0200
P_100: 0.0100
recall_1: 0.0000
recall_5: 0.0000
recall_10: 0.0000
recall_25: 0.3333
recall_50: 0.3333
recall_100: 0.3333
ndcg_cut_1: 0.0000
ndcg_cut_5: 0.0000
ndcg_cut_10: 0.0000
ndcg_cut_25: 0.1052
ndcg_cut_50: 0.1052
ndcg_cut_100: 0.1052
map_cut_1: 0.0000
map_cut_5: 0.0000
map_cut_10: 0.0000
map_cut_25: 0.0159
map_cut_50: 0.0159
map_cut_100: 0.0159
```

## Retrieval Results

### DOC[1] (IRRELEVANT) eye_capture_shape/21823-eyes_9_0.txt
> Most people are born with two eyes. Working together, they give you a field of<br>view about 200 degrees wide and 135 degrees tall. When your eyes work together<br>correctly, they give you depth perception and 3D vision. They also give you<br>color vision.<br><br>It’s also important to remember that sight and vision aren’t necessarily the<br>same thing, even though many people — including eye care specialists and<br>healthcare professionals — use those terms interchangeably. Sight is what your<br>eyes do. Vision is the entire process that starts with sight and ends with

### DOC[2] (IRRELEVANT) two_organs_but_not_all/Humaneye_94_0.txt
> Having two eyes allows the brain to determine the depth and distance of an<br>object, called stereovision, and gives the sense of three-dimensionality to<br>the vision. Both eyes must point accurately enough that the object of regard<br>falls on corresponding points of the two retinas to stimulate stereovision;<br>otherwise, double vision might occur. Some persons with congenitally crossed<br>eyes tend to ignore one eye's vision, thus do not suffer double vision, and do<br>not have stereovision. The movements of the eye are controlled by six muscles<br>attached to each

### DOC[3] (IRRELEVANT) eyes_smooth_transition/Opticalillusion_110_0.txt
> Research indicates that 3D vision capabilities emerge and are learned jointly<br>with the planning of movements.  [41]  That is, as depth cues are better<br>perceived, individuals can develop more efficient patterns of movement and<br>interaction within the 3D environment around them.  [41]  After a long process<br>of learning, an internal representation of the world emerges that is well-<br>adjusted to the perceived data coming from closer objects. The representation<br>of distant objects near the horizon is less "adequate".  [ _[ further<br>explanation needed  ](/

### DOC[4] (IRRELEVANT) 3D_vision/full_47_5.txt
> Would one who<br>underwent surgery that allowed them to gain a previously inexperienced sense<br>of vision be able to “know” what they were seeing? If so, how rapidly and to<br>what level would the ability to use this knowledge, for example, for<br>perceiving three dimensions (3D) vision and geometry, come about? These<br>findings are also interesting for the nature vs. nurture debate concerning<br>visual properties. This debate dates back to the time of John Locke and his<br>acquaintance William Molineux, who pondered in correspondence whether a blind

### DOC[5] (IRRELEVANT) 3D_vision/full_61_0.txt
> ###  3.2. Depth perception with the Brock string task<br><br>If one has binocular depth perception, they will see two lines crossing<br>instead of only one line after some time. The two children with bilateral<br>congenital cataracts removed (RS and HB) had no binocular depth perception.<br>Four of the five children with unilateral trauma-induced cataract removals did<br>have depth perception. IG, who had a congenital cataract in one eye removed,<br>did not have depth perception during the task.


## Ground Truth

### GROUND TRUTH 0, ranked not in top 100, 3D_vision/Binocular_disparity_0.txt
> Binocular disparity refers to the difference in image location of an object seen by the left and right eyes, resulting from the eyes’ horizontal separation (parallax). The mind uses binocular disparity to extract depth information from the two-dimensional retinal images in stereopsis. In computer vision, binocular disparity refers to the difference in coordinates of similar features within two stereo images.<br>A similar disparity can be used in rangefinding by a coincidence rangefinder to determine distance and/or altitude to a target. In astronomy, the disparity between different locations on the Earth can be used to determine various celestial parallax, and Earth's orbit can be used for stellar parallax.

### GROUND TRUTH 1, ranked 20, 3D_vision/Binocular_disparity_2.txt
> Tricking neurons with 2D images[edit]<br>Figure 2. Simulation of disparity from depth in the plane. (relates to Figure 1)<br>Brain cells (neurons) in a part of the brain responsible for processing visual information coming from the retinae (primary visual cortex) can detect the existence of disparity in their input from the eyes. Specifically, these neurons will be active, if an object with "their" special disparity lies within the part of the visual field to which they have access (receptive field).<br>Researchers investigating precise properties of these neurons with respect to disparity present visual stimuli with different disparities to the cells and look whether they are active or not. One possibility to present stimuli with different disparities is to place objects in varying depth in front of the eyes. However, the drawback to this method may not be precise enough for objects placed further away as they possess smaller disparities while objects closer will have greater disparities. Instead, neuroscientists use an alternate method as schematised in Figure 2.<br>Figure 2: The disparity of an object with different depth than the fixation point can alternatively be produced by presenting an image of the object to one eye and a laterally shifted version of the same image to the other eye. The full black circle is the point of fixation. Objects in varying depths are placed along the line of fixation of the left eye. The same disparity produced from a shift in depth of an object (filled coloured circles) can also be produced by laterally shifting the object in constant depth in the picture one eye sees (black circles with coloured margin). Note that for near disparities the lateral shift has to be larger to correspond to the same depth compared with far disparities. This is what neuroscientists usually do with random dot stimuli to study disparity selectivity of neurons since the lateral distance required to test disparities is less than the distances required using depth tests. This principle has also been applied in autostereogram illusions.

### GROUND TRUTH 2, ranked not in top 100, 3D_vision/Binocular_disparity_1.txt
> Definition[edit]<br>Figure 1. Definition of binocular disparity (far and near).<br>Human eyes are horizontally separated by about 50–75 mm (interpupillary distance) depending on each individual. Thus, each eye has a slightly different view of the world around. This can be easily seen when alternately closing one eye while looking at a vertical edge. The binocular disparity can be observed from apparent horizontal shift of the vertical edge between both views.<br>At any given moment, the line of sight of the two eyes meet at a point in space. This point in space projects to the same location (i.e. the center) on the retinae of the two eyes. Because of the different viewpoints observed by the  left and right eye however, many other points in space do not fall on corresponding retinal locations. Visual binocular disparity is defined as the difference between the point of projection in the two  eyes and is usually expressed in degrees as the visual angle.<br>The term "binocular disparity" refers to geometric measurements made external to the eye. The disparity of the images on the actual retina depends on factors internal to the eye, especially the location of the nodal points, even if the cross section of the retina is a perfect circle. Disparity on retina conforms to binocular disparity when measured as degrees, while much different if measured as distance due to the complicated structure inside eye.<br>Figure 1: The full black circle is the point of fixation. The blue object lies nearer to the observer. Therefore, it has a "near" disparity dn. Objects lying more far away (green) correspondingly have a "far" disparity df. Binocular disparity is the angle between two lines of projection . One of which is the real projection from the object to the actual point of projection. The other one is the imaginary projection running through the nodal point of the fixation point.<br>In computer vision, binocular disparity is calculated from stereo images taken from a set of stereo cameras. The variable distance between these cameras, called the baseline, can affect the disparity of a specific point on their respective image plane. As the baseline increases, the disparity increases due to the greater angle needed to align the sight on the point. However, in computer vision, binocular disparity is referenced as coordinate differences of the point between the right and left images instead of a visual angle. The units are usually measured in pixels.
