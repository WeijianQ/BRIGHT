# Query `49`

*How does the brain train its neural network?
One question that came up learning how artificial neural networks are working was how the brain can train its neural network?
When we say we have an artificial neural network, the problem behind it is a typical, but uncommon minimizing problem. The math behind it is logical and pretty easy. But it's math, so an computer can calculate it by doing millions of iterations. But the brain can't do that (I would be surprised)
So, how does the brain solve this task. Trial & Error, we don't know or is there an even more complex system behind it?*

### Metrics

```
recip_rank: 0.0159
P_1: 0.0000
P_5: 0.0000
P_10: 0.0000
P_25: 0.0000
P_50: 0.0000
P_100: 0.0100
recall_1: 0.0000
recall_5: 0.0000
recall_10: 0.0000
recall_25: 0.0000
recall_50: 0.0000
recall_100: 0.5000
ndcg_cut_1: 0.0000
ndcg_cut_5: 0.0000
ndcg_cut_10: 0.0000
ndcg_cut_25: 0.0000
ndcg_cut_50: 0.0000
ndcg_cut_100: 0.1022
map_cut_1: 0.0000
map_cut_5: 0.0000
map_cut_10: 0.0000
map_cut_25: 0.0000
map_cut_50: 0.0000
map_cut_100: 0.0079
```

## Retrieval Results

### DOC[1] (IRRELEVANT) neurons_learn/Neural_network_(machine_learning)_63_0.txt
> ##  Training  [  edit  ]<br><br>Neural networks are typically trained through  empirical risk minimization .<br>This method is based on the idea of optimizing the network's parameters to<br>minimize the difference, or empirical risk, between the predicted output and<br>the actual target values in a given dataset.  [4]  Gradient based methods such<br>as  backpropagation  are usually used to estimate the parameters of the<br>network.  [4]  During the training phase, ANNs learn from  labeled  training<br>data by iteratively updating their

### DOC[2] (IRRELEVANT) brain_train_neural_network/neural-networks-help-us-understand-how-brain-recognizes-numbers_12_0.txt
> It would be premature to conclude, however, that human children learn in<br>exactly the same way that this neural network does. The model is ultimately “a<br>very, very simple approximation of what the brain is doing, even with all its<br>complexity,” Mistry says. That simplicity makes the network easier to study<br>and train, but it also limits how much it can tell us about human biology.<br><br>Nevertheless, the model does an impressive enough job of approximating the<br>number learning process in children that Mistry and Menon have high hopes for<br>its future

### DOC[3] (IRRELEVANT) neurons_learn/Neural_network_(machine_learning)_88_0.txt
> |  This section includes a  list of references ,  related reading , or<br>external links ,  but its sources remain unclear because it lacks  inline<br>citations .  Please help  improve  this section by  introducing  more precise<br>citations.  (  August 2019  )  (  Learn how and when to remove this message  )  <br>---|---  <br>  <br>See also:  Mathematical optimization ,  Estimation theory , and  Machine<br>learning<br><br>Learning is the adaptation of the network to better

### DOC[4] (IRRELEVANT) neurons_learn/Neural_network_(machine_learning)_67_0.txt
> Warren McCulloch  and  Walter Pitts  [12]  (1943) also considered a non-<br>learning computational model for neural networks.  [13]<br><br>In the late 1940s,  D. O. Hebb  [14]  created a learning  hypothesis  based on<br>the mechanism of  neural plasticity  that became known as  Hebbian learning .<br>Hebbian learning is considered to be a 'typical'  unsupervised learning  rule<br>and its later variants were early models for  long term potentiation .

### DOC[5] (IRRELEVANT) neurons_learn/Neural_network_(machine_learning)_126_0.txt
> ###  Training  [  edit  ]<br><br>A common criticism of neural networks, particularly in robotics, is that they<br>require too many training samples for real-world operation.  [221]  Any<br>learning machine needs sufficient representative examples in order to capture<br>the underlying structure that allows it to generalize to new cases. Potential<br>solutions include randomly shuffling training examples, by using a numerical<br>optimization algorithm that does not take too large steps when changing the<br>network connections following an example, grouping examples in so-called mini-<br>batches and/or introducing a


## Ground Truth

### GROUND TRUTH 0, ranked 61, brain_train_neural_network/Hebbian_theory_0.txt
> Hebbian theory is a neuropsychological theory claiming that an increase in synaptic efficacy arises from a presynaptic cell's repeated and persistent stimulation of a postsynaptic cell. It is an attempt to explain synaptic plasticity, the adaptation of brain neurons during the learning process. It was introduced by Donald Hebb in his 1949 book The Organization of Behavior. The theory is also called Hebb's rule, Hebb's postulate, and cell assembly theory. Hebb states it as follows:<br>The theory is often summarized as "Cells that fire together wire together." However, Hebb emphasized that cell A needs to "take part in firing" cell B, and such causality can occur only if cell A fires just before, not at the same time as, cell B. This aspect of causation in Hebb's work foreshadowed what is now known about spike-timing-dependent plasticity, which requires temporal precedence.<br>The theory attempts to explain associative or Hebbian learning, in which simultaneous activation of cells leads to pronounced increases in synaptic strength between those cells. It also provides a biological basis for errorless learning methods for education and memory rehabilitation. In the study of neural networks in cognitive function, it is often regarded as the neuronal basis of unsupervised learning.

### GROUND TRUTH 1, ranked not in top 100, brain_train_neural_network/Hebbian_theory_1.txt
> Hebbian engrams and cell assembly theory[edit]<br>Hebbian theory concerns how neurons might connect themselves to become engrams. Hebb's theories on the form and function of cell assemblies can be understood from the following:<br>The general idea is an old one, that any two cells or systems of cells that are repeatedly active at the same time will tend to become 'associated' so that activity in one facilitates activity in the other.<br>Hebb also wrote:<br>When one cell repeatedly assists in firing another, the axon of the first cell develops synaptic knobs (or enlarges them if they already exist) in contact with the soma of the second cell.<br>[D. Alan Allport] posits additional ideas regarding cell assembly theory and its role in forming engrams, along the lines of the concept of auto-association, described as follows:<br>If the inputs to a system cause the same pattern of activity to occur repeatedly, the set of active elements constituting that pattern will become increasingly strongly inter-associated. That is, each element will tend to turn on every other element and (with negative weights) to turn off the elements that do not form part of the pattern. To put it another way, the pattern as a whole will become 'auto-associated'.  We may call a learned (auto-associated) pattern an engram.<br>Work in the laboratory of Eric Kandel has provided evidence for the involvement of Hebbian learning mechanisms at synapses in the marine gastropod Aplysia californica. Experiments on Hebbian synapse modification mechanisms at the central nervous system synapses of vertebrates are much more difficult to control than are experiments with the relatively simple peripheral nervous system synapses studied in marine invertebrates. Much of the work on long-lasting synaptic changes between vertebrate neurons (such as long-term potentiation) involves the use of non-physiological experimental stimulation of brain cells. However, some of the physiologically relevant synapse modification mechanisms that have been studied in vertebrate brains do seem to be examples of Hebbian processes. One such study reviews results from experiments that indicate that long-lasting changes in synaptic strengths can be induced by physiologically relevant synaptic activity working through both Hebbian and non-Hebbian mechanisms.
