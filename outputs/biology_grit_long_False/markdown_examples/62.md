# Query `62`

*How does a neuron change as you learn?
I am currently taking a course called "Introduction to Machine Learning with ENCOG 3", and I have a question about how well the Artificial Intelligence (AI) algorithm for a "neural network" corresponds with how an actual neuron works.
In the course, they model a neuron like this: AI implementation of a neuron's algorithm
x1, x2, etc. are voltage inputs, the wij are weights. The inputs are multiplied by these weights and summed up by the neuron. The neuron then has an "activation function" which then takes the sum of weighted inputs and calculates an output, typically a value between 0 and 1 (or between -1 and 1). You can think of the wij as representing dendrites (a higher weight means a more dense and thus conductive dendrite), and the output of the activation function as the voltage that gets sent down an axon.
The AI neural network algorithm creates a kind of intelligence by modifying the weights (wij shown in the picture).
My first questions is: Is this a good approximation as to how neurons actually work? That is, do our neurons "learn" by changing the weights (dendrite density, conductivity)? Or, is there some other mechanism that is more important (e.g. do neurons learn by changing their activation or summation functions?)
My second question is: If neurons really do learn by changing the density of dendrites, then how fast does this happen? Is this a fast process like DNA replication? Does the neuron quickly generate (or decrease) dendrite density when it receives some kind of biochemical signal that it needs to learn now?
I understand that much of this might not yet be known, but would like to know how well the AI algorithm corresponds with current theories on biological neural networks.*

### Metrics

```
recip_rank: 0.1000
P_1: 0.0000
P_5: 0.0000
P_10: 0.1000
P_25: 0.0800
P_50: 0.0400
P_100: 0.0300
recall_1: 0.0000
recall_5: 0.0000
recall_10: 0.3333
recall_25: 0.6667
recall_50: 0.6667
recall_100: 1.0000
ndcg_cut_1: 0.0000
ndcg_cut_5: 0.0000
ndcg_cut_10: 0.1357
ndcg_cut_25: 0.2666
ndcg_cut_50: 0.2666
ndcg_cut_100: 0.3406
map_cut_1: 0.0000
map_cut_5: 0.0000
map_cut_10: 0.0333
map_cut_25: 0.0939
map_cut_50: 0.0939
map_cut_100: 0.1064
```

## Retrieval Results

### DOC[1] (IRRELEVANT) neuron_onto/thesynapse_166_0.txt
> Functionally related neurons connect to form neural networks (also known as<br>neural nets or assemblies). The connections between neurons are not static,<br>though, they change over time. The more signals sent between two neurons, the<br>stronger the connection grows.

### DOC[2] (IRRELEVANT) neurons_learn/Neural_network_(machine_learning)_61_1.txt
> brain. Each artificial neuron receives signals<br>from connected neurons, then processes them and sends a signal to other<br>connected neurons. The "signal" is a  real number , and the output of each<br>neuron is computed by some non-linear function of the sum of its inputs,<br>called the  activation function . The strength of the signal at each<br>connection is determined by a  weight , which adjusts during the learning<br>process.

### DOC[3] (IRRELEVANT) neurons_form_connections/explainernaturenurtu_8_0.txt
> Get facts about the coronavirus pandemic and the latest research<br>Changes occur in brain wiring, modifying the strength of connections between neurons. This form of neuroplasticity can involve adding or removing new synapses. If you remember anything you’ve read in this article, then you may have stored that new information in your brain via the formation of new connections between specific subsets of neurons.

### DOC[4] (IRRELEVANT) brain_train_neural_network/Hebbian_theory_3_3.txt
> =f\left(\sum _{i=1}^{N}w_{i}x_{i}\right).}<br>As defined in the previous sections, Hebbian plasticity describes the evolution in time of the synaptic weight <br><br><br><br>w<br><br><br>{\displaystyle w}<br><br>:<br>d<br><br>w<br><br>i<br><br><br><br><br>d<br>t<br><br><br><br>=<br>η<br><br>x<br><br>i<br><br><br>y<br>.<br><br><br>{\displaystyle {\frac {dw_{i}}{dt}}=\eta x_{i}y.}

### DOC[5] (IRRELEVANT) neurons_learn/Hebbian_theory_3_3.txt
> =f\left(\sum _{i=1}^{N}w_{i}x_{i}\right).}<br>As defined in the previous sections, Hebbian plasticity describes the evolution in time of the synaptic weight <br><br><br><br>w<br><br><br>{\displaystyle w}<br><br>:<br>d<br><br>w<br><br>i<br><br><br><br><br>d<br>t<br><br><br><br>=<br>η<br><br>x<br><br>i<br><br><br>y<br>.<br><br><br>{\displaystyle {\frac {dw_{i}}{dt}}=\eta x_{i}y.}


## Ground Truth

### GROUND TRUTH 0, ranked 11, neurons_learn/Hebbian_theory_1.txt
> Hebbian engrams and cell assembly theory[edit]<br>Hebbian theory concerns how neurons might connect themselves to become engrams. Hebb's theories on the form and function of cell assemblies can be understood from the following:<br>The general idea is an old one, that any two cells or systems of cells that are repeatedly active at the same time will tend to become 'associated' so that activity in one facilitates activity in the other.<br>Hebb also wrote:<br>When one cell repeatedly assists in firing another, the axon of the first cell develops synaptic knobs (or enlarges them if they already exist) in contact with the soma of the second cell.<br>[D. Alan Allport] posits additional ideas regarding cell assembly theory and its role in forming engrams, along the lines of the concept of auto-association, described as follows:<br>If the inputs to a system cause the same pattern of activity to occur repeatedly, the set of active elements constituting that pattern will become increasingly strongly inter-associated. That is, each element will tend to turn on every other element and (with negative weights) to turn off the elements that do not form part of the pattern. To put it another way, the pattern as a whole will become 'auto-associated'.  We may call a learned (auto-associated) pattern an engram.<br>Work in the laboratory of Eric Kandel has provided evidence for the involvement of Hebbian learning mechanisms at synapses in the marine gastropod Aplysia californica. Experiments on Hebbian synapse modification mechanisms at the central nervous system synapses of vertebrates are much more difficult to control than are experiments with the relatively simple peripheral nervous system synapses studied in marine invertebrates. Much of the work on long-lasting synaptic changes between vertebrate neurons (such as long-term potentiation) involves the use of non-physiological experimental stimulation of brain cells. However, some of the physiologically relevant synapse modification mechanisms that have been studied in vertebrate brains do seem to be examples of Hebbian processes. One such study reviews results from experiments that indicate that long-lasting changes in synaptic strengths can be induced by physiologically relevant synaptic activity working through both Hebbian and non-Hebbian mechanisms.

### GROUND TRUTH 1, ranked 9, neurons_learn/Hebbian_theory_2.txt
> Principles[edit]<br>From the point of view of artificial neurons and artificial neural networks, Hebb's principle can be described as a method of determining how to alter the weights between model neurons. The weight between two neurons increases if the two neurons activate simultaneously, and reduces if they activate separately. Nodes that tend to be either both positive or both negative at the same time have strong positive weights, while those that tend to be opposite have strong negative weights.<br>The following is a formulaic description of Hebbian learning: (many other descriptions are possible)<br>w<br><br>i<br>j<br><br><br>=<br><br>x<br><br>i<br><br><br><br>x<br><br>j<br><br><br><br><br>{\displaystyle \,w_{ij}=x_{i}x_{j}}<br>where <br><br><br><br><br>w<br><br>i<br>j<br><br><br><br><br>{\displaystyle w_{ij}}<br><br> is the weight of the connection from neuron <br><br><br><br>j<br><br><br>{\displaystyle j}<br><br> to neuron <br><br><br><br>i<br><br><br>{\displaystyle i}<br><br> and <br><br><br><br><br>x<br><br>i<br><br><br><br><br>{\displaystyle x_{i}}<br><br> the input for neuron <br><br><br><br>i<br><br><br>{\displaystyle i}<br><br>. Note that this is pattern learning (weights updated after every training example). In a Hopfield network, connections <br><br><br><br><br>w<br><br>i<br>j<br><br><br><br><br>{\displaystyle w_{ij}}<br><br> are set to zero if <br><br><br><br>i<br>=<br>j<br><br><br>{\displaystyle i=j}<br><br> (no reflexive connections allowed). With binary neurons (activations either 0 or 1), connections would be set to 1 if the connected neurons have the same activation for a pattern.<br>When several training patterns are used the expression becomes an average of individual ones:<br>w<br><br>i<br>j<br><br><br>=<br><br><br>1<br>p<br><br><br><br>∑<br><br>k<br>=<br>1<br><br><br>p<br><br><br><br>x<br><br>i<br><br><br>k<br><br><br><br>x<br><br>j<br><br><br>k<br><br><br><br><br>{\displaystyle w_{ij}={\frac {1}{p}}\sum _{k=1}^{p}x_{i}^{k}x_{j}^{k}}<br>where <br><br><br><br><br>w<br><br>i<br>j<br><br><br><br><br>{\displaystyle w_{ij}}<br><br> is the weight of the connection from neuron <br><br><br><br>j<br><br><br>{\displaystyle j}<br><br> to neuron <br><br><br><br>i<br><br><br>{\displaystyle i}<br><br>, <br><br><br><br>p<br><br><br>{\displaystyle p}<br><br> is the number of training patterns and <br><br><br><br><br>x<br><br>i<br><br><br>k<br><br><br><br><br>{\displaystyle x_{i}^{k}}<br><br> the <br><br><br><br>k<br><br><br>{\displaystyle k}<br><br>-th input for neuron <br><br><br><br>i<br><br><br>{\displaystyle i}<br><br>. This is learning by epoch (weights updated after all the training examples are presented), being last term applicable to both discrete and continuous training sets. Again, in a Hopfield network, connections <br><br><br><br><br>w<br><br>i<br>j<br><br><br><br><br>{\displaystyle w_{ij}}<br><br> are set to zero if <br><br><br><br>i<br>=<br>j<br><br><br>{\displaystyle i=j}<br><br> (no reflexive connections).<br>A variation of Hebbian learning that takes into account phenomena such as blocking and many other neural learning phenomena is the mathematical model of Harry Klopf. Klopf's model reproduces a great many biological phenomena, and is also simple to implement.

### GROUND TRUTH 2, ranked 80, neurons_learn/Hebbian_theory_0.txt
> Hebbian theory is a neuropsychological theory claiming that an increase in synaptic efficacy arises from a presynaptic cell's repeated and persistent stimulation of a postsynaptic cell. It is an attempt to explain synaptic plasticity, the adaptation of brain neurons during the learning process. It was introduced by Donald Hebb in his 1949 book The Organization of Behavior. The theory is also called Hebb's rule, Hebb's postulate, and cell assembly theory. Hebb states it as follows:<br>The theory is often summarized as "Cells that fire together wire together." However, Hebb emphasized that cell A needs to "take part in firing" cell B, and such causality can occur only if cell A fires just before, not at the same time as, cell B. This aspect of causation in Hebb's work foreshadowed what is now known about spike-timing-dependent plasticity, which requires temporal precedence.<br>The theory attempts to explain associative or Hebbian learning, in which simultaneous activation of cells leads to pronounced increases in synaptic strength between those cells. It also provides a biological basis for errorless learning methods for education and memory rehabilitation. In the study of neural networks in cognitive function, it is often regarded as the neuronal basis of unsupervised learning.
