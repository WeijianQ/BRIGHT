# Query `36`

## Original Question

*Given an array of integers `temperatures` represents the daily temperatures, return _an array_ `answer` _such that_ `answer[i]` _is the number of days you have to wait after the_ `ith` _day to get a warmer temperature_. If there is no future day for which this is possible, keep `answer[i] == 0` instead.

Example 1:

Input: temperatures = \[73,74,75,71,69,72,76,73\]
Output: \[1,1,4,2,1,1,0,0\]

Example 2:

Input: temperatures = \[30,40,50,60\]
Output: \[1,1,1,0\]

Example 3:

Input: temperatures = \[30,60,90\]
Output: \[1,1,0\]

Constraints:

   `1 <= temperatures.length <= 105`
   `30 <= temperatures[i] <= 100`*

## gpt4 Reasoning

```markdown
The essential problem here is to find, for each day represented in the input array `temperatures`, how many days one must wait until experiencing a warmer day. If no such warmer day exists after the current day, the output should be `0` for that day.

### Approach to Solve the Problem:

1. **Initialization**: We start by understanding that we need to traverse through the array to compare the temperature of each day with the temperatures of the subsequent days. Therefore, we initialize an array `answer` of the same length as `temperatures` with all elements set to `0`, since that's the default value for days when a warmer day does not follow.

2. **Traverse the Array**: The main part of the solution involves iterating through the `temperatures` array. For each day (temperature), we need to find the next day with a higher temperature. This requires a nested iteration for each element, where we compare the current day's temperature with the temperatures of the following days.

3. **Find the Warmer Day**: For each day, starting from the current index, we look ahead to find a day with a higher temperature. Once found, we calculate the difference in indices (which represents the number of days waited) and update the corresponding index in the `answer` array with this value.

4. **Optimization with a Monotonic Stack**: A brute force approach using nested loops can lead to a time complexity of O(n^2), which might not be efficient for large arrays. To optimize, we can use a stack to keep track of the indices of the days for which we are yet to find a warmer day. This stack should maintain a decreasing order of temperatures (monotonic stack). When we encounter a day with a temperature higher than that of the top of the stack, it means we have found a warmer day for the day at the top of the stack. We then pop from the stack, calculate the number of days waited, and update the `answer` array accordingly. We repeat this until the stack is empty or the current day's temperature is not warmer than that on the top of the stack, then push the current day's index onto the stack.

### Steps in Detail with Monotonic Stack:

- Initialize an empty stack and the `answer` array with zeros.
- Iterate through the `temperatures` array with the index `i`.
- While the stack is not empty and the current day's temperature is higher than the temperature of the day at the index on the top of the stack:
  - Pop the top index from the stack.
  - Calculate the difference between the current index `i` and the popped index to find the number of days waited.
  - Update the `answer` array at the popped index with this difference.
- Push the current index `i` onto the stack.
- Continue this process until we have gone through the entire `temperatures` array.

By the end of the iteration, the `answer` array will be filled with the number of days each day has to wait for a warmer temperature, or `0` if no such day exists. This approach significantly reduces the time complexity to O(n), where n is the length of the `temperatures` array, since each element is pushed and popped from the stack exactly once.
```

### Metrics

```
recip_rank: 0.0714
P_1: 0.0000
P_5: 0.0000
P_10: 0.0000
P_25: 0.0400
P_50: 0.0200
P_100: 0.0100
recall_1: 0.0000
recall_5: 0.0000
recall_10: 0.0000
recall_25: 1.0000
recall_50: 1.0000
recall_100: 1.0000
ndcg_cut_1: 0.0000
ndcg_cut_5: 0.0000
ndcg_cut_10: 0.0000
ndcg_cut_25: 0.2560
ndcg_cut_50: 0.2560
ndcg_cut_100: 0.2560
map_cut_1: 0.0000
map_cut_5: 0.0000
map_cut_10: 0.0000
map_cut_25: 0.0714
map_cut_50: 0.0714
map_cut_100: 0.0714
```

## Retrieval Results

### DOC[1] (IRRELEVANT) leetcode/csn_python_train_197146.txt
> def parse_AMR_line(line):<br>        """<br>        Parse a AMR from line representation to an AMR object.<br>        This parsing algorithm scans the line once and process each character, in a shift-reduce style.<br><br>        """<br>        # Current state. It denotes the last significant symbol encountered. 1 for (, 2 for :, 3 for /,<br>        # and 0 for start state or ')'<br>        # Last significant symbol is ( --- start processing node name<br>        # Last significant symbol is : --- start processing relation name<br>        # Last significant symbol is / --- start processing node value (concept name)<br>        # Last significant symbol is ) --- current node processing is complete<br>        # Note that if these symbols are inside parenthesis, they are not significant symbols.<br>        state = 0<br>        # node stack for parsing<br>        stack = []<br>        # current not-yet-reduced character sequence<br>        cur_charseq = []<br>        # key: node name value: node value<br>        node_dict = {}<br>        # node name list (order: occurrence of the node)<br>        node_name_list = []<br>        # key: node name:  value: list of (relation name, the other node name)<br>        node_relation_dict1 = defaultdict(list)<br>        # key: node name, value: list of (attribute name, const value) or (relation name, unseen node name)<br>        node_relation_dict2 = defaultdict(list)<br>        # current relation name<br>        cur_relation_name = ""<br>        # having unmatched quote string<br>        in_quote = False<br>        for i, c in enumerate(line.strip()):<br>            if c == " ":<br>                # allow space in relation name<br>                if state == 2:<br>                    cur_charseq.append(c)<br>                continue<br>            if c == "\"":<br>                # flip in_quote value when a quote symbol is encountered<br>                # insert placeholder if in_quote from last symbol<br>                if in_quote:<br>                    cur_charseq.append('_')<br>                in_quote = not in_quote<br>            elif c == "(":<br>                # not significant symbol if inside quote<br>                if in_quote:<br>                    cur_charseq.append(c)<br>                    continue<br>                # get the attribute name<br>                # e.g :arg0 (x ...<br>                # at this point we get "arg0"<br>                if state == 2:<br>                    # in this state, current relation name should be empty<br>                    if cur_relation_name != "":<br>                        print("Format error when processing ", line[0:i + 1], file=ERROR_LOG)<br>                        return None<br>                    # update current relation name for future use<br>                    cur_relation_name = "".join(cur_charseq).strip()<br>                    cur_charseq[:] = []<br>                state = 1<br>            elif c == ":":<br>                # not significant symbol if inside quote<br>                if in_quote:<br>                    cur_charseq.append(c)<br>                    continue<br>                # Last significant symbol is "/". Now we encounter ":"<br>                # Example:<br>                # :OR (o2 / OR<br>                #    :mod (o3 / official)<br>                #  gets node value "OR" at this point<br>                if state == 3:<br>                    node_value = "".join(cur_charseq)<br>                    # clear current char sequence<br>                    cur_charseq[:] = []<br>                    # pop node name ("o2" in the above example)<br>                    cur_node_name = stack[-1]<br>                    # update node name/value map<br>                    node_dict[cur_node_name] = node_value<br>                # Last significant symbol is ":". Now we encounter ":"<br>                # Example:<br>                # :op1 w :quant 30<br>                # or :day 14 :month 3<br>                # the problem is that we cannot decide if node value is attribute value (constant)<br>                # or node value (variable) at this moment<br>                elif state == 2:<br>                    temp_attr_value = "".join(cur_charseq)<br>                    cur_charseq[:] = []<br>                    parts = temp_attr_value.split()<br>                    if len(parts) < 2:<br>                        print("Error in processing; part len < 2", line[0:i + 1], file=ERROR_LOG)<br>                        return None<br>                    # For the above example, node name is "op1", and node value is "w"<br>                    # Note that this node name might not be encountered before<br>                    relation_name = parts[0].strip()<br>                    relation_value = parts[1].strip()<br>                    # We need to link upper level node to the current<br>                    # top of stack is upper level node<br>                    if len(stack) == 0:<br>                        print("Error in processing", line[:i], relation_name, relation_value, file=ERROR_LOG)<br>                        return None<br>                    # if we have not seen this node name before<br>                    if relation_value not in node_dict:<br>                        node_relation_dict2[stack[-1]].append((relation_name, relation_value))<br>                    else:<br>                        node_relation_dict1[stack[-1]].append((relation_name, relation_value))<br>                state = 2<br>            elif c == "/":<br>                if in_quote:<br>                    cur_charseq.append(c)<br>                    continue<br>                # Last significant symbol is "(". Now we encounter "/"<br>                # Example:<br>                # (d / default-01<br>                # get "d" here<br>                if state == 1:<br>                    node_name = "".join(cur_charseq)<br>                    cur_charseq[:] = []<br>                    # if this node name is already in node_dict, it is duplicate<br>                    if node_name in node_dict:<br>                        print("Duplicate node name ", node_name, " in parsing AMR", file=ERROR_LOG)<br>                        return None<br>                    # push the node name to stack<br>                    stack.append(node_name)<br>                    # add it to node name list<br>                    node_name_list.append(node_name)<br>                    # if this node is part of the relation<br>                    # Example:<br>                    # :arg1 (n / nation)<br>                    # cur_relation_name is arg1<br>                    # node name is n<br>                    # we have a relation arg1(upper level node, n)<br>                    if cur_relation_name != "":<br>                        # if relation name ends with "-of", e.g."arg0-of",<br>                        # it is reverse of some relation. For example, if a is "arg0-of" b,<br>                        # we can also say b is "arg0" a.<br>                        # If the relation name ends with "-of", we store the reverse relation.<br>                        if not cur_relation_name.endswith("-of"):<br>                            # stack[-2] is upper_level node we encountered, as we just add node_name to stack<br>                            node_relation_dict1[stack[-2]].append((cur_relation_name, node_name))<br>                        else:<br>                            # cur_relation_name[:-3] is to delete "-of"<br>                            node_relation_dict1[node_name].append((cur_relation_name[:-3], stack[-2]))<br>                        # clear current_relation_name<br>                        cur_relation_name = ""<br>                else:<br>                    # error if in other state<br>                    print("Error in parsing AMR", line[0:i + 1], file=ERROR_LOG)<br>                    return None<br>                state = 3<br>            elif c == ")":<br>                if in_quote:<br>                    cur_charseq.append(c)<br>                    continue<br>                # stack should be non-empty to find upper level node<br>                if len(stack) == 0:<br>                    print("Unmatched parenthesis at position", i, "in processing", line[0:i + 1], file=ERROR_LOG)<br>                    return None<br>                # Last significant symbol is ":". Now we encounter ")"<br>                # Example:<br>                # :op2 "Brown") or :op2 w)<br>                # get \"Brown\" or w here<br>                if state == 2:<br>                    temp_attr_value = "".join(cur_charseq)<br>                    cur_charseq[:] = []<br>                    parts = temp_attr_value.split()<br>                    if len(parts) < 2:<br>                        print("Error processing", line[:i + 1], temp_attr_value, file=ERROR_LOG)<br>                        return None<br>                    relation_name = parts[0].strip()<br>                    relation_value = parts[1].strip()<br>                    # store reverse of the relation<br>                    # we are sure relation_value is a node here, as "-of" relation is only between two nodes<br>                    if relation_name.endswith("-of"):<br>                        node_relation_dict1[relation_value].append((relation_name[:-3], stack[-1]))<br>                    # attribute value not seen before<br>                    # Note that it might be a constant attribute value, or an unseen node<br>                    # process this after we have seen all the node names<br>                    elif relation_value not in node_dict:<br>                        node_relation_dict2[stack[-1]].append((relation_name, relation_value))<br>                    else:<br>                        node_relation_dict1[stack[-1]].append((relation_name, relation_value))<br>                # Last significant symbol is "/". Now we encounter ")"<br>                # Example:<br>                # :arg1 (n / nation)<br>                # we get "nation" here<br>                elif state == 3:<br>                    node_value = "".join(cur_charseq)<br>                    cur_charseq[:] = []<br>                    cur_node_name = stack[-1]<br>                    # map node name to its value<br>                    node_dict[cur_node_name] = node_value<br>                # pop from stack, as the current node has been processed<br>                stack.pop()<br>                cur_relation_name = ""<br>                state = 0<br>            else:<br>                # not significant symbols, so we just shift.<br>                cur_charseq.append(c)<br>        #create data structures to initialize an AMR<br>        node_value_list = []<br>        relation_list = []<br>        attribute_list = []<br>        for v in node_name_list:<br>            if v not in node_dict:<br>                print("Error: Node name not found", v, file=ERROR_LOG)<br>                return None<br>            else:<br>                node_value_list.append(node_dict[v])<br>            # build relation list and attribute list for this node<br>            node_rel_list = []<br>            node_attr_list = []<br>            if v in node_relation_dict1:<br>                for v1 in node_relation_dict1[v]:<br>                    node_rel_list.append([v1[0], v1[1]])<br>            if v in node_relation_dict2:<br>                for v2 in node_relation_dict2[v]:<br>                    # if value is in quote, it is a constant value<br>                    # strip the quote and put it in attribute map<br>                    if v2[1][0] == "\"" and v2[1][-1] == "\"":<br>                        node_attr_list.append([[v2[0]], v2[1][1:-1]])<br>                    # if value is a node name<br>                    elif v2[1] in node_dict:<br>                        node_rel_list.append([v2[0], v2[1]])<br>                    else:<br>                        node_attr_list.append([v2[0], v2[1]])<br>            # each node has a relation list and attribute list<br>            relation_list.append(node_rel_list)<br>            attribute_list.append(node_attr_list)<br>        # add TOP as an attribute. The attribute value is the top node value<br>        attribute_list[0].append(["TOP", node_value_list[0]])<br>        result_amr = AMR(node_name_list, node_value_list, relation_list, attribute_list)<br>        return result_amr

### DOC[2] (IRRELEVANT) leetcode/csn_python_train_144360.txt
> def place(vertices_resources, nets, machine, constraints,<br>          effort=1.0, random=default_random, on_temperature_change=None,<br>          kernel=default_kernel, kernel_kwargs={}):<br>    """A flat Simulated Annealing based placement algorithm.<br><br>    This placement algorithm uses simulated annealing directly on the supplied<br>    problem graph with the objective of reducing wire lengths (and thus,<br>    indirectly, the potential for congestion). Though computationally<br>    expensive, this placer produces relatively good placement solutions.<br><br>    The annealing temperature schedule used by this algorithm is taken from<br>    "VPR: A New Packing, Placement and Routing Tool for FPGA Research" by<br>    Vaughn Betz and Jonathan Rose from the "1997 International Workshop on<br>    Field Programmable Logic and Applications".<br><br>    Two implementations of the algorithm's kernel are available:<br><br>     :py:class:`~rig.place_and_route.place.sa.python_kernel.PythonKernel` A<br>      pure Python implementation which is available on all platforms supported<br>      by Rig.<br>     :py:class:`~rig.place_and_route.place.sa.c_kernel.CKernel` A C<br>      implementation which is typically 50-150x faster than the basic Python<br>      kernel. Since this implementation requires a C compiler during<br>      installation, it is an optional feature of Rig. See the<br>      :py:class:`CKernel's documentation<br>      <rig.place_and_route.place.sa.c_kernel.CKernel` for details.<br><br>    The fastest kernel installed is used by default and can be manually chosen<br>    using the ``kernel`` argument.<br><br>    This algorithm produces INFO level logging information describing the<br>    progress made by the algorithm.<br><br>    .. warning:<br>        This algorithm does not attempt to produce good solutions to the<br>        bin-packing problem of optimally fitting vertices into chips and it may<br>        fail if a good placement requires good bin packing.<br><br>    Parameters<br>    ----------<br>    effort : float<br>        A scaling factor for the number of iterations the algorithm should run<br>        for. 1.0 is probably about as low as you'll want to go in practice and<br>        runtime increases linearly as you increase this parameter.<br>    random : :py:class:`random.Random`<br>        A Python random number generator. Defaults to ``import random`` but can<br>        be set to your own instance of :py:class:`random.Random` to allow you<br>        to control the seed and produce deterministic results. For results to<br>        be deterministic, vertices_resources must be supplied as an<br>        :py:class:`collections.OrderedDict`.<br>    on_temperature_change : callback_function or None<br>        An (optional) callback function which is called every time the<br>        temperature is changed. This callback can be used to provide status<br>        updates<br><br>        The callback function is passed the following arguments:<br><br>         ``iteration_count``: the number of iterations the placer has<br>          attempted (integer)<br>         ``placements``: The current placement solution.<br>         ``cost``: the weighted sum over all nets of bounding-box size.<br>          (float)<br>         ``acceptance_rate``: the proportion of iterations which have resulted<br>          in an accepted change since the last callback call. (float between<br>          0.0 and 1.0)<br>         ``temperature``: The current annealing temperature. (float)<br>         ``distance_limit``: The maximum distance any swap may be made over.<br>          (integer)<br><br>        If the callback returns False, the anneal is terminated immediately and<br>        the current solution is returned.<br>    kernel : :py:class:`~rig.place_and_route.place.sa.kernel.Kernel`<br>        A simulated annealing placement kernel. A sensible default will be<br>        chosen based on the available kernels on this machine. The kernel may<br>        not be used if the placement problem has a trivial solution.<br>    kernel_kwargs : dict<br>        Optional kernel-specific keyword arguments to pass to the kernel<br>        constructor.<br>    """<br>    # Special case: just return immediately when there's nothing to place<br>    if len(vertices_resources) == 0:<br>        return {}<br><br>    # Within the algorithm we modify the resource availability values in the<br>    # machine to account for the effects of the current placement. As a result,<br>    # an internal copy of the structure must be made.<br>    machine = machine.copy()<br><br>    # {vertex: (x, y), ...} gives the location of all vertices whose position<br>    # is fixed by a LocationConstraint.<br>    fixed_vertices = {}<br><br>    # Handle constraints<br>    vertices_resources, nets, constraints, substitutions = \<br>        apply_same_chip_constraints(vertices_resources, nets, constraints)<br>    for constraint in constraints:<br>        if isinstance(constraint, LocationConstraint):<br>            # Location constraints are handled by recording the set of fixed<br>            # vertex locations and subtracting their resources from the chips<br>            # they're allocated to. These vertices will then not be added to<br>            # the internal placement data structure to prevent annealing from<br>            # moving them. They will be re-introduced at the last possible<br>            # moment.<br>            location = constraint.location<br>            if location not in machine:<br>                raise InvalidConstraintError(<br>                    "Chip requested by {} unavailable".format(machine))<br>            vertex = constraint.vertex<br><br>            # Record the constrained vertex's location<br>            fixed_vertices[vertex] = location<br><br>            # Make sure the vertex fits at the requested location (updating the<br>            # resource availability after placement)<br>            resources = vertices_resources[vertex]<br>            machine[location] = subtract_resources(machine[location],<br>                                                   resources)<br>            if overallocated(machine[location]):<br>                raise InsufficientResourceError(<br>                    "Cannot meet {}".format(constraint))<br>        elif isinstance(constraint,  # pragma: no branch<br>                        ReserveResourceConstraint):<br>            apply_reserve_resource_constraint(machine, constraint)<br><br>    # Initially randomly place the movable vertices<br>    movable_vertices = {v for v in vertices_resources<br>                        if v not in fixed_vertices}<br>    initial_placements = _initial_placement(movable_vertices,<br>                                            vertices_resources,<br>                                            machine, random)<br><br>    # Include the fixed vertices in initial placement<br>    initial_placements.update(fixed_vertices)<br><br>    # Filter out empty or singleton nets and those weighted as zero since they<br>    # cannot influence placement.<br>    nets = [n for n in nets if len(set(n))  1 and n.weight  0.0]<br><br>    # Special cases where no placement effort is required:<br>    #  There is only one chip<br>    #  There are no resource types to be consumed<br>    #  No effort is to be made<br>    #  No movable vertices<br>    #  There are no nets (and moving things has no effect)<br>    trivial = ((machine.width, machine.height) == (1, 1) or<br>               len(machine.chip_resources) == 0 or<br>               effort == 0.0 or<br>               len(movable_vertices) == 0 or<br>               len(nets) == 0)<br>    if trivial:<br>        logger.info("Placement has trivial solution. SA not used.")<br>        finalise_same_chip_constraints(substitutions, initial_placements)<br>        return initial_placements<br><br>    # Intialise the algorithm kernel<br>    k = kernel(vertices_resources, movable_vertices, set(fixed_vertices),<br>               initial_placements, nets, machine, random, kernel_kwargs)<br><br>    logger.info("SA placement kernel: %s", kernel.__name__)<br><br>    # Specifies the maximum distance any swap can span. Initially consider<br>    # swaps that span the entire machine.<br>    distance_limit = max(machine.width, machine.height)<br><br>    # Determine initial temperature according to the heuristic used by VPR: 20<br>    # times the standard deviation of len(movable_vertices) random swap costs.<br>    # The arbitrary very-high temperature is used to cause "all" swaps to be<br>    # accepted.<br>    _0, _1, cost_delta_sd = k.run_steps(len(movable_vertices),<br>                                        distance_limit,<br>                                        1e100)<br>    temperature = 20.0  cost_delta_sd<br><br>    # The number of swap-attempts between temperature changes is selected by<br>    # the heuristic used by VPR. This value is scaled linearly by the effort<br>    # parameter.<br>    num_steps = max(1, int(effort  len(vertices_resources)1.33))<br><br>    logger.info("Initial placement temperature: %0.1f", temperature)<br><br>    # Counter for the number of swap attempts made (used for diagnostic<br>    # purposes)<br>    iteration_count = 0<br><br>    # Holds the total cost of the current placement. This default value chosen<br>    # to ensure the loop below iterates at least once.<br>    current_cost = 0.0<br><br>    # The annealing algorithm runs until a heuristic termination condition<br>    # (taken from VPR) is hit. The heuristic waits until the temperature falls<br>    # below a small fraction of the average net cost.<br>    while temperature  (0.005  current_cost) / len(nets):<br>        # Run an iteration at the current temperature<br>        num_accepted, current_cost, _ = k.run_steps(<br>            num_steps, int(math.ceil(distance_limit)), temperature)<br><br>        # The ratio of accepted-to-not-accepted changes<br>        r_accept = num_accepted / float(num_steps)<br><br>        # Special case: Can't do better than 0 cost! This is a special case<br>        # since the normal termination condition will not terminate if the cost<br>        # doesn't drop below 0.<br>        if current_cost == 0:<br>            break<br><br>        # The temperature is reduced by a factor heuristically based on the<br>        # acceptance rate. The schedule below attempts to maximise the time<br>        # spent at temperatures where a large portion (but not all) of changes<br>        # are being accepted. If lots of changes are being accepted (e.g.<br>        # during high-temperature periods) then most of them are likely not to<br>        # be beneficial. If few changes are being accepted, we're probably<br>        # pretty close to the optimal placement.<br>        if r_accept  0.96:<br>            alpha = 0.5<br>        elif r_accept  0.8:<br>            alpha = 0.9<br>        elif r_accept  0.15:<br>            alpha = 0.95<br>        else:<br>            alpha = 0.8<br>        temperature = alpha  temperature<br><br>        # According to:<br>        #  M. Huang, F. Romeo, and A. Sangiovanni-Vincentelli, "An Efficient<br>        #   General Cooling Schedule for Simulated Annealing" ICCAD, 1986, pp.<br>        #   381 - 384 and J. Lam<br>        #  J. Delosme, "Performance of a New Annealing Schedule" DAC, 1988,<br>        #   pp. 306 - 311.<br>        # It is desirable to keep the acceptance ratio as close to 0.44 for as<br>        # long as possible. As a result, when r_accept falls below this we can<br>        # help increase the acceptance rate by reducing the set of possible<br>        # swap candidates based on the observation that near the end of<br>        # placement, most things are near their optimal location and thus long<br>        # distance swaps are unlikely to be useful.<br>        distance_limit = 1.0 - 0.44 + r_accept<br>        distance_limit = min(max(distance_limit, 1.0),<br>                             max(machine.width, machine.height))<br><br>        iteration_count += num_steps<br>        logger.debug("Iteration: %d, "<br>                     "Cost: %0.1f, "<br>                     "Kept: %0.1f%%, "<br>                     "Temp: %0.3f, "<br>                     "Dist: %d.",<br>                     iteration_count, current_cost,<br>                     r_accept100, temperature, math.ceil(distance_limit))<br><br>        # Call the user callback before the next iteration, terminating if<br>        # requested.<br>        if on_temperature_change is not None:<br>            placements = k.get_placements().copy()<br>            finalise_same_chip_constraints(substitutions, placements)<br>            ret_val = on_temperature_change(iteration_count,<br>                                            placements,<br>                                            current_cost,<br>                                            r_accept,<br>                                            temperature,<br>                                            distance_limit)<br>            if ret_val is False:<br>                break<br><br>    logger.info("Anneal terminated after %d iterations.", iteration_count)<br><br>    placements = k.get_placements()<br>    finalise_same_chip_constraints(substitutions, placements)<br><br>    return placements

### DOC[3] (IRRELEVANT) leetcode/csn_python_train_65611.txt
> def _compute_stacksize(self):<br>        '''<br>        Given this object's code list, compute its maximal stack usage.<br>        This is done by scanning the code, and computing for each opcode<br>        the stack state at the opcode.<br><br>        '''<br><br>        # get local access to code, save some attribute lookups later<br>        code = self.code<br><br>        # A mapping from labels to their positions in the code list<br>        label_pos = { op : pos<br>                        for pos, (op, arg) in enumerate(code)<br>                        if isinstance(op, Label)<br>                    }<br><br>        # sf_targets are the targets of SETUP_FINALLY opcodes. They are<br>        # recorded because they have special stack behaviour. If an exception<br>        # was raised in the block pushed by a SETUP_FINALLY opcode, the block<br>        # is popped and 3 objects are pushed. On return or continue, the<br>        # block is popped and 2 objects are pushed. If nothing happened, the<br>        # block is popped by a POP_BLOCK opcode and 1 object is pushed by a<br>        # (LOAD_CONST, None) operation.<br>        #<br>        # In Python 3, the targets of SETUP_WITH have similar behavior,<br>        # complicated by the fact that they also have an __exit__ method<br>        # stacked and what it returns determines what they pop. So their<br>        # stack depth is one greater, a fact we are going to ignore for the<br>        # time being :-/<br>        #<br>        # Our solution is to record the stack state of SETUP_FINALLY targets<br>        # as having 3 objects pushed, which is the maximum. However, to make<br>        # stack recording consistent, the get_next_stacks function will always<br>        # yield the stack state of the target as if 1 object was pushed, but<br>        # this will be corrected in the actual stack recording.<br><br>        sf_targets = set( label_pos[arg]<br>                          for op, arg in code<br>                          if op == SETUP_FINALLY or op == SETUP_WITH<br>                        )<br><br>        # What we compute - for each opcode, its stack state, as an n-tuple.<br>        # n is the number of blocks pushed. For each block, we record the number<br>        # of objects pushed.<br>        stacks = [None]  len(code)<br><br>        def get_next_stacks(pos, curstack):<br>            """<br>            Get a code position and the stack state before the operation<br>            was done, and yield pairs (pos, curstack) for the next positions<br>            to be explored - those are the positions to which you can get<br>            from the given (pos, curstack).<br><br>            If the given position was already explored, nothing will be yielded.<br>            """<br>            op, arg = code[pos]<br><br>            if isinstance(op, Label):<br>                # We should check if we already reached a node only if it is<br>                # a label.<br><br>                if pos in sf_targets:<br>                    # Adjust a SETUP_FINALLY from 1 to 3 stack entries.<br>                    curstack = curstack[:-1] + (curstack[-1] + 2,)<br><br>                if stacks[pos] is None:<br>                    stacks[pos] = curstack<br>                else:<br>                    if stacks[pos] != curstack:<br>                        raise ValueError("Inconsistent code")<br>                    return<br><br>            def newstack(n):<br>                # Return a new stack, modified by adding n elements to the last<br>                # block<br>                if curstack[-1] + n < 0:<br>                    raise ValueError("Popped a non-existing element")<br>                return curstack[:-1] + (curstack[-1]+n,)<br><br>            if not isopcode(op):<br>                # label or SetLineno - just continue to next line<br>                yield pos+1, curstack<br><br>            elif op in ( RETURN_VALUE, RAISE_VARARGS ):<br>                # No place in particular to continue to<br>                pass<br><br>            elif op in (JUMP_FORWARD, JUMP_ABSOLUTE):<br>                # One possibility for a jump<br>                yield label_pos[arg], curstack<br><br>            elif op in (POP_JUMP_IF_FALSE, POP_JUMP_IF_TRUE):<br>                # Two possibilities for a jump<br>                yield label_pos[arg], newstack(-1)<br>                yield pos+1, newstack(-1)<br><br>            elif op in (JUMP_IF_TRUE_OR_POP, JUMP_IF_FALSE_OR_POP):<br>                # Two possibilities for a jump<br>                yield label_pos[arg], curstack<br>                yield pos+1, newstack(-1)<br><br>            elif op == FOR_ITER:<br>                # FOR_ITER pushes next(TOS) on success, and pops TOS and jumps<br>                # on failure<br>                yield label_pos[arg], newstack(-1)<br>                yield pos+1, newstack(1)<br><br>            elif op == BREAK_LOOP:<br>                # BREAK_LOOP goes to the end of a loop and pops a block<br>                # but like RETURN_VALUE we have no instruction position<br>                # to give. For now treat like RETURN_VALUE<br>                pass<br><br>            elif op == CONTINUE_LOOP:<br>                # CONTINUE_LOOP jumps to the beginning of a loop which should<br>                # already have been discovered. It does not change the stack<br>                # state nor does it create or pop a block.<br>                #yield label_pos[arg], curstack<br>                #yield label_pos[arg], curstack[:-1]<br>                pass<br><br>            elif op == SETUP_LOOP:<br>                # We continue with a new block.<br>                # On break, we jump to the label and return to current stack<br>                # state.<br>                yield label_pos[arg], curstack<br>                yield pos+1, curstack + (0,)<br><br>            elif op == SETUP_EXCEPT:<br>                # We continue with a new block.<br>                # On exception, we jump to the label with 3 extra objects on<br>                # stack<br>                yield label_pos[arg], newstack(3)<br>                yield pos+1, curstack + (0,)<br><br>            elif op == SETUP_FINALLY or op == SETUP_WITH :<br>                # We continue with a new block.<br>                # On exception, we jump to the label with 3 extra objects on<br>                # stack, but to keep stack recording consistent, we behave as<br>                # if we add only 1 object. Extra 2 will be added to the actual<br>                # recording.<br>                yield label_pos[arg], newstack(1)<br>                yield pos+1, curstack + ( int(op == SETUP_WITH) ,)<br><br>            elif op == POP_BLOCK:<br>                # Just pop the block<br>                yield pos+1, curstack[:-1]<br><br>            elif op == END_FINALLY :<br>                # Since stack recording of SETUP_FINALLY targets is of 3 pushed<br>                # objects (as when an exception is raised), we pop 3 objects.<br>                yield pos+1, newstack(-3)<br><br>            elif op == _WITH_CLEANUP_OPCODE:<br>                # Since WITH_CLEANUP[_START] is always found after SETUP_FINALLY<br>                # targets, and the stack recording is that of a raised<br>                # exception, we can simply pop 1 object and let END_FINALLY<br>                # pop the remaining 3.<br>                yield pos+1, newstack(-1)<br><br>            else:<br>                # nothing special, use the CPython value<br>                yield pos+1, newstack( stack_effect( op, arg ) )<br><br><br>        # Now comes the calculation: open_positions holds positions which are<br>        # yet to be explored. In each step we take one open position, and<br>        # explore it by appending the positions to which it can go, to<br>        # open_positions. On the way, we update maxsize.<br>        #<br>        # open_positions is a list of tuples: (pos, stack state)<br>        #<br>        # Sneaky Python coding trick here. get_next_stacks() is a generator,<br>        # it contains yield statements. So when we call get_next_stacks()<br>        # what is returned is an iterator. However, the yield statements in<br>        # get_next_stacks() are not in a loop as usual; rather it is<br>        # straight-line code that will execute 0, 1 or 2 yields depending on<br>        # the Opcode at pos.<br>        #<br>        # the list.extend() method takes an iterator and exhausts it, adding<br>        # all yielded values to the list. Hence the statement<br>        #<br>        #   open_positions.extend(get_next_stacks(pos,curstack))<br>        #<br>        # appends 0, 1 or 2 tuples (pos, stack_state) to open_positions.<br><br>        maxsize = 0<br>        open_positions = [(0, (0,))]<br>        while open_positions:<br>            pos, curstack = open_positions.pop()<br>            maxsize = max(maxsize, sum(curstack))<br>            open_positions.extend(get_next_stacks(pos, curstack))<br><br>        return maxsize

### DOC[4] (IRRELEVANT) leetcode/csn_python_train_132059.txt
> def pretty(self, start, end, e, messages=None):<br>        """Pretties up the output error message so it is readable<br>        and designates where the error came from"""<br><br>        log.debug("Displaying document from lines '%i' to '%i'", start, end)<br><br>        errorlist = []<br>        if len(e.context)  0:<br>            errorlist = e.context<br>        else:<br>            errorlist.append(e)<br><br>        for error in errorlist:<br>            validator = error.validator<br><br>            if validator == "required":<br>                # Handle required fields<br>                msg = error.message<br>                messages.append("Between lines %d - %d. %s" % (start, end, msg))<br>            elif validator == "additionalProperties":<br>                # Handle additional properties not allowed<br>                if len(error.message)  256:<br>                    msg = error.message[:253] + "..."<br>                else:<br>                    msg = error.message<br>                    messages.append("Between lines %d - %d. %s" % (start, end, msg))<br>            elif len(error.relative_path)  0:<br>                # Handle other cases where we can loop through the lines<br><br>                # get the JSON path to traverse through the file<br>                jsonpath = error.relative_path<br>                array_index = 0<br><br>                current_start = start<br>                foundline = 0<br>                found = False<br><br>                context = collections.deque(maxlen=20)<br>                tag = "        <<<<<<<<< Expects: %s <<<<<<<<<\n"""<br>                for cnt, path in enumerate(error.relative_path):<br><br>                    # Need to set the key we are looking, and then check the array count<br>                    # if it is an array, we have some interesting checks to do<br>                    if int(cnt) % 2 == 0:<br>                        # we know we have some array account<br>                        # array_index keeps track of the array count we are looking for or number<br>                        # of matches we need to skip over before we get to the one we care about<br><br>                        # check if previous array_index  0. if so, then we know we need to use<br>                        # that one to track down the specific instance of this nested key.<br>                        # later on, we utilize this array_index loop through<br>                        # if array_index == 0:<br>                        array_index = jsonpath[cnt]<br><br>                        match_count = 0<br>                        continue<br>                    elif int(cnt) % 2 == 1:<br>                        # we know we have some key name<br>                        # current_key keeps track of the key we are looking for in the JSON Path<br>                        current_key = jsonpath[cnt]<br><br>                    for linenum in range(current_start, end):<br>                        line = linecache.getline(self.ymlfile, linenum)<br><br>                        # Check if line contains the error<br>                        if ":" in line:<br>                            l = line.split(':')<br>                            key = l[0]<br>                            value = ':'.join(l[1:])<br><br>                            # TODO:<br>                            # Handle maxItems TBD<br>                            # Handle minItems TBD<br>                            # Handle in-order (bytes) TBD<br>                            # Handle uniqueness TBD<br><br>                            # Handle cases where key in yml file is hexadecimal<br>                            try:<br>                                key = int(key.strip(), 16)<br>                            except ValueError:<br>                                key = key.strip()<br><br>                            if str(key) == current_key:<br>                                # check if we are at our match_count and end of the path<br>                                if match_count == array_index:<br>                                    # check if we are at end of the jsonpath<br>                                    if cnt == len(jsonpath)-1:<br>                                        # we are at the end of path so let's stop here'<br>                                        if error.validator == "type":<br>                                            if value.strip() == str(error.instance):<br>                                                errormsg = "Value '%s' should be of type '%s'" % (error.instance, str(error.validator_value))<br>                                                line = line.replace("\n", (tag % errormsg))<br>                                                foundline = linenum<br>                                                found = True<br>                                            elif value.strip() == "" and error.instance is None:<br>                                                errormsg = "Missing value for %s." % key<br>                                                line = line.replace("\n", (tag % errormsg))<br>                                                foundline = linenum<br>                                                found = True<br><br>                                    elif not found:<br>                                        # print "EXTRA FOO"<br>                                        # print match_count<br>                                        # print array_index<br>                                        # print current_key<br>                                        # print line<br>                                        # otherwise change the start to the current line<br>                                        current_start = linenum<br>                                        break<br><br>                                match_count += 1<br><br><br>                                <br><br>                        # for the context queue, we want to get the error to appear in<br>                        # the middle of the error output. to do so, we will only append<br>                        # to the queue in 2 cases:<br>                        #<br>                        # 1. before we find the error (found == False). we can<br>                        #    just keep pushing on the queue until we find it in the YAML.<br>                        # 2. once we find the error (found == True), we just want to push<br>                        #    onto the queue until the the line is in the middle<br>                        if not found or (found and context.maxlen  (linenum-foundline)2):<br>                            context.append(line)<br>                        elif found and context.maxlen <= (linenum-foundline)2:<br>                            break<br><br><br>                    # Loop through the queue and generate a readable msg output<br>                    out = ""<br>                    for line in context:<br>                        out += line<br><br>                    if foundline:<br>                        msg = "Error found on line %d in %s:\n\n%s" % (foundline, self.ymlfile, out)<br>                        messages.append(msg)<br><br>                        # reset the line it was found on and the context<br>                        foundline = 0<br>                        context.clear()<br><br>                    linecache.clearcache()<br>            else:<br>                messages.append(error.message)

### DOC[5] (IRRELEVANT) leetcode/csn_python_train_261935.txt
> def _compute_stacksize(self):<br>        """Get a code list, compute its maximal stack usage."""<br>        # This is done by scanning the code, and computing for each opcode<br>        # the stack state at the opcode.<br>        code = self.code<br><br>        # A mapping from labels to their positions in the code list<br>        label_pos = dict((op, pos)<br>                         for pos, (op, arg) in enumerate(code)<br>                         if isinstance(op, Label))<br><br>        # sf_targets are the targets of SETUP_FINALLY opcodes. They are recorded<br>        # because they have special stack behaviour. If an exception was raised<br>        # in the block pushed by a SETUP_FINALLY opcode, the block is popped<br>        # and 3 objects are pushed. On return or continue, the block is popped<br>        # and 2 objects are pushed. If nothing happened, the block is popped by<br>        # a POP_BLOCK opcode and 1 object is pushed by a (LOAD_CONST, None)<br>        # operation.<br>        #<br>        # Our solution is to record the stack state of SETUP_FINALLY targets<br>        # as having 3 objects pushed, which is the maximum. However, to make<br>        # stack recording consistent, the get_next_stacks function will always<br>        # yield the stack state of the target as if 1 object was pushed, but<br>        # this will be corrected in the actual stack recording.<br><br>        sf_targets = set(label_pos[arg]<br>                         for op, arg in code<br>                         if op == SETUP_FINALLY)<br><br>        # What we compute - for each opcode, its stack state, as an n-tuple.<br>        # n is the number of blocks pushed. For each block, we record the number<br>        # of objects pushed.<br>        stacks = [None]  len(code)<br><br>        def get_next_stacks(pos, curstack):<br>            """Get a code position and the stack state before the operation<br>            was done, and yield pairs (pos, curstack) for the next positions<br>            to be explored - those are the positions to which you can get<br>            from the given (pos, curstack).<br><br>            If the given position was already explored, nothing will be yielded.<br>            """<br>            op, arg = code[pos]<br><br>            if isinstance(op, Label):<br>                # We should check if we already reached a node only if it is<br>                # a label.<br>                if pos in sf_targets:<br>                    curstack = curstack[:-1] + (curstack[-1] + 2,)<br>                if stacks[pos] is None:<br>                    stacks[pos] = curstack<br>                else:<br>                    if stacks[pos] != curstack:<br>                        raise ValueError("Inconsistent code")<br>                    return<br><br>            def newstack(n):<br>                # Return a new stack, modified by adding n elements to the last<br>                # block<br>                if curstack[-1] + n < 0:<br>                    raise ValueError("Popped a non-existing element")<br>                return curstack[:-1] + (curstack[-1]+n,)<br><br>            if not isopcode(op):<br>                # label or SetLineno - just continue to next line<br>                yield pos+1, curstack<br><br>            elif op in (STOP_CODE, RETURN_VALUE, RAISE_VARARGS):<br>                # No place in particular to continue to<br>                pass<br><br>            elif op == MAKE_CLOSURE and python_version == '2.4':<br>                # This is only relevant in Python 2.4 - in Python 2.5 the stack<br>                # effect of MAKE_CLOSURE can be calculated from the arg.<br>                # In Python 2.4, it depends on the number of freevars of TOS,<br>                # which should be a code object.<br>                if pos == 0:<br>                    raise ValueError("MAKE_CLOSURE can't be the first opcode")<br>                lastop, lastarg = code[pos-1]<br>                if lastop != LOAD_CONST:<br>                    raise ValueError(<br>                        "MAKE_CLOSURE should come after a LOAD_CONST op")<br>                try:<br>                    nextrapops = len(lastarg.freevars)<br>                except AttributeError:<br>                    try:<br>                        nextrapops = len(lastarg.co_freevars)<br>                    except AttributeError:<br>                        raise ValueError(<br>                            "MAKE_CLOSURE preceding const should "<br>                            "be a code or a Code object")<br><br>                yield pos+1, newstack(-arg-nextrapops)<br><br>            elif op not in hasflow:<br>                # Simple change of stack<br>                pop, push = getse(op, arg)<br>                yield pos+1, newstack(push - pop)<br><br>            elif op in (JUMP_FORWARD, JUMP_ABSOLUTE):<br>                # One possibility for a jump<br>                yield label_pos[arg], curstack<br><br>            elif python_version < '2.7' and op in (JUMP_IF_FALSE, JUMP_IF_TRUE):<br>                # Two possibilities for a jump<br>                yield label_pos[arg], curstack<br>                yield pos+1, curstack<br><br>            elif python_version = '2.7' and op in (POP_JUMP_IF_FALSE, POP_JUMP_IF_TRUE):<br>                # Two possibilities for a jump<br>                yield label_pos[arg], newstack(-1)<br>                yield pos+1, newstack(-1)<br><br>            elif python_version = '2.7' and op in (JUMP_IF_TRUE_OR_POP, JUMP_IF_FALSE_OR_POP):<br>                # Two possibilities for a jump<br>                yield label_pos[arg], curstack<br>                yield pos+1, newstack(-1)<br><br>            elif op == FOR_ITER:<br>                # FOR_ITER pushes next(TOS) on success, and pops TOS and jumps<br>                # on failure<br>                yield label_pos[arg], newstack(-1)<br>                yield pos+1, newstack(1)<br><br>            elif op == BREAK_LOOP:<br>                # BREAK_LOOP jumps to a place specified on block creation, so<br>                # it is ignored here<br>                pass<br><br>            elif op == CONTINUE_LOOP:<br>                # CONTINUE_LOOP jumps to the beginning of a loop which should<br>                # already ave been discovered, but we verify anyway.<br>                # It pops a block.<br>                if python_version == '2.6':<br>                  pos, stack = label_pos[arg], curstack[:-1]<br>                  if stacks[pos] != stack: #this could be a loop with a 'with' inside<br>                    yield pos, stack[:-1] + (stack[-1]-1,)<br>                  else:<br>                    yield pos, stack<br>                else:<br>                  yield label_pos[arg], curstack[:-1]<br><br>            elif op == SETUP_LOOP:<br>                # We continue with a new block.<br>                # On break, we jump to the label and return to current stack<br>                # state.<br>                yield label_pos[arg], curstack<br>                yield pos+1, curstack + (0,)<br><br>            elif op == SETUP_EXCEPT:<br>                # We continue with a new block.<br>                # On exception, we jump to the label with 3 extra objects on<br>                # stack<br>                yield label_pos[arg], newstack(3)<br>                yield pos+1, curstack + (0,)<br><br>            elif op == SETUP_FINALLY:<br>                # We continue with a new block.<br>                # On exception, we jump to the label with 3 extra objects on<br>                # stack, but to keep stack recording consistent, we behave as<br>                # if we add only 1 object. Extra 2 will be added to the actual<br>                # recording.<br>                yield label_pos[arg], newstack(1)<br>                yield pos+1, curstack + (0,)<br><br>            elif python_version == '2.7' and op == SETUP_WITH:<br>                yield label_pos[arg], curstack<br>                yield pos+1, newstack(-1) + (1,)<br><br>            elif op == POP_BLOCK:<br>                # Just pop the block<br>                yield pos+1, curstack[:-1]<br><br>            elif op == END_FINALLY:<br>                # Since stack recording of SETUP_FINALLY targets is of 3 pushed<br>                # objects (as when an exception is raised), we pop 3 objects.<br>                yield pos+1, newstack(-3)<br><br>            elif op == WITH_CLEANUP:<br>                # Since WITH_CLEANUP is always found after SETUP_FINALLY<br>                # targets, and the stack recording is that of a raised<br>                # exception, we can simply pop 1 object and let END_FINALLY<br>                # pop the remaining 3.<br>                if python_version == '2.7':<br>                  yield pos+1, newstack(2)<br>                else:<br>                  yield pos+1, newstack(-1)<br><br>            else:<br>                assert False, "Unhandled opcode: %r" % op<br><br><br>        # Now comes the calculation: open_positions holds positions which are<br>        # yet to be explored. In each step we take one open position, and<br>        # explore it by adding the positions to which you can get from it, to<br>        # open_positions. On the way, we update maxsize.<br>        # open_positions is a list of tuples: (pos, stack state)<br>        maxsize = 0<br>        open_positions = [(0, (0,))]<br>        while open_positions:<br>            pos, curstack = open_positions.pop()<br>            maxsize = max(maxsize, sum(curstack))<br>            open_positions.extend(get_next_stacks(pos, curstack))<br><br>        return maxsize


## Ground Truth

### GROUND TRUTH 0, ranked 13, leetcode/leetcode_496.txt
> def next_greater_element(nums1, nums2):<br>    """The next greater element of some element `x` in an array is the first greater element that is to the right of `x` in the same array.<br><br>You are given two distinct 0-indexed integer arrays `nums1` and `nums2`, where `nums1` is a subset of `nums2`.<br><br>For each `0 <= i < nums1.length`, find the index `j` such that `nums1[i] == nums2[j]` and determine the next greater element of `nums2[j]` in `nums2`. If there is no next greater element, then the answer for this query is `-1`.<br><br>Return _an array_ `ans` _of length_ `nums1.length` _such that_ `ans[i]` _is the next greater element as described above._<br><br>Example 1:<br><br>Input: nums1 = \[4,1,2\], nums2 = \[1,3,4,2\]<br>Output: \[-1,3,-1\]<br>Explanation: The next greater element for each value of nums1 is as follows:<br>- 4 is underlined in nums2 = \[1,3,4,2\]. There is no next greater element, so the answer is -1.<br>- 1 is underlined in nums2 = \[1,3,4,2\]. The next greater element is 3.<br>- 2 is underlined in nums2 = \[1,3,4,2\]. There is no next greater element, so the answer is -1.<br><br>Example 2:<br><br>Input: nums1 = \[2,4\], nums2 = \[1,2,3,4\]<br>Output: \[3,-1\]<br>Explanation: The next greater element for each value of nums1 is as follows:<br>- 2 is underlined in nums2 = \[1,2,3,4\]. The next greater element is 3.<br>- 4 is underlined in nums2 = \[1,2,3,4\]. There is no next greater element, so the answer is -1.<br><br>Constraints:<br><br>   `1 <= nums1.length <= nums2.length <= 1000`<br>   `0 <= nums1[i], nums2[i] <= 104`<br>   All integers in `nums1` and `nums2` are unique.<br>   All the integers of `nums1` also appear in `nums2`.<br><br>Follow up: Could you find an `O(nums1.length + nums2.length)` solution?"""<br><br>    next_greater = {}<br>    stack = []<br><br>    for num in nums2:<br>        while stack and stack[-1] < num:<br>            next_greater[stack.pop()] = num<br>        stack.append(num)<br><br>    return [next_greater.get(n, -1) for n in nums1]
