# Query `101`

## Original Question

*You are given a list of bombs. The range of a bomb is defined as the area where its effect can be felt. This area is in the shape of a circle with the center as the location of the bomb.

The bombs are represented by a 0-indexed 2D integer array `bombs` where `bombs[i] = [xi, yi, ri]`. `xi` and `yi` denote the X-coordinate and Y-coordinate of the location of the `ith` bomb, whereas `ri` denotes the radius of its range.

You may choose to detonate a single bomb. When a bomb is detonated, it will detonate all bombs that lie in its range. These bombs will further detonate the bombs that lie in their ranges.

Given the list of `bombs`, return _the maximum number of bombs that can be detonated if you are allowed to detonate only one bomb_.

Example 1:

Input: bombs = \[\[2,1,3\],\[6,1,4\]\]
Output: 2
Explanation:
The above figure shows the positions and ranges of the 2 bombs.
If we detonate the left bomb, the right bomb will not be affected.
But if we detonate the right bomb, both bombs will be detonated.
So the maximum bombs that can be detonated is max(1, 2) = 2.

Example 2:

Input: bombs = \[\[1,1,5\],\[10,10,5\]\]
Output: 1
Explanation:
Detonating either bomb will not detonate the other bomb, so the maximum number of bombs that can be detonated is 1.

Example 3:

Input: bombs = \[\[1,2,3\],\[2,3,1\],\[3,4,2\],\[4,5,3\],\[5,6,4\]\]
Output: 5
Explanation:
The best bomb to detonate is bomb 0 because:
- Bomb 0 detonates bombs 1 and 2. The red circle denotes the range of bomb 0.
- Bomb 2 detonates bomb 3. The blue circle denotes the range of bomb 2.
- Bomb 3 detonates bomb 4. The green circle denotes the range of bomb 3.
Thus all 5 bombs are detonated.

Constraints:

   `1 <= bombs.length <= 100`
   `bombs[i].length == 3`
   `1 <= xi, yi, ri <= 105`*

## gpt4 Reasoning

```markdown
The essential problem here is to find the maximum number of bombs that can be detonated by initiating the explosion of just one bomb, taking into account the chain reaction that can occur when bombs within the range of an exploding bomb are also detonated. This problem involves understanding the spatial relationships between the bombs, specifically, which bombs are within the range of others.

### Key Concepts

1. **Bomb Representation**: Each bomb is represented as `[xi, yi, ri]`, where `(xi, yi)` is the bomb's location on a 2D plane, and `ri` is the radius of its explosion range.
2. **Detonation Chain Reaction**: Detonating one bomb can potentially detonate others within its range, which can further detonate others within their ranges, and so on.
3. **Goal**: To find the single bomb detonation that leads to the highest number of total detonations.

### Step-by-Step Approach

1. **Model the Problem**: This can be seen as a graph problem where each bomb is a node, and an edge exists between two bombs if one can detonate the other due to being within the explosion range.

2. **Build Connections**: Calculate the distance between every pair of bombs to determine if one can detonate the other. The distance between two points `(x1, y1)` and `(x2, y2)` is given by the Euclidean distance formula \(\sqrt{(x2-x1)^2 + (y2-y1)^2}\). If this distance is less than or equal to the radius of the bomb initiating the potential detonation, an edge is formed.

3. **Find the Best Starting Point**:
   - Perform a Depth-First Search (DFS) or Breadth-First Search (BFS) from each bomb to see how many bombs can be detonated, including chain reactions.
   - Keep track of the maximum number of bombs detonated starting from each bomb.
   - The DFS/BFS needs to account for the fact that once a bomb is detonated (visited), it cannot detonate again (prevent cycles).

4. **Optimization**: Since the number of bombs can be up to 100, and we potentially perform a DFS/BFS starting from each bomb, the algorithm might seem computationally intensive at first glance. However, the problem size is relatively small, making this brute-force approach feasible. Optimization techniques could involve memoization or pruning the search space by not revisiting nodes already known to result in fewer detonations.

### Conclusion

By mapping the problem to a graph, where nodes are bombs and edges represent the potential to detonate another bomb, we can systematically explore all possibilities to find the optimal starting bomb. This involves calculating distances to establish connections and then using a search algorithm like DFS or BFS to explore the outcome of detonating each bomb, directly addressing the problem's goal.
```

### Metrics

```
recip_rank: 0.0000
P_1: 0.0000
P_5: 0.0000
P_10: 0.0000
P_25: 0.0000
P_50: 0.0000
P_100: 0.0000
recall_1: 0.0000
recall_5: 0.0000
recall_10: 0.0000
recall_25: 0.0000
recall_50: 0.0000
recall_100: 0.0000
ndcg_cut_1: 0.0000
ndcg_cut_5: 0.0000
ndcg_cut_10: 0.0000
ndcg_cut_25: 0.0000
ndcg_cut_50: 0.0000
ndcg_cut_100: 0.0000
map_cut_1: 0.0000
map_cut_5: 0.0000
map_cut_10: 0.0000
map_cut_25: 0.0000
map_cut_50: 0.0000
map_cut_100: 0.0000
```

## Retrieval Results

### DOC[1] (IRRELEVANT) leetcode/leetcode_1620.txt
> def canArrange(arr, k):<br>    """You are given an array of network towers `towers`, where `towers[i] = [xi, yi, qi]` denotes the `ith` network tower with location `(xi, yi)` and quality factor `qi`. All the coordinates are integral coordinates on the X-Y plane, and the distance between the two coordinates is the Euclidean distance.<br><br>You are also given an integer `radius` where a tower is reachable if the distance is less than or equal to `radius`. Outside that distance, the signal becomes garbled, and the tower is not reachable.<br><br>The signal quality of the `ith` tower at a coordinate `(x, y)` is calculated with the formula `⌊qi / (1 + d)⌋`, where `d` is the distance between the tower and the coordinate. The network quality at a coordinate is the sum of the signal qualities from all the reachable towers.<br><br>Return _the array_ `[cx, cy]` _representing the integral coordinate_ `(cx, cy)` _where the network quality is maximum. If there are multiple coordinates with the same network quality, return the lexicographically minimum non-negative coordinate._<br><br>Note:<br><br>   A coordinate `(x1, y1)` is lexicographically smaller than `(x2, y2)` if either:<br>       `x1 < x2`, or<br>       `x1 == x2` and `y1 < y2`.<br>   `⌊val⌋` is the greatest integer less than or equal to `val` (the floor function).<br><br>Example 1:<br><br>Input: towers = \[\[1,2,5\],\[2,1,7\],\[3,1,9\]\], radius = 2<br>Output: \[2,1\]<br>Explanation: At coordinate (2, 1) the total quality is 13.<br>- Quality of 7 from (2, 1) results in ⌊7 / (1 + sqrt(0)⌋ = ⌊7⌋ = 7<br>- Quality of 5 from (1, 2) results in ⌊5 / (1 + sqrt(2)⌋ = ⌊2.07⌋ = 2<br>- Quality of 9 from (3, 1) results in ⌊9 / (1 + sqrt(1)⌋ = ⌊4.5⌋ = 4<br>No other coordinate has a higher network quality.<br><br>Example 2:<br><br>Input: towers = \[\[23,11,21\]\], radius = 9<br>Output: \[23,11\]<br>Explanation: Since there is only one tower, the network quality is highest right at the tower's location.<br><br>Example 3:<br><br>Input: towers = \[\[1,2,13\],\[2,1,7\],\[0,1,9\]\], radius = 2<br>Output: \[1,2\]<br>Explanation: Coordinate (1, 2) has the highest network quality.<br><br>Constraints:<br><br>   `1 <= towers.length <= 50`<br>   `towers[i].length == 3`<br>   `0 <= xi, yi, qi <= 50`<br>   `1 <= radius <= 50`"""<br><br>    counts = [0]  k<br>    for num in arr:<br>        counts[(num % k + k) % k] += 1<br>    if counts[0] % 2 != 0:<br>        return False<br>    for i in range(1, k // 2 + 1):<br>        if counts[i] != counts[k - i]:<br>            return False<br>    return True

### DOC[2] (IRRELEVANT) leetcode/csn_python_train_120494.txt
> def _find_peak(data, peak_fit_box=5, mask=None):<br>    """<br>    Find location of the peak in an array. This is done by fitting a second<br>    degree 2D polynomial to the data within a `peak_fit_box` and computing the<br>    location of its maximum. An initial<br>    estimate of the position of the maximum will be performed by searching<br>    for the location of the pixel/array element with the maximum value.<br><br>    Parameters<br>    ----------<br>    data : numpy.ndarray<br>        2D data.<br><br>    peak_fit_box : int, optional<br>        Size (in pixels) of the box around the initial estimate of the maximum<br>        to be used for quadratic fitting from which peak location is computed.<br>        It is assumed that fitting box is a square with sides of length<br>        given by ``peak_fit_box``.<br><br>    mask : numpy.ndarray, optional<br>        A boolean type `~numpy.ndarray` indicating "good" pixels in image data<br>        (`True`) and "bad" pixels (`False`). If not provided all pixels<br>        in `image_data` will be used for fitting.<br><br>    Returns<br>    -------<br>    coord : tuple of float<br>        A pair of coordinates of the peak.<br><br>    fit_status : str<br>        Status of the peak search. Currently the following values can be<br>        returned:<br><br>        - ``'SUCCESS'``: Fit was successful and peak is not on the edge of<br>          the input array;<br>        - ``'ERROR:NODATA'``: Not enough valid data to perform the fit; The<br>          returned coordinate is the center of input array;<br>        - ``'WARNING:EDGE'``: Peak lies on the edge of the input array.<br>          Returned coordinates are the result of a discreet search;<br>        - ``'WARNING:BADFIT'``: Performed fid did not find a maximum. Returned<br>          coordinates are the result of a discreet search;<br>        - ``'WARNING:CENTER-OF-MASS'``: Returned coordinates are the result<br>          of a center-of-mass estimate instead of a polynomial fit. This is<br>          either due to too few points to perform a fit or due to a<br>          failure of the polynomial fit.<br><br>    fit_box : a tuple of two tuples<br>        A tuple of two tuples of the form ``((x1, x2), (y1, y2))`` that<br>        indicates pixel ranges used for fitting (these indices can be used<br>        directly for slicing input data)<br><br>    """<br>    # check arguments:<br>    data = np.asarray(data, dtype=np.float64)<br>    ny, nx = data.shape<br><br>    # find index of the pixel having maximum value:<br>    if mask is None:<br>        jmax, imax = np.unravel_index(np.argmax(data), data.shape)<br>        coord = (float(imax), float(jmax))<br><br>    else:<br>        j, i = np.indices(data.shape)<br>        i = i[mask]<br>        j = j[mask]<br><br>        if i.size == 0:<br>            # no valid data:<br>            coord = ((nx - 1.0) / 2.0, (ny - 1.0) / 2.0)<br>            return coord, 'ERROR:NODATA', np.s_[0:ny-1, 0:nx-1]<br><br>        ind = np.argmax(data[mask])<br>        imax = i[ind]<br>        jmax = j[ind]<br>        coord = (float(imax), float(jmax))<br><br>    if data[jmax, imax] < 1:<br>        # no valid data: we need some counts in the histogram bins<br>        coord = ((nx - 1.0) / 2.0, (ny - 1.0) / 2.0)<br>        return coord, 'ERROR:NODATA', np.s_[0:ny-1, 0:nx-1]<br><br>    # choose a box around maxval pixel:<br>    x1 = max(0, imax - peak_fit_box // 2)<br>    x2 = min(nx, x1 + peak_fit_box)<br>    y1 = max(0, jmax - peak_fit_box // 2)<br>    y2 = min(ny, y1 + peak_fit_box)<br><br>    # if peak is at the edge of the box, return integer indices of the max:<br>    if imax == x1 or imax == x2 or jmax == y1 or jmax == y2:<br>        return (float(imax), float(jmax)), 'WARNING:EDGE', np.s_[y1:y2, x1:x2]<br><br>    # expand the box if needed:<br>    if (x2 - x1) < peak_fit_box:<br>        if x1 == 0:<br>            x2 = min(nx, x1 + peak_fit_box)<br>        if x2 == nx:<br>            x1 = max(0, x2 - peak_fit_box)<br><br>    if (y2 - y1) < peak_fit_box:<br>        if y1 == 0:<br>            y2 = min(ny, y1 + peak_fit_box)<br>        if y2 == ny:<br>            y1 = max(0, y2 - peak_fit_box)<br><br>    if x2 - x1 == 0 or y2 - y1 == 0:<br>        # not enough data:<br>        coord = ((nx - 1.0) / 2.0, (ny - 1.0) / 2.0)<br>        return coord, 'ERROR:NODATA', np.s_[y1:y2, x1:x2]<br><br>    # fit a 2D 2nd degree polynomial to data:<br>    xi = np.arange(x1, x2)<br>    yi = np.arange(y1, y2)<br>    x, y = np.meshgrid(xi, yi)<br>    x = x.ravel()<br>    y = y.ravel()<br>    v = np.vstack((np.ones_like(x), x, y, xy, xx, yy)).T<br>    d = data[y1:y2, x1:x2].ravel()<br>    if mask is not None:<br>        m = mask[y1:y2, x1:x2].ravel()<br>        v = v[m]<br>        d = d[m]<br><br>    if d.size == 0 or np.max(d) <= 0:<br>        coord = ((nx - 1.0) / 2.0, (ny - 1.0) / 2.0)<br>        return coord, 'ERROR:NODATA', np.s_[y1:y2, x1:x2]<br><br>    if d.size < 6:<br>        # we need at least 6 points to fit a 2D quadratic polynomial<br>        # attempt center-of-mass instead:<br>        dt = d.sum()<br>        xc = np.dot(v[:, 1], d) / dt<br>        yc = np.dot(v[:, 2], d) / dt<br>        return (xc, yc), 'WARNING:CENTER-OF-MASS', np.s_[y1:y2, x1:x2]<br><br>    try:<br>        c = np.linalg.lstsq(v, d, rcond=None)[0]<br>    except np.linalg.LinAlgError:<br>        print("WARNING: Least squares failed!\n{}".format(c))<br><br>        # attempt center-of-mass instead:<br>        dt = d.sum()<br>        xc = np.dot(v[:, 1], d) / dt<br>        yc = np.dot(v[:, 2], d) / dt<br>        return (xc, yc), 'WARNING:CENTER-OF-MASS', np.s_[y1:y2, x1:x2]<br><br>    # find maximum of the polynomial:<br>    _, c10, c01, c11, c20, c02 = c<br>    det = 4  c02  c20 - c112<br>    if det <= 0 or ((c20  0.0 and c02 = 0.0) or (c20 = 0.0 and c02  0.0)):<br>        # polynomial does not have max. return maximum value in the data:<br>        return coord, 'WARNING:BADFIT', np.s_[y1:y2, x1:x2]<br><br>    xm = (c01  c11 - 2.0  c02  c10) / det<br>    ym = (c10  c11 - 2.0  c01  c20) / det<br><br>    if 0.0 <= xm <= (nx - 1.0) and 0.0 <= ym <= (ny - 1.0):<br>        coord = (xm, ym)<br>        fit_status = 'SUCCESS'<br><br>    else:<br>        xm = 0.0 if xm < 0.0 else min(xm, nx - 1.0)<br>        ym = 0.0 if ym < 0.0 else min(ym, ny - 1.0)<br>        fit_status = 'WARNING:EDGE'<br><br>    return coord, fit_status, np.s_[y1:y2, x1:x2]

### DOC[3] (IRRELEVANT) leetcode/csn_python_train_15814.txt
> def create(dataset, features=None, distance=None, radius=1.,<br>           min_core_neighbors=10, verbose=True):<br>    """<br>    Create a DBSCAN clustering model. The DBSCAN method partitions the input<br>    dataset into three types of points, based on the estimated probability<br>    density at each point.<br><br>    - Core points have a large number of points within a given neighborhood.<br>      Specifically, `min_core_neighbors` must be within distance `radius` of a<br>      point for it to be considered a core point.<br><br>    - Boundary points are within distance `radius` of a core point, but<br>      don't have sufficient neighbors of their own to be considered core.<br><br>    - Noise points comprise the remainder of the data. These points have too<br>      few neighbors to be considered core points, and are further than distance<br>      `radius` from all core points.<br><br>    Clusters are formed by connecting core points that are neighbors of each<br>    other, then assigning boundary points to their nearest core neighbor's<br>    cluster.<br><br>    Parameters<br>    ----------<br>    dataset : SFrame<br>        Training data, with each row corresponding to an observation. Must<br>        include all features specified in the `features` parameter, but may have<br>        additional columns as well.<br><br>    features : list[str], optional<br>        Name of the columns with features to use in comparing records. 'None'<br>        (the default) indicates that all columns of the input `dataset` should<br>        be used to train the model. All features must be numeric, i.e. integer<br>        or float types.<br><br>    distance : str or list[list], optional<br>        Function to measure the distance between any two input data rows. This<br>        may be one of two types:<br><br>        - String: the name of a standard distance function. One of<br>          'euclidean', 'squared_euclidean', 'manhattan', 'levenshtein',<br>          'jaccard', 'weighted_jaccard', 'cosine', 'dot_product' (deprecated),<br>          or 'transformed_dot_product'.<br><br>        - Composite distance: the weighted sum of several standard distance<br>          functions applied to various features. This is specified as a list of<br>          distance components, each of which is itself a list containing three<br>          items:<br><br>          1. list or tuple of feature names (str)<br><br>          2. standard distance name (str)<br><br>          3. scaling factor (int or float)<br><br>        For more information about Turi Create distance functions, please<br>        see the :py:mod:`~turicreate.toolkits.distances` module.<br><br>        For sparse vectors, missing keys are assumed to have value 0.0.<br><br>        If 'distance' is left unspecified, a composite distance is constructed<br>        automatically based on feature types.<br><br>    radius : int or float, optional<br>        Size of each point's neighborhood, with respect to the specified<br>        distance function.<br><br>    min_core_neighbors : int, optional<br>        Number of neighbors that must be within distance `radius` of a point in<br>        order for that point to be considered a "core point" of a cluster.<br><br>    verbose : bool, optional<br>        If True, print progress updates and model details during model creation.<br><br>    Returns<br>    -------<br>    out : DBSCANModel<br>        A model containing a cluster label for each row in the input `dataset`.<br>        Also contains the indices of the core points, cluster boundary points,<br>        and noise points.<br><br>    See Also<br>    --------<br>    DBSCANModel, turicreate.toolkits.distances<br><br>    Notes<br>    -----<br>    - Our implementation of DBSCAN first computes the similarity graph on the<br>      input dataset, which can be a computationally intensive process. In the<br>      current implementation, some distances are substantially faster than<br>      others; in particular "euclidean", "squared_euclidean", "cosine", and<br>      "transformed_dot_product" are quite fast, while composite distances can be<br>      slow.<br><br>    - Any distance function in the GL Create library may be used with DBSCAN but<br>      the results may be poor for distances that violate the standard metric<br>      properties, i.e. symmetry, non-negativity, triangle inequality, and<br>      identity of indiscernibles. In particular, the DBSCAN algorithm is based<br>      on the concept of connecting high-density points that are close to each<br>      other into a single cluster, but the notion of close may be very<br>      counterintuitive if the chosen distance function is not a valid metric.<br>      The distances "euclidean", "manhattan", "jaccard", and "levenshtein" will<br>      likely yield the best results.<br><br>    References<br>    ----------<br>    - Ester, M., et al. (1996) `A Density-Based Algorithm for Discovering<br>      Clusters in Large Spatial Databases with Noise<br>      <https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf`_. In Proceedings of the<br>      Second International Conference on Knowledge Discovery and Data Mining.<br>      pp. 226-231.<br><br>    - `Wikipedia - DBSCAN <https://en.wikipedia.org/wiki/DBSCAN`_<br><br>    - `Visualizing DBSCAN Clustering<br>      <http://www.naftaliharris.com/blog/visualizing-dbscan-clustering/`_<br><br>    Examples<br>    --------<br>     sf = turicreate.SFrame({<br>    ...     'x1': [0.6777, -9.391, 7.0385, 2.2657, 7.7864, -10.16, -8.162,<br>    ...            8.8817, -9.525, -9.153, 2.0860, 7.6619, 6.5511, 2.7020],<br>    ...     'x2': [5.6110, 8.5139, 5.3913, 5.4743, 8.3606, 7.8843, 2.7305,<br>    ...            5.1679, 6.7231, 3.7051, 1.7682, 7.4608, 3.1270, 6.5624]})<br>    ...<br>     model = turicreate.dbscan.create(sf, radius=4.25, min_core_neighbors=3)<br>     model.cluster_id.print_rows(15)<br>    +--------+------------+----------+<br>    | row_id | cluster_id |   type   |<br>    +--------+------------+----------+<br>    |   8    |     0      |   core   |<br>    |   7    |     2      |   core   |<br>    |   0    |     1      |   core   |<br>    |   2    |     2      |   core   |<br>    |   3    |     1      |   core   |<br>    |   11   |     2      |   core   |<br>    |   4    |     2      |   core   |<br>    |   1    |     0      | boundary |<br>    |   6    |     0      | boundary |<br>    |   5    |     0      | boundary |<br>    |   9    |     0      | boundary |<br>    |   12   |     2      | boundary |<br>    |   10   |     1      | boundary |<br>    |   13   |     1      | boundary |<br>    +--------+------------+----------+<br>    [14 rows x 3 columns]<br>    """<br><br>    ## Start the training time clock and instantiate an empty model<br>    logger = _logging.getLogger(__name__)<br>    start_time = _time.time()<br><br><br>    ## Validate the input dataset<br>    _tkutl._raise_error_if_not_sframe(dataset, "dataset")<br>    _tkutl._raise_error_if_sframe_empty(dataset, "dataset")<br><br><br>    ## Validate neighborhood parameters<br>    if not isinstance(min_core_neighbors, int) or min_core_neighbors < 0:<br>        raise ValueError("Input 'min_core_neighbors' must be a non-negative " +<br>                         "integer.")<br><br>    if not isinstance(radius, (int, float)) or radius < 0:<br>        raise ValueError("Input 'radius' must be a non-negative integer " +<br>                         "or float.")<br><br><br>    ## Compute all-point nearest neighbors within `radius` and count<br>    #  neighborhood sizes<br>    knn_model = _tc.nearest_neighbors.create(dataset, features=features,<br>                                             distance=distance,<br>                                             method='brute_force',<br>                                             verbose=verbose)<br><br>    knn = knn_model.similarity_graph(k=None, radius=radius,<br>                                     include_self_edges=False,<br>                                     output_type='SFrame',<br>                                     verbose=verbose)<br><br>    neighbor_counts = knn.groupby('query_label', _agg.COUNT)<br><br><br>    ### NOTE: points with NO neighbors are already dropped here!<br><br>    ## Identify core points and boundary candidate points. Not all of the<br>    #  boundary candidates will be boundary points - some are in small isolated<br>    #  clusters.<br>    if verbose:<br>        logger.info("Identifying noise points and core points.")<br><br>    boundary_mask = neighbor_counts['Count'] < min_core_neighbors<br>    core_mask = 1 - boundary_mask<br><br>    # this includes too small clusters<br>    boundary_idx = neighbor_counts[boundary_mask]['query_label']<br>    core_idx = neighbor_counts[core_mask]['query_label']<br><br><br>    ## Build a similarity graph on the core points<br>    ## NOTE: careful with singleton core points - the second filter removes them<br>    #  from the edge set so they have to be added separately as vertices.<br>    if verbose:<br>        logger.info("Constructing the core point similarity graph.")<br><br>    core_vertices = knn.filter_by(core_idx, 'query_label')<br>    core_edges = core_vertices.filter_by(core_idx, 'reference_label')<br><br>    core_graph = _tc.SGraph()<br>    core_graph = core_graph.add_vertices(core_vertices[['query_label']],<br>                                         vid_field='query_label')<br>    core_graph = core_graph.add_edges(core_edges, src_field='query_label',<br>                                      dst_field='reference_label')<br><br><br>    ## Compute core point connected components and relabel to be consecutive<br>    #  integers<br>    cc = _tc.connected_components.create(core_graph, verbose=verbose)<br>    cc_labels = cc.component_size.add_row_number('__label')<br>    core_assignments = cc.component_id.join(cc_labels, on='component_id',<br>                                               how='left')[['__id', '__label']]<br>    core_assignments['type'] = 'core'<br><br><br>    ## Join potential boundary points to core cluster labels (points that aren't<br>    #  really on a boundary are implicitly dropped)<br>    if verbose:<br>        logger.info("Processing boundary points.")<br><br>    boundary_edges = knn.filter_by(boundary_idx, 'query_label')<br><br>    # separate real boundary points from points in small isolated clusters<br>    boundary_core_edges = boundary_edges.filter_by(core_idx, 'reference_label')<br><br>    # join a boundary point to its single closest core point.<br>    boundary_assignments = boundary_core_edges.groupby('query_label',<br>                    {'reference_label': _agg.ARGMIN('rank', 'reference_label')})<br><br>    boundary_assignments = boundary_assignments.join(core_assignments,<br>                                                 on={'reference_label': '__id'})<br><br>    boundary_assignments = boundary_assignments.rename({'query_label': '__id'}, inplace=True)<br>    boundary_assignments = boundary_assignments.remove_column('reference_label', inplace=True)<br>    boundary_assignments['type'] = 'boundary'<br><br><br>    ## Identify boundary candidates that turned out to be in small clusters but<br>    #  not on real cluster boundaries<br>    small_cluster_idx = set(boundary_idx).difference(<br>                                                   boundary_assignments['__id'])<br><br><br>    ## Identify individual noise points by the fact that they have no neighbors.<br>    noise_idx = set(range(dataset.num_rows())).difference(<br>                                                 neighbor_counts['query_label'])<br><br>    noise_idx = noise_idx.union(small_cluster_idx)<br><br>    noise_assignments = _tc.SFrame({'row_id': _tc.SArray(list(noise_idx), int)})<br>    noise_assignments['cluster_id'] = None<br>    noise_assignments['cluster_id'] = noise_assignments['cluster_id'].astype(int)<br>    noise_assignments['type'] = 'noise'<br><br><br>    ## Append core, boundary, and noise results to each other.<br>    master_assignments = _tc.SFrame()<br>    num_clusters = 0<br><br>    if core_assignments.num_rows()  0:<br>        core_assignments = core_assignments.rename({'__id': 'row_id',<br>                                                    '__label': 'cluster_id'}, inplace=True)<br>        master_assignments = master_assignments.append(core_assignments)<br>        num_clusters = len(core_assignments['cluster_id'].unique())<br><br>    if boundary_assignments.num_rows()  0:<br>        boundary_assignments = boundary_assignments.rename({'__id': 'row_id',<br>                                                       '__label': 'cluster_id'}, inplace=True)<br>        master_assignments = master_assignments.append(boundary_assignments)<br><br>    if noise_assignments.num_rows()  0:<br>        master_assignments = master_assignments.append(noise_assignments)<br><br><br>    ## Post-processing and formatting<br>    state = {'verbose': verbose,<br>             'radius': radius,<br>             'min_core_neighbors': min_core_neighbors,<br>             'distance': knn_model.distance,<br>             'num_distance_components': knn_model.num_distance_components,<br>             'num_examples': dataset.num_rows(),<br>             'features': knn_model.features,<br>             'num_features': knn_model.num_features,<br>             'unpacked_features': knn_model.unpacked_features,<br>             'num_unpacked_features': knn_model.num_unpacked_features,<br>             'cluster_id': master_assignments,<br>             'num_clusters': num_clusters,<br>             'training_time': _time.time() - start_time}<br><br>    return DBSCANModel(state)

### DOC[4] (IRRELEVANT) leetcode/csn_python_train_144450.txt
> def ner_net(source, destinations, width, height, wrap_around=False, radius=10):<br>    """Produce a shortest path tree for a given net using NER.<br><br>    This is the kernel of the NER algorithm.<br><br>    Parameters<br>    ----------<br>    source : (x, y)<br>        The coordinate of the source vertex.<br>    destinations : iterable([(x, y), ...])<br>        The coordinates of destination vertices.<br>    width : int<br>        Width of the system (nodes)<br>    height : int<br>        Height of the system (nodes)<br>    wrap_around : bool<br>        True if wrap-around links should be used, false if they should be<br>        avoided.<br>    radius : int<br>        Radius of area to search from each node. 20 is arbitrarily selected in<br>        the paper and shown to be acceptable in practice.<br><br>    Returns<br>    -------<br>    (:py:class:`~.rig.place_and_route.routing_tree.RoutingTree`,<br>     {(x,y): :py:class:`~.rig.place_and_route.routing_tree.RoutingTree`, ...})<br>        A RoutingTree is produced rooted at the source and visiting all<br>        destinations but which does not contain any vertices etc. For<br>        convenience, a dictionarry mapping from destination (x, y) coordinates<br>        to the associated RoutingTree is provided to allow the caller to insert<br>        these items.<br>    """<br>    # Map from (x, y) to RoutingTree objects<br>    route = {source: RoutingTree(source)}<br><br>    # Handle each destination, sorted by distance from the source, closest<br>    # first.<br>    for destination in sorted(destinations,<br>                              key=(lambda destination:<br>                                   shortest_mesh_path_length(<br>                                       to_xyz(source), to_xyz(destination))<br>                                   if not wrap_around else<br>                                   shortest_torus_path_length(<br>                                       to_xyz(source), to_xyz(destination),<br>                                       width, height))):<br>        # We shall attempt to find our nearest neighbouring placed node.<br>        neighbour = None<br><br>        # Try to find a nearby (within radius hops) node in the routing tree<br>        # that we can route to (falling back on just routing to the source).<br>        #<br>        # In an implementation according to the algorithm's original<br>        # specification looks for nodes at each point in a growing set of rings<br>        # of concentric hexagons. If it doesn't find any destinations this<br>        # means an awful lot of checks: 1261 for the default radius of 20.<br>        #<br>        # An alternative (but behaviourally identical) implementation scans the<br>        # list of all route nodes created so far and finds the closest node<br>        # which is < radius hops (falling back on the origin if no node is<br>        # closer than radius hops).  This implementation requires one check per<br>        # existing route node. In most routes this is probably a lot less than<br>        # 1261 since most routes will probably have at most a few hundred route<br>        # nodes by the time the last destination is being routed.<br>        #<br>        # Which implementation is best is a difficult question to answer:<br>        #  In principle nets with quite localised connections (e.g.<br>        #   nearest-neighbour or centroids traffic) may route slightly more<br>        #   quickly with the original algorithm since it may very quickly find<br>        #   a neighbour.<br>        #  In nets which connect very spaced-out destinations the second<br>        #   implementation may be quicker since in such a scenario it is<br>        #   unlikely that a neighbour will be found.<br>        #  In extremely high-fan-out nets (e.g. broadcasts), the original<br>        #   method is very likely to perform far better than the alternative<br>        #   method since most iterations will complete immediately while the<br>        #   alternative method must scan all the route vertices.<br>        # As such, it should be clear that neither method alone is 'best' and<br>        # both have degenerate performance in certain completely reasonable<br>        # styles of net. As a result, a simple heuristic is used to decide<br>        # which technique to use.<br>        #<br>        # The following micro-benchmarks are crude estimate of the<br>        # runtime-per-iteration of each approach (at least in the case of a<br>        # torus topology)::<br>        #<br>        #     $ # Original approach<br>        #     $ python -m timeit --setup 'x, y, w, h, r = 1, 2, 5, 10, \<br>        #                                     {x:None for x in range(10)}' \<br>        #                        'x += 1; y += 1; x %= w; y %= h; (x, y) in r'<br>        #     1000000 loops, best of 3: 0.207 usec per loop<br>        #     $ # Alternative approach<br>        #     $ python -m timeit --setup 'from rig.geometry import \<br>        #                                 shortest_torus_path_length' \<br>        #                        'shortest_torus_path_length( \<br>        #                             (0, 1, 2), (3, 2, 1), 10, 10)'<br>        #     1000000 loops, best of 3: 0.666 usec per loop<br>        #<br>        # From this we can approximately suggest that the alternative approach<br>        # is 3x more expensive per iteration. A very crude heuristic is to use<br>        # the original approach when the number of route nodes is more than<br>        # 1/3rd of the number of routes checked by the original method.<br>        concentric_hexagons = memoized_concentric_hexagons(radius)<br>        if len(concentric_hexagons) < len(route) / 3:<br>            # Original approach: Start looking for route nodes in a concentric<br>            # spiral pattern out from the destination node.<br>            for x, y in concentric_hexagons:<br>                x += destination[0]<br>                y += destination[1]<br>                if wrap_around:<br>                    x %= width<br>                    y %= height<br>                if (x, y) in route:<br>                    neighbour = (x, y)<br>                    break<br>        else:<br>            # Alternative approach: Scan over every route node and check to see<br>            # if any are < radius, picking the closest one if so.<br>            neighbour = None<br>            neighbour_distance = None<br>            for candidate_neighbour in route:<br>                if wrap_around:<br>                    distance = shortest_torus_path_length(<br>                        to_xyz(candidate_neighbour), to_xyz(destination),<br>                        width, height)<br>                else:<br>                    distance = shortest_mesh_path_length(<br>                        to_xyz(candidate_neighbour), to_xyz(destination))<br><br>                if distance <= radius and (neighbour is None or<br>                                           distance < neighbour_distance):<br>                    neighbour = candidate_neighbour<br>                    neighbour_distance = distance<br><br>        # Fall back on routing directly to the source if no nodes within radius<br>        # hops of the destination was found.<br>        if neighbour is None:<br>            neighbour = source<br><br>        # Find the shortest vector from the neighbour to this destination<br>        if wrap_around:<br>            vector = shortest_torus_path(to_xyz(neighbour),<br>                                         to_xyz(destination),<br>                                         width, height)<br>        else:<br>            vector = shortest_mesh_path(to_xyz(neighbour), to_xyz(destination))<br><br>        # The longest-dimension-first route may inadvertently pass through an<br>        # already connected node. If the route is allowed to pass through that<br>        # node it would create a cycle in the route which would be VeryBad(TM).<br>        # As a result, we work backward through the route and truncate it at<br>        # the first point where the route intersects with a connected node.<br>        ldf = longest_dimension_first(vector, neighbour, width, height)<br>        i = len(ldf)<br>        for direction, (x, y) in reversed(ldf):<br>            i -= 1<br>            if (x, y) in route:<br>                # We've just bumped into a node which is already part of the<br>                # route, this becomes our new neighbour and we truncate the LDF<br>                # route. (Note ldf list is truncated just after the current<br>                # position since it gives (direction, destination) pairs).<br>                neighbour = (x, y)<br>                ldf = ldf[i + 1:]<br>                break<br><br>        # Take the longest dimension first route.<br>        last_node = route[neighbour]<br>        for direction, (x, y) in ldf:<br>            this_node = RoutingTree((x, y))<br>            route[(x, y)] = this_node<br><br>            last_node.children.append((Routes(direction), this_node))<br>            last_node = this_node<br><br>    return (route[source], route)

### DOC[5] (IRRELEVANT) leetcode/leetcode_1401.txt
> def checkOverlap(radius, xCenter, yCenter, x1, y1, x2, y2):<br>    """You are given a circle represented as `(radius, xCenter, yCenter)` and an axis-aligned rectangle represented as `(x1, y1, x2, y2)`, where `(x1, y1)` are the coordinates of the bottom-left corner, and `(x2, y2)` are the coordinates of the top-right corner of the rectangle.<br><br>Return `true` _if the circle and rectangle are overlapped otherwise return_ `false`. In other words, check if there is any point `(xi, yi)` that belongs to the circle and the rectangle at the same time.<br><br>Example 1:<br><br>Input: radius = 1, xCenter = 0, yCenter = 0, x1 = 1, y1 = -1, x2 = 3, y2 = 1<br>Output: true<br>Explanation: Circle and rectangle share the point (1,0).<br><br>Example 2:<br><br>Input: radius = 1, xCenter = 1, yCenter = 1, x1 = 1, y1 = -3, x2 = 2, y2 = -1<br>Output: false<br><br>Example 3:<br><br>Input: radius = 1, xCenter = 0, yCenter = 0, x1 = -1, y1 = 0, x2 = 0, y2 = 1<br>Output: true<br><br>Constraints:<br><br>   `1 <= radius <= 2000`<br>   `-104 <= xCenter, yCenter <= 104`<br>   `-104 <= x1 < x2 <= 104`<br>   `-104 <= y1 < y2 <= 104`"""<br><br>    xClosest = max(x1, min(xCenter, x2))<br>    yClosest = max(y1, min(yCenter, y2))<br>    return (xCenter - xClosest)  2 + (yCenter - yClosest)  2 <= radius  2


## Ground Truth

### GROUND TRUTH 0, ranked not in top 100, leetcode/leetcode_529.txt
> from typing import List<br>    """Let's play the minesweeper game ([Wikipedia](https://en.wikipedia.org/wiki/Minesweeper_(video_game)), [online game](http://minesweeperonline.com))!<br><br>You are given an `m x n` char matrix `board` representing the game board where:<br><br>   `'M'` represents an unrevealed mine,<br>   `'E'` represents an unrevealed empty square,<br>   `'B'` represents a revealed blank square that has no adjacent mines (i.e., above, below, left, right, and all 4 diagonals),<br>   digit (`'1'` to `'8'`) represents how many mines are adjacent to this revealed square, and<br>   `'X'` represents a revealed mine.<br><br>You are also given an integer array `click` where `click = [clickr, clickc]` represents the next click position among all the unrevealed squares (`'M'` or `'E'`).<br><br>Return _the board after revealing this position according to the following rules_:<br><br>1.  If a mine `'M'` is revealed, then the game is over. You should change it to `'X'`.<br>2.  If an empty square `'E'` with no adjacent mines is revealed, then change it to a revealed blank `'B'` and all of its adjacent unrevealed squares should be revealed recursively.<br>3.  If an empty square `'E'` with at least one adjacent mine is revealed, then change it to a digit (`'1'` to `'8'`) representing the number of adjacent mines.<br>4.  Return the board when no more squares will be revealed.<br><br>Example 1:<br><br>Input: board = \[\[ "E ", "E ", "E ", "E ", "E "\],\[ "E ", "E ", "M ", "E ", "E "\],\[ "E ", "E ", "E ", "E ", "E "\],\[ "E ", "E ", "E ", "E ", "E "\]\], click = \[3,0\]<br>Output: \[\[ "B ", "1 ", "E ", "1 ", "B "\],\[ "B ", "1 ", "M ", "1 ", "B "\],\[ "B ", "1 ", "1 ", "1 ", "B "\],\[ "B ", "B ", "B ", "B ", "B "\]\]<br><br>Example 2:<br><br>Input: board = \[\[ "B ", "1 ", "E ", "1 ", "B "\],\[ "B ", "1 ", "M ", "1 ", "B "\],\[ "B ", "1 ", "1 ", "1 ", "B "\],\[ "B ", "B ", "B ", "B ", "B "\]\], click = \[1,2\]<br>Output: \[\[ "B ", "1 ", "E ", "1 ", "B "\],\[ "B ", "1 ", "X ", "1 ", "B "\],\[ "B ", "1 ", "1 ", "1 ", "B "\],\[ "B ", "B ", "B ", "B ", "B "\]\]<br><br>Constraints:<br><br>   `m == board.length`<br>   `n == board[i].length`<br>   `1 <= m, n <= 50`<br>   `board[i][j]` is either `'M'`, `'E'`, `'B'`, or a digit from `'1'` to `'8'`.<br>   `click.length == 2`<br>   `0 <= clickr < m`<br>   `0 <= clickc < n`<br>   `board[clickr][clickc]` is either `'M'` or `'E'`."""<br><br><br>def reveal(board: List[List[str]], row: int, col: int, directions: List[List[int]]) - None:<br>    if row < 0 or row = len(board) or col < 0 or col = len(board[0]) or board[row][col] != 'E':<br>        return<br><br>    mines = 0<br>    for dir in directions:<br>        newRow, newCol = row + dir[0], col + dir[1]<br>        if newRow = 0 and newRow < len(board) and newCol = 0 and newCol < len(board[0]) and board[newRow][newCol] == 'M':<br>            mines += 1<br><br>    if mines  0:<br>        board[row][col] = str(mines)<br>    else:<br>        board[row][col] = 'B'<br>        for dir in directions:<br>            reveal(board, row + dir[0], col + dir[1], directions)<br><br>def updateBoard(board: List[List[str]], click: List[int]) - List[List[str]]:<br>    row, col = click<br><br>    if board[row][col] == 'M':<br>        board[row][col] = 'X'<br>    else:<br>        directions = [[1, 0], [1, -1], [0, -1], [-1, -1], [-1, 0], [-1, 1], [0, 1], [1, 1]]<br>        reveal(board, row, col, directions)<br><br>    return board

### GROUND TRUTH 1, ranked not in top 100, leetcode/leetcode_547.txt
> def findCircleNum(isConnected):<br>    """There are `n` cities. Some of them are connected, while some are not. If city `a` is connected directly with city `b`, and city `b` is connected directly with city `c`, then city `a` is connected indirectly with city `c`.<br><br>A province is a group of directly or indirectly connected cities and no other cities outside of the group.<br><br>You are given an `n x n` matrix `isConnected` where `isConnected[i][j] = 1` if the `ith` city and the `jth` city are directly connected, and `isConnected[i][j] = 0` otherwise.<br><br>Return _the total number of provinces_.<br><br>Example 1:<br><br>Input: isConnected = \[\[1,1,0\],\[1,1,0\],\[0,0,1\]\]<br>Output: 2<br><br>Example 2:<br><br>Input: isConnected = \[\[1,0,0\],\[0,1,0\],\[0,0,1\]\]<br>Output: 3<br><br>Constraints:<br><br>   `1 <= n <= 200`<br>   `n == isConnected.length`<br>   `n == isConnected[i].length`<br>   `isConnected[i][j]` is `1` or `0`.<br>   `isConnected[i][i] == 1`<br>   `isConnected[i][j] == isConnected[j][i]`"""<br><br>    def dfs(isConnected, visited, i):<br>        visited[i] = True<br>        for j in range(len(isConnected)):<br>            if isConnected[i][j] == 1 and not visited[j]:<br>                dfs(isConnected, visited, j)<br><br>    provinces = 0<br>    visited = [False]  len(isConnected)<br>    for i in range(len(isConnected)):<br>        if not visited[i]:<br>            dfs(isConnected, visited, i)<br>            provinces += 1<br>    return provinces

### GROUND TRUTH 2, ranked not in top 100, leetcode/leetcode_695.txt
> def maxAreaOfIsland(grid):<br>    """You are given an `m x n` binary matrix `grid`. An island is a group of `1`'s (representing land) connected 4-directionally (horizontal or vertical.) You may assume all four edges of the grid are surrounded by water.<br><br>The area of an island is the number of cells with a value `1` in the island.<br><br>Return _the maximum area of an island in_ `grid`. If there is no island, return `0`.<br><br>Example 1:<br><br>Input: grid = \[\[0,0,1,0,0,0,0,1,0,0,0,0,0\],\[0,0,0,0,0,0,0,1,1,1,0,0,0\],\[0,1,1,0,1,0,0,0,0,0,0,0,0\],\[0,1,0,0,1,1,0,0,1,0,1,0,0\],\[0,1,0,0,1,1,0,0,1,1,1,0,0\],\[0,0,0,0,0,0,0,0,0,0,1,0,0\],\[0,0,0,0,0,0,0,1,1,1,0,0,0\],\[0,0,0,0,0,0,0,1,1,0,0,0,0\]\]<br>Output: 6<br>Explanation: The answer is not 11, because the island must be connected 4-directionally.<br><br>Example 2:<br><br>Input: grid = \[\[0,0,0,0,0,0,0,0\]\]<br>Output: 0<br><br>Constraints:<br><br>   `m == grid.length`<br>   `n == grid[i].length`<br>   `1 <= m, n <= 50`<br>   `grid[i][j]` is either `0` or `1`."""<br><br>    def dfs(i, j):<br>        if i < 0 or i = len(grid) or j < 0 or j = len(grid[0]) or grid[i][j] == 0:<br>            return 0<br>        grid[i][j] = 0<br>        return 1 + dfs(i-1, j) + dfs(i+1, j) + dfs(i, j-1) + dfs(i, j+1)<br><br>    max_area = 0<br>    for i in range(len(grid)):<br>        for j in range(len(grid[0])):<br>            if grid[i][j]:<br>                max_area = max(max_area, dfs(i, j))<br>    return max_area

### GROUND TRUTH 3, ranked not in top 100, leetcode/leetcode_994.txt
> def prisonAfterNDays(cells, n):<br>    """You are given an `m x n` `grid` where each cell can have one of three values:<br><br>   `0` representing an empty cell,<br>   `1` representing a fresh orange, or<br>   `2` representing a rotten orange.<br><br>Every minute, any fresh orange that is 4-directionally adjacent to a rotten orange becomes rotten.<br><br>Return _the minimum number of minutes that must elapse until no cell has a fresh orange_. If _this is impossible, return_ `-1`.<br><br>Example 1:<br><br>Input: grid = \[\[2,1,1\],\[1,1,0\],\[0,1,1\]\]<br>Output: 4<br><br>Example 2:<br><br>Input: grid = \[\[2,1,1\],\[0,1,1\],\[1,0,1\]\]<br>Output: -1<br>Explanation: The orange in the bottom left corner (row 2, column 0) is never rotten, because rotting only happens 4-directionally.<br><br>Example 3:<br><br>Input: grid = \[\[0,2\]\]<br>Output: 0<br>Explanation: Since there are already no fresh oranges at minute 0, the answer is just 0.<br><br>Constraints:<br><br>   `m == grid.length`<br>   `n == grid[i].length`<br>   `1 <= m, n <= 10`<br>   `grid[i][j]` is `0`, `1`, or `2`."""<br><br>    n = n % 14 if n % 14 != 0 else 14 # Pattern repeats every 14 days<br><br>    for _ in range(n):<br>        temp = [0]  8<br>        for i in range(1, 7):<br>            temp[i] = int(cells[i - 1] == cells[i + 1])<br>        cells = temp<br><br>    return cells
