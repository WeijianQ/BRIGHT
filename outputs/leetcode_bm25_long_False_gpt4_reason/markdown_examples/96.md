# Query `96`

## Original Question

*A city is represented as a bi-directional connected graph with `n` vertices where each vertex is labeled from `1` to `n` (inclusive). The edges in the graph are represented as a 2D integer array `edges`, where each `edges[i] = [ui, vi]` denotes a bi-directional edge between vertex `ui` and vertex `vi`. Every vertex pair is connected by at most one edge, and no vertex has an edge to itself. The time taken to traverse any edge is `time` minutes.

Each vertex has a traffic signal which changes its color from green to red and vice versa every `change` minutes. All signals change at the same time. You can enter a vertex at any time, but can leave a vertex only when the signal is green. You cannot wait at a vertex if the signal is green.

The second minimum value is defined as the smallest value strictly larger than the minimum value.

   For example the second minimum value of `[2, 3, 4]` is `3`, and the second minimum value of `[2, 2, 4]` is `4`.

Given `n`, `edges`, `time`, and `change`, return _the second minimum time it will take to go from vertex_ `1` _to vertex_ `n`.

Notes:

   You can go through any vertex any number of times, including `1` and `n`.
   You can assume that when the journey starts, all signals have just turned green.

Example 1:

       

Input: n = 5, edges = \[\[1,2\],\[1,3\],\[1,4\],\[3,4\],\[4,5\]\], time = 3, change = 5
Output: 13
Explanation:
The figure on the left shows the given graph.
The blue path in the figure on the right is the minimum time path.
The time taken is:
- Start at 1, time elapsed=0
- 1 -> 4: 3 minutes, time elapsed=3
- 4 -> 5: 3 minutes, time elapsed=6
Hence the minimum time needed is 6 minutes.

The red path shows the path to get the second minimum time.
- Start at 1, time elapsed=0
- 1 -> 3: 3 minutes, time elapsed=3
- 3 -> 4: 3 minutes, time elapsed=6
- Wait at 4 for 4 minutes, time elapsed=10
- 4 -> 5: 3 minutes, time elapsed=13
Hence the second minimum time is 13 minutes.      

Example 2:

Input: n = 2, edges = \[\[1,2\]\], time = 3, change = 2
Output: 11
Explanation:
The minimum time path is 1 -> 2 with time = 3 minutes.
The second minimum time path is 1 -> 2 -> 1 -> 2 with time = 11 minutes.

Constraints:

   `2 <= n <= 104`
   `n - 1 <= edges.length <= min(2  104, n  (n - 1) / 2)`
   `edges[i].length == 2`
   `1 <= ui, vi <= n`
   `ui != vi`
   There are no duplicate edges.
   Each vertex can be reached directly or indirectly from every other vertex.
   `1 <= time, change <= 103`*

## gpt4 Reasoning

```markdown
The essential problem here is to calculate the second minimum time required to travel from vertex 1 to vertex n in a bi-directional connected graph, considering the constraints of traffic signals at each vertex. To address this, we need to understand the mechanics of signal changes, travel time between vertices, and the structure of the graph. Here’s a detailed step-by-step reasoning and information that could be relevant to solve this problem:

### 1. Graph Representation and Path Finding
- **Graph Representation:** The graph is bi-directional and connected, meaning there's a way to reach every vertex from any other vertex. This also implies the existence of cycles which could be leveraged for finding alternative paths (second minimum time).
- **Shortest Path Algorithm:** A modification of Dijkstra's algorithm or Breadth-First Search (BFS) could be used to find the shortest and the second shortest paths from vertex 1 to vertex n. We must account for the waiting time at each vertex due to signal changes.

### 2. Signal Timing Mechanics
- **Signal Cycle:** The traffic signal at each vertex changes from green to red and vice versa every `change` minutes. This affects when a vertex can be left.
- **Waiting Time Calculation:** To decide whether to wait at a vertex or not, we need to calculate the elapsed time upon arrival at each vertex and compare it against the signal cycle (`change` minutes).

### 3. Path Time Calculation
- **Travel Time:** The time taken to traverse any edge is `time` minutes.
- **Total Time:** For any path, the total time is the sum of the traversal times of the edges plus any waiting time at the vertices due to red signals.

### 4. Finding the Second Minimum Time
- **Minimum Time Path:** Initially, we find the shortest path from vertex 1 to vertex n, considering the signal timings.
- **Second Minimum Time Path:** To find the second minimum time, we need to explore paths that are longer than the shortest path by at least one edge or include waiting times due to signal changes. This could involve:
  - Taking a longer route that has more edges.
  - Revisiting some vertices to introduce a deliberate delay while ensuring the total path length is the second shortest.
  
### 5. Edge Cases and Constraints
- **Direct Path:** In the case of a graph with only two vertices (1 and 2), the second minimum time would involve traversing the edge multiple times to satisfy the condition of being strictly larger than the minimum time.
- **Signal Synchronization:** Since all signals change at the same time, their state (green or red) can be determined by the total elapsed time since the start.

### Solution Approach
1. **Model the Graph:** Use adjacency lists to represent the graph for efficient traversal.
2. **Implement Path Finding with Signal Timing:** Modify a shortest path algorithm to account for signal timing at each vertex.
3. **Track Paths and Times:** While finding paths, track both the minimum and second minimum times. This might involve maintaining a structure to store the best and second-best times to reach each vertex.
4. **Optimize for Second Minimum:** After identifying the minimum time path, focus on paths that could potentially yield the second minimum time, considering revisits or longer paths that are feasible within the constraints.

### Conclusion
To solve this problem, we need a nuanced approach that combines graph traversal algorithms with additional logic to handle the unique constraints of signal timings. By carefully modeling the problem and iteratively refining the approach to track and compare path times, it's possible to calculate the second minimum time required to travel from vertex 1 to vertex n.
```

### Metrics

```
recip_rank: 0.1667
P_1: 0.0000
P_5: 0.0000
P_10: 0.1000
P_25: 0.0400
P_50: 0.0200
P_100: 0.0200
recall_1: 0.0000
recall_5: 0.0000
recall_10: 0.3333
recall_25: 0.3333
recall_50: 0.3333
recall_100: 0.6667
ndcg_cut_1: 0.0000
ndcg_cut_5: 0.0000
ndcg_cut_10: 0.1672
ndcg_cut_25: 0.1672
ndcg_cut_50: 0.1672
ndcg_cut_100: 0.2495
map_cut_1: 0.0000
map_cut_5: 0.0000
map_cut_10: 0.0556
map_cut_25: 0.0556
map_cut_50: 0.0556
map_cut_100: 0.0686
```

## Retrieval Results

### DOC[1] (IRRELEVANT) leetcode/csn_python_train_314887.txt
> def min_vertex_coloring(G, sampler=None, sampler_args):<br>    """Returns an approximate minimum vertex coloring.<br><br>    Vertex coloring is the problem of assigning a color to the<br>    vertices of a graph in a way that no adjacent vertices have the<br>    same color. A minimum vertex coloring is the problem of solving<br>    the vertex coloring problem using the smallest number of colors.<br><br>    Since neighboring vertices must satisfy a constraint of having<br>    different colors, the problem can be posed as a binary constraint<br>    satisfaction problem.<br><br>    Defines a QUBO with ground states corresponding to minimum<br>    vertex colorings and uses the sampler to sample from it.<br><br>    Parameters<br>    ----------<br>    G : NetworkX graph<br>        The graph on which to find a minimum vertex coloring.<br><br>    sampler<br>        A binary quadratic model sampler. A sampler is a process that<br>        samples from low energy states in models defined by an Ising<br>        equation or a Quadratic Unconstrained Binary Optimization<br>        Problem (QUBO). A sampler is expected to have a 'sample_qubo'<br>        and 'sample_ising' method. A sampler is expected to return an<br>        iterable of samples, in order of increasing energy. If no<br>        sampler is provided, one must be provided using the<br>        `set_default_sampler` function.<br><br>    sampler_args<br>        Additional keyword parameters are passed to the sampler.<br><br>    Returns<br>    -------<br>    coloring : dict<br>        A coloring for each vertex in G such that no adjacent nodes<br>        share the same color. A dict of the form {node: color, ...}<br><br>    Example<br>    -------<br>    This example colors a single Chimera unit cell. It colors the four<br>    horizontal qubits one color (0) and the four vertical qubits another (1).<br><br>     # Set up a sampler; this example uses a sampler from dimod https://github.com/dwavesystems/dimod<br>     import dimod<br>     import dwave_networkx as dnx<br>     samplerSA = dimod.SimulatedAnnealingSampler()<br>     # Create a graph and color it<br>     G = dnx.chimera_graph(1, 1, 4)<br>     colors = dnx.min_vertex_coloring(G, sampler=samplerSA)<br>     colors<br>    {0: 0, 1: 0, 2: 0, 3: 0, 4: 1, 5: 1, 6: 1, 7: 1}<br><br>    References<br>    ----------<br>    .. [DWMP] Dahl, E., "Programming the D-Wave: Map Coloring Problem",<br>       https://www.dwavesys.com/sites/default/files/Map%20Coloring%20WP2.pdf<br><br>    Notes<br>    -----<br>    Samplers by their nature may not return the optimal solution. This<br>    function does not attempt to confirm the quality of the returned<br>    sample.<br><br>    """<br><br>    # if the given graph is not connected, apply the function to each connected component<br>    # seperately.<br>    if not nx.is_connected(G):<br>        coloring = {}<br>        for subG in (G.subgraph(c).copy() for c in nx.connected_components(G)):<br>            sub_coloring = min_vertex_coloring(subG, sampler, sampler_args)<br>            coloring.update(sub_coloring)<br>        return coloring<br><br>    n_nodes = len(G)  # number of nodes<br>    n_edges = len(G.edges)  # number of edges<br><br>    # ok, first up, we can eliminate a few graph types trivially<br><br>    # Graphs with no edges, have chromatic number 1<br>    if not n_edges:<br>        return {node: 0 for node in G}<br><br>    # Complete graphs have chromatic number N<br>    if n_edges == n_nodes  (n_nodes - 1) // 2:<br>        return {node: color for color, node in enumerate(G)}<br><br>    # The number of variables in the QUBO is approximately the number of nodes in the graph<br>    # times the number of potential colors, so we want as tight an upper bound on the<br>    # chromatic number (chi) as possible<br>    chi_ub = _chromatic_number_upper_bound(G, n_nodes, n_edges)<br><br>    # now we can start coloring. Without loss of generality, we can determine some of<br>    # the node colors before trying to solve.<br>    partial_coloring, possible_colors, chi_lb = _partial_precolor(G, chi_ub)<br><br>    # ok, to get the rest of the coloring, we need to start building the QUBO. We do this<br>    # by assigning a variable x_v_c for each node v and color c. This variable will be 1<br>    # when node v is colored c, and 0 otherwise.<br><br>    # let's assign an index to each of the variables<br>    counter = itertools.count()<br>    x_vars = {v: {c: next(counter) for c in possible_colors[v]} for v in possible_colors}<br><br>    # now we have three different constraints we wish to add.<br><br>    # the first constraint enforces the coloring rule, that for each pair of vertices<br>    # u, v that share an edge, they should be different colors<br>    Q_neighbor = _vertex_different_colors_qubo(G, x_vars)<br><br>    # the second constraint enforces that each vertex has a single color assigned<br>    Q_vertex = _vertex_one_color_qubo(x_vars)<br><br>    # the third constraint is that we want a minimum vertex coloring, so we want to<br>    # disincentivize the colors we might not need.<br>    Q_min_color = _minimum_coloring_qubo(x_vars, chi_lb, chi_ub, magnitude=.75)<br><br>    # combine all three constraints<br>    Q = Q_neighbor<br>    for (u, v), bias in iteritems(Q_vertex):<br>        if (u, v) in Q:<br>            Q[(u, v)] += bias<br>        elif (v, u) in Q:<br>            Q[(v, u)] += bias<br>        else:<br>            Q[(u, v)] = bias<br>    for (v, v), bias in iteritems(Q_min_color):<br>        if (v, v) in Q:<br>            Q[(v, v)] += bias<br>        else:<br>            Q[(v, v)] = bias<br><br>    # use the sampler to find low energy states<br>    response = sampler.sample_qubo(Q, sampler_args)<br><br>    # we want the lowest energy sample<br>    sample = next(iter(response))<br><br>    # read off the coloring<br>    for v in x_vars:<br>        for c in x_vars[v]:<br>            if sample[x_vars[v][c]]:<br>                partial_coloring[v] = c<br><br>    return partial_coloring

### DOC[2] (IRRELEVANT) leetcode/csn_python_train_314836.txt
> def traveling_salesman(G, sampler=None, lagrange=2, weight='weight',<br>                       sampler_args):<br>    """Returns an approximate minimum traveling salesperson route.<br><br>    Defines a QUBO with ground states corresponding to the<br>    minimum routes and uses the sampler to sample<br>    from it.<br><br>    A route is a cycle in the graph that reaches each node exactly once.<br>    A minimum route is a route with the smallest total edge weight.<br><br>    Parameters<br>    ----------<br>    G : NetworkX graph<br>        The graph on which to find a minimum traveling salesperson route.<br>        This should be a complete graph with non-zero weights on every edge.<br><br>    sampler :<br>        A binary quadratic model sampler. A sampler is a process that<br>        samples from low energy states in models defined by an Ising<br>        equation or a Quadratic Unconstrained Binary Optimization<br>        Problem (QUBO). A sampler is expected to have a 'sample_qubo'<br>        and 'sample_ising' method. A sampler is expected to return an<br>        iterable of samples, in order of increasing energy. If no<br>        sampler is provided, one must be provided using the<br>        `set_default_sampler` function.<br><br>    lagrange : optional (default 2)<br>        Lagrange parameter to weight constraints (visit every city once)<br>        versus objective (shortest distance route).<br><br>    weight : optional (default 'weight')<br>        The name of the edge attribute containing the weight.<br><br>    sampler_args :<br>        Additional keyword parameters are passed to the sampler.<br><br>    Returns<br>    -------<br>    route : list<br>       List of nodes in order to be visited on a route<br><br>    Examples<br>    --------<br>    This example uses a `dimod <https://github.com/dwavesystems/dimod`_ sampler<br>    to find a minimum route in a five-cities problem.<br><br>     import dwave_networkx as dnx<br>     import networkx as nx<br>     import dimod<br>    ...<br>     G = nx.complete_graph(4)<br>     G.add_weighted_edges_from({(0, 1, 1), (0, 2, 2), (0, 3, 3), (1, 2, 3),<br>    ...                            (1, 3, 4), (2, 3, 5)})<br>     dnx.traveling_salesman(G, dimod.ExactSolver())<br>    [2, 1, 0, 3]<br><br>    Notes<br>    -----<br>    Samplers by their nature may not return the optimal solution. This<br>    function does not attempt to confirm the quality of the returned<br>    sample.<br><br>    """<br>    # Get a QUBO representation of the problem<br>    Q = traveling_salesman_qubo(G, lagrange, weight)<br><br>    # use the sampler to find low energy states<br>    response = sampler.sample_qubo(Q, sampler_args)<br><br>    # we want the lowest energy sample, in order by stop number<br>    sample = next(iter(response))<br>    route = []<br>    for entry in sample:<br>        if sample[entry]  0:<br>            route.append(entry)<br>    route.sort(key=lambda x: x[1])<br>    return list((x[0] for x in route))

### DOC[3] (IRRELEVANT) leetcode/csn_python_train_144450.txt
> def ner_net(source, destinations, width, height, wrap_around=False, radius=10):<br>    """Produce a shortest path tree for a given net using NER.<br><br>    This is the kernel of the NER algorithm.<br><br>    Parameters<br>    ----------<br>    source : (x, y)<br>        The coordinate of the source vertex.<br>    destinations : iterable([(x, y), ...])<br>        The coordinates of destination vertices.<br>    width : int<br>        Width of the system (nodes)<br>    height : int<br>        Height of the system (nodes)<br>    wrap_around : bool<br>        True if wrap-around links should be used, false if they should be<br>        avoided.<br>    radius : int<br>        Radius of area to search from each node. 20 is arbitrarily selected in<br>        the paper and shown to be acceptable in practice.<br><br>    Returns<br>    -------<br>    (:py:class:`~.rig.place_and_route.routing_tree.RoutingTree`,<br>     {(x,y): :py:class:`~.rig.place_and_route.routing_tree.RoutingTree`, ...})<br>        A RoutingTree is produced rooted at the source and visiting all<br>        destinations but which does not contain any vertices etc. For<br>        convenience, a dictionarry mapping from destination (x, y) coordinates<br>        to the associated RoutingTree is provided to allow the caller to insert<br>        these items.<br>    """<br>    # Map from (x, y) to RoutingTree objects<br>    route = {source: RoutingTree(source)}<br><br>    # Handle each destination, sorted by distance from the source, closest<br>    # first.<br>    for destination in sorted(destinations,<br>                              key=(lambda destination:<br>                                   shortest_mesh_path_length(<br>                                       to_xyz(source), to_xyz(destination))<br>                                   if not wrap_around else<br>                                   shortest_torus_path_length(<br>                                       to_xyz(source), to_xyz(destination),<br>                                       width, height))):<br>        # We shall attempt to find our nearest neighbouring placed node.<br>        neighbour = None<br><br>        # Try to find a nearby (within radius hops) node in the routing tree<br>        # that we can route to (falling back on just routing to the source).<br>        #<br>        # In an implementation according to the algorithm's original<br>        # specification looks for nodes at each point in a growing set of rings<br>        # of concentric hexagons. If it doesn't find any destinations this<br>        # means an awful lot of checks: 1261 for the default radius of 20.<br>        #<br>        # An alternative (but behaviourally identical) implementation scans the<br>        # list of all route nodes created so far and finds the closest node<br>        # which is < radius hops (falling back on the origin if no node is<br>        # closer than radius hops).  This implementation requires one check per<br>        # existing route node. In most routes this is probably a lot less than<br>        # 1261 since most routes will probably have at most a few hundred route<br>        # nodes by the time the last destination is being routed.<br>        #<br>        # Which implementation is best is a difficult question to answer:<br>        #  In principle nets with quite localised connections (e.g.<br>        #   nearest-neighbour or centroids traffic) may route slightly more<br>        #   quickly with the original algorithm since it may very quickly find<br>        #   a neighbour.<br>        #  In nets which connect very spaced-out destinations the second<br>        #   implementation may be quicker since in such a scenario it is<br>        #   unlikely that a neighbour will be found.<br>        #  In extremely high-fan-out nets (e.g. broadcasts), the original<br>        #   method is very likely to perform far better than the alternative<br>        #   method since most iterations will complete immediately while the<br>        #   alternative method must scan all the route vertices.<br>        # As such, it should be clear that neither method alone is 'best' and<br>        # both have degenerate performance in certain completely reasonable<br>        # styles of net. As a result, a simple heuristic is used to decide<br>        # which technique to use.<br>        #<br>        # The following micro-benchmarks are crude estimate of the<br>        # runtime-per-iteration of each approach (at least in the case of a<br>        # torus topology)::<br>        #<br>        #     $ # Original approach<br>        #     $ python -m timeit --setup 'x, y, w, h, r = 1, 2, 5, 10, \<br>        #                                     {x:None for x in range(10)}' \<br>        #                        'x += 1; y += 1; x %= w; y %= h; (x, y) in r'<br>        #     1000000 loops, best of 3: 0.207 usec per loop<br>        #     $ # Alternative approach<br>        #     $ python -m timeit --setup 'from rig.geometry import \<br>        #                                 shortest_torus_path_length' \<br>        #                        'shortest_torus_path_length( \<br>        #                             (0, 1, 2), (3, 2, 1), 10, 10)'<br>        #     1000000 loops, best of 3: 0.666 usec per loop<br>        #<br>        # From this we can approximately suggest that the alternative approach<br>        # is 3x more expensive per iteration. A very crude heuristic is to use<br>        # the original approach when the number of route nodes is more than<br>        # 1/3rd of the number of routes checked by the original method.<br>        concentric_hexagons = memoized_concentric_hexagons(radius)<br>        if len(concentric_hexagons) < len(route) / 3:<br>            # Original approach: Start looking for route nodes in a concentric<br>            # spiral pattern out from the destination node.<br>            for x, y in concentric_hexagons:<br>                x += destination[0]<br>                y += destination[1]<br>                if wrap_around:<br>                    x %= width<br>                    y %= height<br>                if (x, y) in route:<br>                    neighbour = (x, y)<br>                    break<br>        else:<br>            # Alternative approach: Scan over every route node and check to see<br>            # if any are < radius, picking the closest one if so.<br>            neighbour = None<br>            neighbour_distance = None<br>            for candidate_neighbour in route:<br>                if wrap_around:<br>                    distance = shortest_torus_path_length(<br>                        to_xyz(candidate_neighbour), to_xyz(destination),<br>                        width, height)<br>                else:<br>                    distance = shortest_mesh_path_length(<br>                        to_xyz(candidate_neighbour), to_xyz(destination))<br><br>                if distance <= radius and (neighbour is None or<br>                                           distance < neighbour_distance):<br>                    neighbour = candidate_neighbour<br>                    neighbour_distance = distance<br><br>        # Fall back on routing directly to the source if no nodes within radius<br>        # hops of the destination was found.<br>        if neighbour is None:<br>            neighbour = source<br><br>        # Find the shortest vector from the neighbour to this destination<br>        if wrap_around:<br>            vector = shortest_torus_path(to_xyz(neighbour),<br>                                         to_xyz(destination),<br>                                         width, height)<br>        else:<br>            vector = shortest_mesh_path(to_xyz(neighbour), to_xyz(destination))<br><br>        # The longest-dimension-first route may inadvertently pass through an<br>        # already connected node. If the route is allowed to pass through that<br>        # node it would create a cycle in the route which would be VeryBad(TM).<br>        # As a result, we work backward through the route and truncate it at<br>        # the first point where the route intersects with a connected node.<br>        ldf = longest_dimension_first(vector, neighbour, width, height)<br>        i = len(ldf)<br>        for direction, (x, y) in reversed(ldf):<br>            i -= 1<br>            if (x, y) in route:<br>                # We've just bumped into a node which is already part of the<br>                # route, this becomes our new neighbour and we truncate the LDF<br>                # route. (Note ldf list is truncated just after the current<br>                # position since it gives (direction, destination) pairs).<br>                neighbour = (x, y)<br>                ldf = ldf[i + 1:]<br>                break<br><br>        # Take the longest dimension first route.<br>        last_node = route[neighbour]<br>        for direction, (x, y) in ldf:<br>            this_node = RoutingTree((x, y))<br>            route[(x, y)] = this_node<br><br>            last_node.children.append((Routes(direction), this_node))<br>            last_node = this_node<br><br>    return (route[source], route)

### DOC[4] (IRRELEVANT) leetcode/csn_python_train_144360.txt
> def place(vertices_resources, nets, machine, constraints,<br>          effort=1.0, random=default_random, on_temperature_change=None,<br>          kernel=default_kernel, kernel_kwargs={}):<br>    """A flat Simulated Annealing based placement algorithm.<br><br>    This placement algorithm uses simulated annealing directly on the supplied<br>    problem graph with the objective of reducing wire lengths (and thus,<br>    indirectly, the potential for congestion). Though computationally<br>    expensive, this placer produces relatively good placement solutions.<br><br>    The annealing temperature schedule used by this algorithm is taken from<br>    "VPR: A New Packing, Placement and Routing Tool for FPGA Research" by<br>    Vaughn Betz and Jonathan Rose from the "1997 International Workshop on<br>    Field Programmable Logic and Applications".<br><br>    Two implementations of the algorithm's kernel are available:<br><br>     :py:class:`~rig.place_and_route.place.sa.python_kernel.PythonKernel` A<br>      pure Python implementation which is available on all platforms supported<br>      by Rig.<br>     :py:class:`~rig.place_and_route.place.sa.c_kernel.CKernel` A C<br>      implementation which is typically 50-150x faster than the basic Python<br>      kernel. Since this implementation requires a C compiler during<br>      installation, it is an optional feature of Rig. See the<br>      :py:class:`CKernel's documentation<br>      <rig.place_and_route.place.sa.c_kernel.CKernel` for details.<br><br>    The fastest kernel installed is used by default and can be manually chosen<br>    using the ``kernel`` argument.<br><br>    This algorithm produces INFO level logging information describing the<br>    progress made by the algorithm.<br><br>    .. warning:<br>        This algorithm does not attempt to produce good solutions to the<br>        bin-packing problem of optimally fitting vertices into chips and it may<br>        fail if a good placement requires good bin packing.<br><br>    Parameters<br>    ----------<br>    effort : float<br>        A scaling factor for the number of iterations the algorithm should run<br>        for. 1.0 is probably about as low as you'll want to go in practice and<br>        runtime increases linearly as you increase this parameter.<br>    random : :py:class:`random.Random`<br>        A Python random number generator. Defaults to ``import random`` but can<br>        be set to your own instance of :py:class:`random.Random` to allow you<br>        to control the seed and produce deterministic results. For results to<br>        be deterministic, vertices_resources must be supplied as an<br>        :py:class:`collections.OrderedDict`.<br>    on_temperature_change : callback_function or None<br>        An (optional) callback function which is called every time the<br>        temperature is changed. This callback can be used to provide status<br>        updates<br><br>        The callback function is passed the following arguments:<br><br>         ``iteration_count``: the number of iterations the placer has<br>          attempted (integer)<br>         ``placements``: The current placement solution.<br>         ``cost``: the weighted sum over all nets of bounding-box size.<br>          (float)<br>         ``acceptance_rate``: the proportion of iterations which have resulted<br>          in an accepted change since the last callback call. (float between<br>          0.0 and 1.0)<br>         ``temperature``: The current annealing temperature. (float)<br>         ``distance_limit``: The maximum distance any swap may be made over.<br>          (integer)<br><br>        If the callback returns False, the anneal is terminated immediately and<br>        the current solution is returned.<br>    kernel : :py:class:`~rig.place_and_route.place.sa.kernel.Kernel`<br>        A simulated annealing placement kernel. A sensible default will be<br>        chosen based on the available kernels on this machine. The kernel may<br>        not be used if the placement problem has a trivial solution.<br>    kernel_kwargs : dict<br>        Optional kernel-specific keyword arguments to pass to the kernel<br>        constructor.<br>    """<br>    # Special case: just return immediately when there's nothing to place<br>    if len(vertices_resources) == 0:<br>        return {}<br><br>    # Within the algorithm we modify the resource availability values in the<br>    # machine to account for the effects of the current placement. As a result,<br>    # an internal copy of the structure must be made.<br>    machine = machine.copy()<br><br>    # {vertex: (x, y), ...} gives the location of all vertices whose position<br>    # is fixed by a LocationConstraint.<br>    fixed_vertices = {}<br><br>    # Handle constraints<br>    vertices_resources, nets, constraints, substitutions = \<br>        apply_same_chip_constraints(vertices_resources, nets, constraints)<br>    for constraint in constraints:<br>        if isinstance(constraint, LocationConstraint):<br>            # Location constraints are handled by recording the set of fixed<br>            # vertex locations and subtracting their resources from the chips<br>            # they're allocated to. These vertices will then not be added to<br>            # the internal placement data structure to prevent annealing from<br>            # moving them. They will be re-introduced at the last possible<br>            # moment.<br>            location = constraint.location<br>            if location not in machine:<br>                raise InvalidConstraintError(<br>                    "Chip requested by {} unavailable".format(machine))<br>            vertex = constraint.vertex<br><br>            # Record the constrained vertex's location<br>            fixed_vertices[vertex] = location<br><br>            # Make sure the vertex fits at the requested location (updating the<br>            # resource availability after placement)<br>            resources = vertices_resources[vertex]<br>            machine[location] = subtract_resources(machine[location],<br>                                                   resources)<br>            if overallocated(machine[location]):<br>                raise InsufficientResourceError(<br>                    "Cannot meet {}".format(constraint))<br>        elif isinstance(constraint,  # pragma: no branch<br>                        ReserveResourceConstraint):<br>            apply_reserve_resource_constraint(machine, constraint)<br><br>    # Initially randomly place the movable vertices<br>    movable_vertices = {v for v in vertices_resources<br>                        if v not in fixed_vertices}<br>    initial_placements = _initial_placement(movable_vertices,<br>                                            vertices_resources,<br>                                            machine, random)<br><br>    # Include the fixed vertices in initial placement<br>    initial_placements.update(fixed_vertices)<br><br>    # Filter out empty or singleton nets and those weighted as zero since they<br>    # cannot influence placement.<br>    nets = [n for n in nets if len(set(n))  1 and n.weight  0.0]<br><br>    # Special cases where no placement effort is required:<br>    #  There is only one chip<br>    #  There are no resource types to be consumed<br>    #  No effort is to be made<br>    #  No movable vertices<br>    #  There are no nets (and moving things has no effect)<br>    trivial = ((machine.width, machine.height) == (1, 1) or<br>               len(machine.chip_resources) == 0 or<br>               effort == 0.0 or<br>               len(movable_vertices) == 0 or<br>               len(nets) == 0)<br>    if trivial:<br>        logger.info("Placement has trivial solution. SA not used.")<br>        finalise_same_chip_constraints(substitutions, initial_placements)<br>        return initial_placements<br><br>    # Intialise the algorithm kernel<br>    k = kernel(vertices_resources, movable_vertices, set(fixed_vertices),<br>               initial_placements, nets, machine, random, kernel_kwargs)<br><br>    logger.info("SA placement kernel: %s", kernel.__name__)<br><br>    # Specifies the maximum distance any swap can span. Initially consider<br>    # swaps that span the entire machine.<br>    distance_limit = max(machine.width, machine.height)<br><br>    # Determine initial temperature according to the heuristic used by VPR: 20<br>    # times the standard deviation of len(movable_vertices) random swap costs.<br>    # The arbitrary very-high temperature is used to cause "all" swaps to be<br>    # accepted.<br>    _0, _1, cost_delta_sd = k.run_steps(len(movable_vertices),<br>                                        distance_limit,<br>                                        1e100)<br>    temperature = 20.0  cost_delta_sd<br><br>    # The number of swap-attempts between temperature changes is selected by<br>    # the heuristic used by VPR. This value is scaled linearly by the effort<br>    # parameter.<br>    num_steps = max(1, int(effort  len(vertices_resources)1.33))<br><br>    logger.info("Initial placement temperature: %0.1f", temperature)<br><br>    # Counter for the number of swap attempts made (used for diagnostic<br>    # purposes)<br>    iteration_count = 0<br><br>    # Holds the total cost of the current placement. This default value chosen<br>    # to ensure the loop below iterates at least once.<br>    current_cost = 0.0<br><br>    # The annealing algorithm runs until a heuristic termination condition<br>    # (taken from VPR) is hit. The heuristic waits until the temperature falls<br>    # below a small fraction of the average net cost.<br>    while temperature  (0.005  current_cost) / len(nets):<br>        # Run an iteration at the current temperature<br>        num_accepted, current_cost, _ = k.run_steps(<br>            num_steps, int(math.ceil(distance_limit)), temperature)<br><br>        # The ratio of accepted-to-not-accepted changes<br>        r_accept = num_accepted / float(num_steps)<br><br>        # Special case: Can't do better than 0 cost! This is a special case<br>        # since the normal termination condition will not terminate if the cost<br>        # doesn't drop below 0.<br>        if current_cost == 0:<br>            break<br><br>        # The temperature is reduced by a factor heuristically based on the<br>        # acceptance rate. The schedule below attempts to maximise the time<br>        # spent at temperatures where a large portion (but not all) of changes<br>        # are being accepted. If lots of changes are being accepted (e.g.<br>        # during high-temperature periods) then most of them are likely not to<br>        # be beneficial. If few changes are being accepted, we're probably<br>        # pretty close to the optimal placement.<br>        if r_accept  0.96:<br>            alpha = 0.5<br>        elif r_accept  0.8:<br>            alpha = 0.9<br>        elif r_accept  0.15:<br>            alpha = 0.95<br>        else:<br>            alpha = 0.8<br>        temperature = alpha  temperature<br><br>        # According to:<br>        #  M. Huang, F. Romeo, and A. Sangiovanni-Vincentelli, "An Efficient<br>        #   General Cooling Schedule for Simulated Annealing" ICCAD, 1986, pp.<br>        #   381 - 384 and J. Lam<br>        #  J. Delosme, "Performance of a New Annealing Schedule" DAC, 1988,<br>        #   pp. 306 - 311.<br>        # It is desirable to keep the acceptance ratio as close to 0.44 for as<br>        # long as possible. As a result, when r_accept falls below this we can<br>        # help increase the acceptance rate by reducing the set of possible<br>        # swap candidates based on the observation that near the end of<br>        # placement, most things are near their optimal location and thus long<br>        # distance swaps are unlikely to be useful.<br>        distance_limit = 1.0 - 0.44 + r_accept<br>        distance_limit = min(max(distance_limit, 1.0),<br>                             max(machine.width, machine.height))<br><br>        iteration_count += num_steps<br>        logger.debug("Iteration: %d, "<br>                     "Cost: %0.1f, "<br>                     "Kept: %0.1f%%, "<br>                     "Temp: %0.3f, "<br>                     "Dist: %d.",<br>                     iteration_count, current_cost,<br>                     r_accept100, temperature, math.ceil(distance_limit))<br><br>        # Call the user callback before the next iteration, terminating if<br>        # requested.<br>        if on_temperature_change is not None:<br>            placements = k.get_placements().copy()<br>            finalise_same_chip_constraints(substitutions, placements)<br>            ret_val = on_temperature_change(iteration_count,<br>                                            placements,<br>                                            current_cost,<br>                                            r_accept,<br>                                            temperature,<br>                                            distance_limit)<br>            if ret_val is False:<br>                break<br><br>    logger.info("Anneal terminated after %d iterations.", iteration_count)<br><br>    placements = k.get_placements()<br>    finalise_same_chip_constraints(substitutions, placements)<br><br>    return placements

### DOC[5] (IRRELEVANT) leetcode/csn_python_train_333992.txt
> def canonical_order(self):<br>        """The vertices in a canonical or normalized order.<br><br>           This routine will return a list of vertices in an order that does not<br>           depend on the initial order, but only depends on the connectivity and<br>           the return values of the function self.get_vertex_string.<br><br>           Only the vertices that are involved in edges will be included. The<br>           result can be given as first argument to self.get_subgraph, with<br>           reduce=True as second argument. This will return a complete canonical<br>           graph.<br><br>           The routine is designed not to use symmetry relations that are<br>           obtained with the GraphSearch routine. We also tried to create an<br>           ordering that feels like natural, i.e. starting in the center and<br>           pushing vertices with few equivalents to the front. If necessary, the<br>           nature of the vertices and  their bonds to atoms closer to the center<br>           will also play a role, but only as a last resort.<br>        """<br>        # A) find an appropriate starting vertex.<br>        # Here we take a central vertex that has a minimal number of symmetrical<br>        # equivalents, 'the highest atom number', and the highest fingerprint.<br>        # Note that the symmetrical equivalents are computed from the vertex<br>        # fingerprints, i.e. without the GraphSearch.<br>        starting_vertex = max(<br>            (<br>                -len(self.equivalent_vertices[vertex]),<br>                self.get_vertex_string(vertex),<br>                self.vertex_fingerprints[vertex].tobytes(),<br>                vertex<br>            ) for vertex in self.central_vertices<br>        )[-1]<br><br>        # B) sort all vertices based on<br>        #      1) distance from central vertex<br>        #      2) number of equivalent vertices<br>        #      3) vertex string, (higher atom numbers come first)<br>        #      4) fingerprint<br>        #      5) vertex index<br>        # The last field is only included to collect the result of the sort.<br>        # The fingerprint on itself would be sufficient, but the three first are<br>        # there to have a naturally appealing result.<br>        l = [<br>            [<br>                -distance,<br>                -len(self.equivalent_vertices[vertex]),<br>                self.get_vertex_string(vertex),<br>                self.vertex_fingerprints[vertex].tobytes(),<br>                vertex<br>            ] for vertex, distance in self.iter_breadth_first(starting_vertex)<br>            if len(self.neighbors[vertex])  0<br>        ]<br>        l.sort(reverse=True)<br><br>        # C) The order of some vertices is still not completely set. e.g.<br>        # consider the case of allene. The four hydrogen atoms are equivalent,<br>        # but one can have two different orders: make geminiles consecutive or<br>        # don't. It is more trikcy than one would think at first sight. In the<br>        # case of allene, geminility could easily solve the problem. Consider a<br>        # big flat rotationally symmetric molecule (order 2). The first five<br>        # shells are order 4 and one would just give a random order to four<br>        # segemnts in the first shell. Only when one reaches the outer part that<br>        # has order two, it turns out that the arbitrary choices in the inner<br>        # shell play a role. So it does not help to look at relations with<br>        # vertices at inner or current shells only. One has to consider the<br>        # whole picture. (unit testing reveals troubles like these)<br><br>        # I need some sleep now. The code below checks for potential fuzz and<br>        # will raise an error if the ordering is not fully determined yet. One<br>        # day, I'll need this code more than I do now, and I'll fix things up.<br>        # I know how to do this, but I don't care enough right now.<br>        # -- Toon<br>        for i in range(1, len(l)):<br>            if l[i][:-1] == l[i-1][:-1]:<br>                raise NotImplementedError<br><br>        # D) Return only the vertex indexes.<br>        return [record[-1] for record in l]


## Ground Truth

### GROUND TRUTH 0, ranked 50, leetcode/leetcode_743.txt
> import heapq<br>    """You are given a network of `n` nodes, labeled from `1` to `n`. You are also given `times`, a list of travel times as directed edges `times[i] = (ui, vi, wi)`, where `ui` is the source node, `vi` is the target node, and `wi` is the time it takes for a signal to travel from source to target.<br><br>We will send a signal from a given node `k`. Return _the minimum time it takes for all the_ `n` _nodes to receive the signal_. If it is impossible for all the `n` nodes to receive the signal, return `-1`.<br><br>Example 1:<br><br>Input: times = \[\[2,1,1\],\[2,3,1\],\[3,4,1\]\], n = 4, k = 2<br>Output: 2<br><br>Example 2:<br><br>Input: times = \[\[1,2,1\]\], n = 2, k = 1<br>Output: 1<br><br>Example 3:<br><br>Input: times = \[\[1,2,1\]\], n = 2, k = 2<br>Output: -1<br><br>Constraints:<br><br>   `1 <= k <= n <= 100`<br>   `1 <= times.length <= 6000`<br>   `times[i].length == 3`<br>   `1 <= ui, vi <= n`<br>   `ui != vi`<br>   `0 <= wi <= 100`<br>   All the pairs `(ui, vi)` are unique. (i.e., no multiple edges.)"""<br><br><br>def networkDelayTime(times, n, k):<br>    graph = {i: [] for i in range(1, n+1)}<br>    for u, v, w in times:<br>        graph[u].append((v, w))<br><br>    dist = {u: float('inf') for u in range(1, n+1)}<br>    dist[k] = 0<br><br>    pq = [(0, k)]<br><br>    while pq:<br>        curr_dist, u = heapq.heappop(pq)<br><br>        for v, weight in graph[u]:<br>            new_dist = curr_dist + weight<br>            if new_dist < dist[v]:<br>                dist[v] = new_dist<br>                heapq.heappush(pq, (new_dist, v))<br><br>    max_time = max(dist.values())<br>    return max_time if max_time < float('inf') else -1

### GROUND TRUTH 1, ranked not in top 100, leetcode/leetcode_1334.txt
> def findTheCity(n, edges, distanceThreshold):<br>    """There are `n` cities numbered from `0` to `n-1`. Given the array `edges` where `edges[i] = [fromi, toi, weighti]` represents a bidirectional and weighted edge between cities `fromi` and `toi`, and given the integer `distanceThreshold`.<br><br>Return the city with the smallest number of cities that are reachable through some path and whose distance is at most `distanceThreshold`, If there are multiple such cities, return the city with the greatest number.<br><br>Notice that the distance of a path connecting cities _i_ and _j_ is equal to the sum of the edges' weights along that path.<br><br>Example 1:<br><br>Input: n = 4, edges = \[\[0,1,3\],\[1,2,1\],\[1,3,4\],\[2,3,1\]\], distanceThreshold = 4<br>Output: 3<br>Explanation: The figure above describes the graph. <br>The neighboring cities at a distanceThreshold = 4 for each city are:<br>City 0 - \[City 1, City 2\] <br>City 1 - \[City 0, City 2, City 3\] <br>City 2 - \[City 0, City 1, City 3\] <br>City 3 - \[City 1, City 2\] <br>Cities 0 and 3 have 2 neighboring cities at a distanceThreshold = 4, but we have to return city 3 since it has the greatest number.<br><br>Example 2:<br><br>Input: n = 5, edges = \[\[0,1,2\],\[0,4,8\],\[1,2,3\],\[1,4,2\],\[2,3,1\],\[3,4,1\]\], distanceThreshold = 2<br>Output: 0<br>Explanation: The figure above describes the graph. <br>The neighboring cities at a distanceThreshold = 2 for each city are:<br>City 0 - \[City 1\] <br>City 1 - \[City 0, City 4\] <br>City 2 - \[City 3, City 4\] <br>City 3 - \[City 2, City 4\]<br>City 4 - \[City 1, City 2, City 3\] <br>The city 0 has 1 neighboring city at a distanceThreshold = 2.<br><br>Constraints:<br><br>   `2 <= n <= 100`<br>   `1 <= edges.length <= n  (n - 1) / 2`<br>   `edges[i].length == 3`<br>   `0 <= fromi < toi < n`<br>   `1 <= weighti, distanceThreshold <= 10^4`<br>   All pairs `(fromi, toi)` are distinct."""<br><br>    distance = [[1e5]  n for _ in range(n)]<br><br>    for edge in edges:<br>        distance[edge[0]][edge[1]] = edge[2]<br>        distance[edge[1]][edge[0]] = edge[2]<br><br>    for i in range(n):<br>        distance[i][i] = 0<br><br>    for k in range(n):<br>        for i in range(n):<br>            for j in range(n):<br>                distance[i][j] = min(distance[i][j], distance[i][k] + distance[k][j])<br><br>    res, minReachable = 0, n<br>    for i in range(n):<br>        reachable = sum(1 for j in range(n) if distance[i][j] <= distanceThreshold)<br>        if reachable <= minReachable:<br>            minReachable = reachable<br>            res = i<br>    return res

### GROUND TRUTH 2, ranked 5, leetcode/leetcode_1976.txt
> def can_split_string(s: str) - bool:<br>    """You are in a city that consists of `n` intersections numbered from `0` to `n - 1` with bi-directional roads between some intersections. The inputs are generated such that you can reach any intersection from any other intersection and that there is at most one road between any two intersections.<br><br>You are given an integer `n` and a 2D integer array `roads` where `roads[i] = [ui, vi, timei]` means that there is a road between intersections `ui` and `vi` that takes `timei` minutes to travel. You want to know in how many ways you can travel from intersection `0` to intersection `n - 1` in the shortest amount of time.<br><br>Return _the number of ways you can arrive at your destination in the shortest amount of time_. Since the answer may be large, return it modulo `109 + 7`.<br><br>Example 1:<br><br>Input: n = 7, roads = \[\[0,6,7\],\[0,1,2\],\[1,2,3\],\[1,3,3\],\[6,3,3\],\[3,5,1\],\[6,5,1\],\[2,5,1\],\[0,4,5\],\[4,6,2\]\]<br>Output: 4<br>Explanation: The shortest amount of time it takes to go from intersection 0 to intersection 6 is 7 minutes.<br>The four ways to get there in 7 minutes are:<br>- 0 ➝ 6<br>- 0 ➝ 4 ➝ 6<br>- 0 ➝ 1 ➝ 2 ➝ 5 ➝ 6<br>- 0 ➝ 1 ➝ 3 ➝ 5 ➝ 6<br><br>Example 2:<br><br>Input: n = 2, roads = \[\[1,0,10\]\]<br>Output: 1<br>Explanation: There is only one way to go from intersection 0 to intersection 1, and it takes 10 minutes.<br><br>Constraints:<br><br>   `1 <= n <= 200`<br>   `n - 1 <= roads.length <= n  (n - 1) / 2`<br>   `roads[i].length == 3`<br>   `0 <= ui, vi <= n - 1`<br>   `1 <= timei <= 109`<br>   `ui != vi`<br>   There is at most one road connecting any two intersections.<br>   You can reach any intersection from any other intersection."""<br><br>    count = [0]  10<br><br>    for c in s:<br>        count[int(c)] += 1<br><br>    for i in range(1, 10):<br>        if count[i]  0 and count[i] == count[i - 1]:<br>            return True<br><br>    return False
