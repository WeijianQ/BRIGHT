# Query `130`

## Original Question

*You are given an array of strings `names`, and an array `heights` that consists of distinct positive integers. Both arrays are of length `n`.

For each index `i`, `names[i]` and `heights[i]` denote the name and height of the `ith` person.

Return `names` _sorted in descending order by the people's heights_.

Example 1:

Input: names = \[ "Mary ", "John ", "Emma "\], heights = \[180,165,170\]
Output: \[ "Mary ", "Emma ", "John "\]
Explanation: Mary is the tallest, followed by Emma and John.

Example 2:

Input: names = \[ "Alice ", "Bob ", "Bob "\], heights = \[155,185,150\]
Output: \[ "Bob ", "Alice ", "Bob "\]
Explanation: The first Bob is the tallest, followed by Alice and the second Bob.

Constraints:

   `n == names.length == heights.length`
   `1 <= n <= 103`
   `1 <= names[i].length <= 20`
   `1 <= heights[i] <= 105`
   `names[i]` consists of lower and upper case English letters.
   All the values of `heights` are distinct.*

## gpt4 Reasoning

```markdown
The essential problem here is to sort the `names` array based on the corresponding values in the `heights` array in descending order. Since each index `i` in both arrays correlates a person's name with their height, we must maintain this relationship while sorting by height. Here are the steps to solve the problem:

1. **Combine the Arrays**: First, we need to combine the `names` and `heights` arrays into a single structure since we want to sort the names based on the heights. A list of tuples or a list of lists where each element is `[height, name]` could work well for this. This way, we keep the name and its corresponding height together.

2. **Sort the Combined Structure**: Next, we sort this combined structure by height in descending order. Since we want the names sorted based on their heights, and given the heights are distinct, we can directly sort based on the height, which is the first element of each tuple or list in our combined structure.

3. **Extract the Names**: After sorting, we extract the names from our sorted structure in the new order. This list of names will now be ordered by the descending order of heights, as required.

4. **Return the Sorted Names**: Finally, we return the sorted list of names.

Here's a breakdown of these steps in more detail:

- **Combining the Arrays**: We can zip the `names` and `heights` arrays together to create a combined structure. This operation pairs each name with its corresponding height.

- **Sorting**: The sort operation can be performed with a custom key function if using a higher-level programming language like Python, specifying that the sort should be based on the heights in descending order.

- **Extracting Names**: Once sorted, we iterate through our sorted structure, collecting the names in their new order. This will give us the names sorted according to the descending heights.

- **Returning Sorted Names**: The final step is simply returning the list of names we've collected.

**Example Solution in Python**:

```python
def sort_names_by_height(names, heights):
    # Step 1: Combine names and heights
    combined = list(zip(heights, names))
    
    # Step 2: Sort the combined list by height in descending order
    combined.sort(reverse=True)
    
    # Step 3: Extract sorted names
    sorted_names = [name for _, name in combined]
    
    # Step 4: Return sorted names
    return sorted_names

# Example Usage
names = ["Mary", "John", "Emma"]
heights = [180, 165, 170]
print(sort_names_by_height(names, heights))
# Output: ['Mary', 'Emma', 'John']
```

This approach ensures we maintain the correlation between each person's name and their height while sorting the names as required.
```

### Metrics

```
recip_rank: 0.0000
P_1: 0.0000
P_5: 0.0000
P_10: 0.0000
P_25: 0.0000
P_50: 0.0000
P_100: 0.0000
recall_1: 0.0000
recall_5: 0.0000
recall_10: 0.0000
recall_25: 0.0000
recall_50: 0.0000
recall_100: 0.0000
ndcg_cut_1: 0.0000
ndcg_cut_5: 0.0000
ndcg_cut_10: 0.0000
ndcg_cut_25: 0.0000
ndcg_cut_50: 0.0000
ndcg_cut_100: 0.0000
map_cut_1: 0.0000
map_cut_5: 0.0000
map_cut_10: 0.0000
map_cut_25: 0.0000
map_cut_50: 0.0000
map_cut_100: 0.0000
```

## Retrieval Results

### DOC[1] (IRRELEVANT) leetcode/csn_python_train_280798.txt
> def _push_subtree(self, leaves: List[bytes]):<br>        """Extend with a full subtree <= the current minimum subtree.<br><br>        The leaves must form a full subtree, i.e. of size 2^k for some k. If<br>        there is a minimum subtree (i.e. __mintree_height  0), then the input<br>        subtree must be smaller or of equal size to the minimum subtree.<br><br>        If the subtree is smaller (or no such minimum exists, in an empty tree),<br>        we can simply append its hash to self.hashes, since this maintains the<br>        invariant property of being sorted in descending size order.<br><br>        If the subtree is of equal size, we are in a similar situation to an<br>        addition carry. We handle it by combining the two subtrees into a larger<br>        subtree (of size 2^(k+1)), then recursively trying to add this new<br>        subtree back into the tree.<br><br>        Any collection of leaves larger than the minimum subtree must undergo<br>        additional partition to conform with the structure of a merkle tree,<br>        which is a more complex operation, performed by extend().<br>        """<br>        size = len(leaves)<br>        if count_bits_set(size) != 1:<br>            raise ValueError("invalid subtree with size != 2^k: %s" % size)<br>        # in general we want the highest bit, but here it's also the lowest bit<br>        # so just reuse that code instead of writing a new highest_bit_set()<br>        subtree_h, mintree_h = lowest_bit_set(size), self.__mintree_height<br>        if mintree_h  0 and subtree_h  mintree_h:<br>            raise ValueError("subtree %s  current smallest subtree %s" % (<br>                subtree_h, mintree_h))<br>        root_hash, hashes = self.__hasher._hash_full(leaves, 0, size)<br>        assert hashes == (root_hash,)<br><br>        if self.hashStore:<br>            for h in hashes:<br>                self.hashStore.writeLeaf(h)<br><br>        new_node_hashes = self.__push_subtree_hash(subtree_h, root_hash)<br><br>        nodes = [(self.tree_size, height, h) for h, height in new_node_hashes]<br>        if self.hashStore:<br>            for node in nodes:<br>                self.hashStore.writeNode(node)

### DOC[2] (IRRELEVANT) leetcode/csn_python_train_274290.txt
> def data_to_links(self, id_col_num, link_col_num, include_links_self='Y'):<br>        """<br>        This takes a table of data conaining a person identifier (Name or ID)<br>        and returns a table showing all links based on a common column <br>        Ip table                  Links by Location  Links by Job <br>        NAME  Location  Job<br>        John  Perth     Plumber   Location,Perth,John,Fred   Job,Farmer,Mary,Jane <br>        Mary  Burra     Farmer    Location,Perth,John,Cindy  <br>        Jane  Darwin    Farmer    Location,Perth,Fred,Cindy  <br>        Fred  Perth     Cleaner<br>        Cindy Perth     Manager  <br>        <br>        So, for any link - link ALL joins. Meaning 3 people in one location<br>        will create 3 links of 2. This is to allow finding any one person, and<br>        listing all their links.<br>        """<br>        res = []<br>        <br>        # construct the header - can be done in 1 line, but clarified<br>        hdr_col_name = 'Cat_name'<br>        hdr_col_val = self.ip_data[0][link_col_num]  # gets the header 'Location'<br>        hdr_col_base_id = self.ip_data[0][id_col_num]  # gets the header 'NAME'<br>        op_hdr = [hdr_col_name,hdr_col_val,hdr_col_base_id + '_a', hdr_col_base_id + '_b','link_count']<br>        <br>        res.append(op_hdr)<br>        <br>        for row in self.ip_data[1:]:  #.sort(key=lambda x:x[id_col_num]):<br>            id_col_a = row[id_col_num]<br>            link_col = row[link_col_num]<br>            row_cat_name = hdr_col_val   # this is replicated for this links list<br>            ok_to_add = True<br>            for link_row in self.ip_data[1:]:    # find all links to this<br>                if link_row[link_col_num] == link_col:<br>                    id_col_b = link_row[id_col_num] # get the name of the other link<br>                    if id_col_a == id_col_b:<br>                        ok_to_add = False<br>                        <br>                    # check that we aren't adding links in reverse order<br>                        <br>                    if ok_to_add == True:<br>                        res.append([row_cat_name, link_col, id_col_a, id_col_b, 1])<br>            <br>            if include_links_self == 'Y': # do we add the self link?<br>                res.append([row_cat_name, link_col, id_col_a, id_col_a, 0])<br>        return res

### DOC[3] (IRRELEVANT) leetcode/csn_python_train_144450.txt
> def ner_net(source, destinations, width, height, wrap_around=False, radius=10):<br>    """Produce a shortest path tree for a given net using NER.<br><br>    This is the kernel of the NER algorithm.<br><br>    Parameters<br>    ----------<br>    source : (x, y)<br>        The coordinate of the source vertex.<br>    destinations : iterable([(x, y), ...])<br>        The coordinates of destination vertices.<br>    width : int<br>        Width of the system (nodes)<br>    height : int<br>        Height of the system (nodes)<br>    wrap_around : bool<br>        True if wrap-around links should be used, false if they should be<br>        avoided.<br>    radius : int<br>        Radius of area to search from each node. 20 is arbitrarily selected in<br>        the paper and shown to be acceptable in practice.<br><br>    Returns<br>    -------<br>    (:py:class:`~.rig.place_and_route.routing_tree.RoutingTree`,<br>     {(x,y): :py:class:`~.rig.place_and_route.routing_tree.RoutingTree`, ...})<br>        A RoutingTree is produced rooted at the source and visiting all<br>        destinations but which does not contain any vertices etc. For<br>        convenience, a dictionarry mapping from destination (x, y) coordinates<br>        to the associated RoutingTree is provided to allow the caller to insert<br>        these items.<br>    """<br>    # Map from (x, y) to RoutingTree objects<br>    route = {source: RoutingTree(source)}<br><br>    # Handle each destination, sorted by distance from the source, closest<br>    # first.<br>    for destination in sorted(destinations,<br>                              key=(lambda destination:<br>                                   shortest_mesh_path_length(<br>                                       to_xyz(source), to_xyz(destination))<br>                                   if not wrap_around else<br>                                   shortest_torus_path_length(<br>                                       to_xyz(source), to_xyz(destination),<br>                                       width, height))):<br>        # We shall attempt to find our nearest neighbouring placed node.<br>        neighbour = None<br><br>        # Try to find a nearby (within radius hops) node in the routing tree<br>        # that we can route to (falling back on just routing to the source).<br>        #<br>        # In an implementation according to the algorithm's original<br>        # specification looks for nodes at each point in a growing set of rings<br>        # of concentric hexagons. If it doesn't find any destinations this<br>        # means an awful lot of checks: 1261 for the default radius of 20.<br>        #<br>        # An alternative (but behaviourally identical) implementation scans the<br>        # list of all route nodes created so far and finds the closest node<br>        # which is < radius hops (falling back on the origin if no node is<br>        # closer than radius hops).  This implementation requires one check per<br>        # existing route node. In most routes this is probably a lot less than<br>        # 1261 since most routes will probably have at most a few hundred route<br>        # nodes by the time the last destination is being routed.<br>        #<br>        # Which implementation is best is a difficult question to answer:<br>        #  In principle nets with quite localised connections (e.g.<br>        #   nearest-neighbour or centroids traffic) may route slightly more<br>        #   quickly with the original algorithm since it may very quickly find<br>        #   a neighbour.<br>        #  In nets which connect very spaced-out destinations the second<br>        #   implementation may be quicker since in such a scenario it is<br>        #   unlikely that a neighbour will be found.<br>        #  In extremely high-fan-out nets (e.g. broadcasts), the original<br>        #   method is very likely to perform far better than the alternative<br>        #   method since most iterations will complete immediately while the<br>        #   alternative method must scan all the route vertices.<br>        # As such, it should be clear that neither method alone is 'best' and<br>        # both have degenerate performance in certain completely reasonable<br>        # styles of net. As a result, a simple heuristic is used to decide<br>        # which technique to use.<br>        #<br>        # The following micro-benchmarks are crude estimate of the<br>        # runtime-per-iteration of each approach (at least in the case of a<br>        # torus topology)::<br>        #<br>        #     $ # Original approach<br>        #     $ python -m timeit --setup 'x, y, w, h, r = 1, 2, 5, 10, \<br>        #                                     {x:None for x in range(10)}' \<br>        #                        'x += 1; y += 1; x %= w; y %= h; (x, y) in r'<br>        #     1000000 loops, best of 3: 0.207 usec per loop<br>        #     $ # Alternative approach<br>        #     $ python -m timeit --setup 'from rig.geometry import \<br>        #                                 shortest_torus_path_length' \<br>        #                        'shortest_torus_path_length( \<br>        #                             (0, 1, 2), (3, 2, 1), 10, 10)'<br>        #     1000000 loops, best of 3: 0.666 usec per loop<br>        #<br>        # From this we can approximately suggest that the alternative approach<br>        # is 3x more expensive per iteration. A very crude heuristic is to use<br>        # the original approach when the number of route nodes is more than<br>        # 1/3rd of the number of routes checked by the original method.<br>        concentric_hexagons = memoized_concentric_hexagons(radius)<br>        if len(concentric_hexagons) < len(route) / 3:<br>            # Original approach: Start looking for route nodes in a concentric<br>            # spiral pattern out from the destination node.<br>            for x, y in concentric_hexagons:<br>                x += destination[0]<br>                y += destination[1]<br>                if wrap_around:<br>                    x %= width<br>                    y %= height<br>                if (x, y) in route:<br>                    neighbour = (x, y)<br>                    break<br>        else:<br>            # Alternative approach: Scan over every route node and check to see<br>            # if any are < radius, picking the closest one if so.<br>            neighbour = None<br>            neighbour_distance = None<br>            for candidate_neighbour in route:<br>                if wrap_around:<br>                    distance = shortest_torus_path_length(<br>                        to_xyz(candidate_neighbour), to_xyz(destination),<br>                        width, height)<br>                else:<br>                    distance = shortest_mesh_path_length(<br>                        to_xyz(candidate_neighbour), to_xyz(destination))<br><br>                if distance <= radius and (neighbour is None or<br>                                           distance < neighbour_distance):<br>                    neighbour = candidate_neighbour<br>                    neighbour_distance = distance<br><br>        # Fall back on routing directly to the source if no nodes within radius<br>        # hops of the destination was found.<br>        if neighbour is None:<br>            neighbour = source<br><br>        # Find the shortest vector from the neighbour to this destination<br>        if wrap_around:<br>            vector = shortest_torus_path(to_xyz(neighbour),<br>                                         to_xyz(destination),<br>                                         width, height)<br>        else:<br>            vector = shortest_mesh_path(to_xyz(neighbour), to_xyz(destination))<br><br>        # The longest-dimension-first route may inadvertently pass through an<br>        # already connected node. If the route is allowed to pass through that<br>        # node it would create a cycle in the route which would be VeryBad(TM).<br>        # As a result, we work backward through the route and truncate it at<br>        # the first point where the route intersects with a connected node.<br>        ldf = longest_dimension_first(vector, neighbour, width, height)<br>        i = len(ldf)<br>        for direction, (x, y) in reversed(ldf):<br>            i -= 1<br>            if (x, y) in route:<br>                # We've just bumped into a node which is already part of the<br>                # route, this becomes our new neighbour and we truncate the LDF<br>                # route. (Note ldf list is truncated just after the current<br>                # position since it gives (direction, destination) pairs).<br>                neighbour = (x, y)<br>                ldf = ldf[i + 1:]<br>                break<br><br>        # Take the longest dimension first route.<br>        last_node = route[neighbour]<br>        for direction, (x, y) in ldf:<br>            this_node = RoutingTree((x, y))<br>            route[(x, y)] = this_node<br><br>            last_node.children.append((Routes(direction), this_node))<br>            last_node = this_node<br><br>    return (route[source], route)

### DOC[4] (IRRELEVANT) leetcode/csn_python_train_72413.txt
> def expand(data):<br>  '''Generates configuration sets based on the YAML input contents<br><br>  For an introduction to the YAML mark-up, just search the net. Here is one of<br>  its references: https://en.wikipedia.org/wiki/YAML<br><br>  A configuration set corresponds to settings for all variables in the<br>  input template that needs replacing. For example, if your template mentions<br>  the variables ``name`` and ``version``, then each configuration set should<br>  yield values for both ``name`` and ``version``.<br><br>  For example:<br><br>  .. code-block:: yaml<br><br>     name: [john, lisa]<br>     version: [v1, v2]<br><br><br>  This should yield to the following configuration sets:<br><br>  .. code-block:: python<br><br>     [<br>       {'name': 'john', 'version': 'v1'},<br>       {'name': 'john', 'version': 'v2'},<br>       {'name': 'lisa', 'version': 'v1'},<br>       {'name': 'lisa', 'version': 'v2'},<br>     ]<br><br><br>  Each key in the input file should correspond to either an object or a YAML<br>  array. If the object is a list, then we'll iterate over it for every possible<br>  combination of elements in the lists. If the element in question is not a<br>  list, then it is considered unique and repeated for each yielded<br>  configuration set. Example<br><br>  .. code-block:: yaml<br><br>     name: [john, lisa]<br>     version: [v1, v2]<br>     text: <br>        hello,<br>        world!<br><br>  Should yield to the following configuration sets:<br><br>  .. code-block:: python<br><br>     [<br>       {'name': 'john', 'version': 'v1', 'text': 'hello, world!'},<br>       {'name': 'john', 'version': 'v2', 'text': 'hello, world!'},<br>       {'name': 'lisa', 'version': 'v1', 'text': 'hello, world!'},<br>       {'name': 'lisa', 'version': 'v2', 'text': 'hello, world!'},<br>     ]<br><br>  Keys starting with one `_` (underscore) are treated as "unique" objects as<br>  well. Example:<br><br>  .. code-block:: yaml<br><br>     name: [john, lisa]<br>     version: [v1, v2]<br>     _unique: [i1, i2]<br><br>  Should yield to the following configuration sets:<br><br>  .. code-block:: python<br><br>     [<br>       {'name': 'john', 'version': 'v1', '_unique': ['i1', 'i2']},<br>       {'name': 'john', 'version': 'v2', '_unique': ['i1', 'i2']},<br>       {'name': 'lisa', 'version': 'v1', '_unique': ['i1', 'i2']},<br>       {'name': 'lisa', 'version': 'v2', '_unique': ['i1', 'i2']},<br>     ]<br><br><br>  Parameters:<br><br>    data (str): YAML data to be parsed<br><br><br>  Yields:<br><br>    dict: A dictionary of key-value pairs for building the templates<br><br>  '''<br><br>  data = _ordered_load(data, yaml.SafeLoader)<br><br>  # separates "unique" objects from the ones we have to iterate<br>  # pre-assemble return dictionary<br>  iterables = dict()<br>  unique = dict()<br>  for key, value in data.items():<br>    if isinstance(value, list) and not key.startswith('_'):<br>      iterables[key] = value<br>    else:<br>      unique[key] = value<br><br>  # generates all possible combinations of iterables<br>  for values in itertools.product(iterables.values()):<br>    retval = dict(unique)<br>    keys = list(iterables.keys())<br>    retval.update(dict(zip(keys, values)))<br>    yield retval

### DOC[5] (IRRELEVANT) leetcode/csn_python_train_326960.txt
> def from_array(a, mode=None, info={}):<br>    """<br>    Create a PNG :class:`Image` object from a 2-dimensional array.<br>    One application of this function is easy PIL-style saving:<br>    ``png.from_array(pixels, 'L').save('foo.png')``.<br><br>    Unless they are specified using the info parameter,<br>    the PNG's height and width are taken from the array size.<br>    The first axis is the height; the second axis is the<br>    ravelled width and channel index.<br>    The array is treated is a sequence of rows,<br>    each row being a sequence of values (``widthchannels`` in number).<br>    So an RGB image that is 16 pixels high and 8 wide will<br>    occupy a 2-dimensional array that is 16x24<br>    (each row will be 83 = 24 sample values).<br><br>    mode is a string that specifies the image colour format in a<br>    PIL-style mode.  It can be:<br><br>    ``'L'``<br>      greyscale (1 channel)<br>    ``'LA'``<br>      greyscale with alpha (2 channel)<br>    ``'RGB'``<br>      colour image (3 channel)<br>    ``'RGBA'``<br>      colour image with alpha (4 channel)<br><br>    The mode string can also specify the bit depth<br>    (overriding how this function normally derives the bit depth,<br>    see below).<br>    Appending ``';16'`` to the mode will cause the PNG to be<br>    16 bits per channel;<br>    any decimal from 1 to 16 can be used to specify the bit depth.<br><br>    When a 2-dimensional array is used mode determines how many<br>    channels the image has, and so allows the width to be derived from<br>    the second array dimension.<br><br>    The array is expected to be a ``numpy`` array,<br>    but it can be any suitable Python sequence.<br>    For example, a list of lists can be used:<br>    ``png.from_array([[0, 255, 0], [255, 0, 255]], 'L')``.<br>    The exact rules are: ``len(a)`` gives the first dimension, height;<br>    ``len(a[0])`` gives the second dimension.<br>    It's slightly more complicated than that because<br>    an iterator of rows can be used, and it all still works.<br>    Using an iterator allows data to be streamed efficiently.<br><br>    The bit depth of the PNG is normally taken from<br>    the array element's datatype<br>    (but if mode specifies a bitdepth then that is used instead).<br>    The array element's datatype is determined in a way which<br>    is supposed to work both for ``numpy`` arrays and for Python<br>    ``array.array`` objects.<br>    A 1 byte datatype will give a bit depth of 8,<br>    a 2 byte datatype will give a bit depth of 16.<br>    If the datatype does not have an implicit size,<br>    like the above example where it is a plain Python list of lists,<br>    then a default of 8 is used.<br><br>    The info parameter is a dictionary that can<br>    be used to specify metadata (in the same style as<br>    the arguments to the :class:`png.Writer` class).<br>    For this function the keys that are useful are:<br><br>    height<br>      overrides the height derived from the array dimensions and<br>      allows a to be an iterable.<br>    width<br>      overrides the width derived from the array dimensions.<br>    bitdepth<br>      overrides the bit depth derived from the element datatype<br>      (but must match mode if that also specifies a bit depth).<br><br>    Generally anything specified in the info dictionary will<br>    override any implicit choices that this function would otherwise make,<br>    but must match any explicit ones.<br>    For example, if the info dictionary has a ``greyscale`` key then<br>    this must be true when mode is ``'L'`` or ``'LA'`` and<br>    false when mode is ``'RGB'`` or ``'RGBA'``.<br>    """<br><br>    # We abuse the info parameter by modifying it.  Take a copy here.<br>    # (Also typechecks info to some extent).<br>    info = dict(info)<br><br>    # Syntax check mode string.<br>    match = RegexModeDecode.match(mode)<br>    if not match:<br>        raise Error("mode string should be 'RGB' or 'L;16' or similar.")<br><br>    mode, bitdepth = match.groups()<br>    if bitdepth:<br>        bitdepth = int(bitdepth)<br><br>    # Colour format.<br>    if 'greyscale' in info:<br>        if bool(info['greyscale']) != ('L' in mode):<br>            raise ProtocolError("info['greyscale'] should match mode.")<br>    info['greyscale'] = 'L' in mode<br><br>    alpha = 'A' in mode<br>    if 'alpha' in info:<br>        if bool(info['alpha']) != alpha:<br>            raise ProtocolError("info['alpha'] should match mode.")<br>    info['alpha'] = alpha<br><br>    # Get bitdepth from mode if possible.<br>    if bitdepth:<br>        if info.get("bitdepth") and bitdepth != info['bitdepth']:<br>            raise ProtocolError(<br>                "bitdepth (%d) should match bitdepth of info (%d)." %<br>                (bitdepth, info['bitdepth']))<br>        info['bitdepth'] = bitdepth<br><br>    # Fill in and/or check entries in info.<br>    # Dimensions.<br>    width, height = check_sizes(<br>        info.get("size"),<br>        info.get("width"),<br>        info.get("height"))<br>    if width:<br>        info["width"] = width<br>    if height:<br>        info["height"] = height<br><br>    if "height" not in info:<br>        try:<br>            info['height'] = len(a)<br>        except TypeError:<br>            raise ProtocolError(<br>                "len(a) does not work, supply info['height'] instead.")<br><br>    planes = len(mode)<br>    if 'planes' in info:<br>        if info['planes'] != planes:<br>            raise Error("info['planes'] should match mode.")<br><br>    # In order to work out whether we the array is 2D or 3D we need its<br>    # first row, which requires that we take a copy of its iterator.<br>    # We may also need the first row to derive width and bitdepth.<br>    a, t = itertools.tee(a)<br>    row = next(t)<br>    del t<br><br>    testelement = row<br>    if 'width' not in info:<br>        width = len(row) // planes<br>        info['width'] = width<br><br>    if 'bitdepth' not in info:<br>        try:<br>            dtype = testelement.dtype<br>            # goto the "else:" clause.  Sorry.<br>        except AttributeError:<br>            try:<br>                # Try a Python array.array.<br>                bitdepth = 8  testelement.itemsize<br>            except AttributeError:<br>                # We can't determine it from the array element's datatype,<br>                # use a default of 8.<br>                bitdepth = 8<br>        else:<br>            # If we got here without exception,<br>            # we now assume that the array is a numpy array.<br>            if dtype.kind == 'b':<br>                bitdepth = 1<br>            else:<br>                bitdepth = 8  dtype.itemsize<br>        info['bitdepth'] = bitdepth<br><br>    for thing in ["width", "height", "bitdepth", "greyscale", "alpha"]:<br>        assert thing in info<br><br>    return Image(a, info)


## Ground Truth

### GROUND TRUTH 0, ranked not in top 100, leetcode/leetcode_1636.txt
> def num_sub(s: str) - int:<br>    """Given an array of integers `nums`, sort the array in increasing order based on the frequency of the values. If multiple values have the same frequency, sort them in decreasing order.<br><br>Return the _sorted array_.<br><br>Example 1:<br><br>Input: nums = \[1,1,2,2,2,3\]<br>Output: \[3,1,1,2,2,2\]<br>Explanation: '3' has a frequency of 1, '1' has a frequency of 2, and '2' has a frequency of 3.<br><br>Example 2:<br><br>Input: nums = \[2,3,1,3,2\]<br>Output: \[1,3,3,2,2\]<br>Explanation: '2' and '3' both have a frequency of 2, so they are sorted in decreasing order.<br><br>Example 3:<br><br>Input: nums = \[-1,1,-6,4,5,-6,1,4,1\]<br>Output: \[5,-1,4,4,-6,-6,1,1,1\]<br><br>Constraints:<br><br>   `1 <= nums.length <= 100`<br>   `-100 <= nums[i] <= 100`"""<br><br>    mod = 1000000007<br>    result = 0<br>    count = 0<br>    for c in s:<br>        count = count + 1 if c == '1' else 0<br>        result = (result + count) % mod<br>    return result

### GROUND TRUTH 1, ranked not in top 100, leetcode/leetcode_2545.txt
> def sort_students(score, k):<br>    """There is a class with `m` students and `n` exams. You are given a 0-indexed `m x n` integer matrix `score`, where each row represents one student and `score[i][j]` denotes the score the `ith` student got in the `jth` exam. The matrix `score` contains distinct integers only.<br><br>You are also given an integer `k`. Sort the students (i.e., the rows of the matrix) by their scores in the `kth` (0-indexed) exam from the highest to the lowest.<br><br>Return _the matrix after sorting it._<br><br>Example 1:<br><br>Input: score = \[\[10,6,9,1\],\[7,5,11,2\],\[4,8,3,15\]\], k = 2<br>Output: \[\[7,5,11,2\],\[10,6,9,1\],\[4,8,3,15\]\]<br>Explanation: In the above diagram, S denotes the student, while E denotes the exam.<br>- The student with index 1 scored 11 in exam 2, which is the highest score, so they got first place.<br>- The student with index 0 scored 9 in exam 2, which is the second highest score, so they got second place.<br>- The student with index 2 scored 3 in exam 2, which is the lowest score, so they got third place.<br><br>Example 2:<br><br>Input: score = \[\[3,4\],\[5,6\]\], k = 0<br>Output: \[\[5,6\],\[3,4\]\]<br>Explanation: In the above diagram, S denotes the student, while E denotes the exam.<br>- The student with index 1 scored 5 in exam 0, which is the highest score, so they got first place.<br>- The student with index 0 scored 3 in exam 0, which is the lowest score, so they got second place.<br><br>Constraints:<br><br>   `m == score.length`<br>   `n == score[i].length`<br>   `1 <= m, n <= 250`<br>   `1 <= score[i][j] <= 105`<br>   `score` consists of distinct integers.<br>   `0 <= k < n`"""<br><br>    score.sort(key=lambda x: x[k], reverse=True)<br>    return score
