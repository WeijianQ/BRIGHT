# Query `49`

## Original Question

*You are given an integer array of unique positive integers `nums`. Consider the following graph:

   There are `nums.length` nodes, labeled `nums[0]` to `nums[nums.length - 1]`,
   There is an undirected edge between `nums[i]` and `nums[j]` if `nums[i]` and `nums[j]` share a common factor greater than `1`.

Return _the size of the largest connected component in the graph_.

Example 1:

Input: nums = \[4,6,15,35\]
Output: 4

Example 2:

Input: nums = \[20,50,9,63\]
Output: 2

Example 3:

Input: nums = \[2,3,6,7,4,12,21,39\]
Output: 8

Constraints:

   `1 <= nums.length <= 2  104`
   `1 <= nums[i] <= 105`
   All the values of `nums` are unique.*

## gpt4 Reasoning

```markdown
The essential problem here is to find the size of the largest connected component in a graph where nodes represent unique positive integers from the given array `nums`, and an edge exists between any two nodes if the integers they represent have a common factor greater than 1. This problem involves concepts from graph theory and number theory. To solve it, let's break it down step by step:

### Step 1: Understanding the Graph Representation

The first step is to understand how the graph is constructed. Each node in the graph represents a unique positive integer from the array `nums`. An edge between two nodes indicates that the integers they represent share at least one common factor greater than 1 (i.e., they are not co-prime).

### Step 2: Finding Common Factors

To determine if an edge should exist between any two nodes, we need a method to find common factors of two numbers efficiently. One way to do this is by calculating the Greatest Common Divisor (GCD) of the two numbers. If the GCD is greater than 1, the numbers share a factor greater than 1, and hence, an edge exists between them.

### Step 3: Building the Graph

Once we have a method to determine if an edge exists between any two nodes, we can proceed to build the graph. This involves iterating over all pairs of numbers in `nums` and adding an edge between them if they share a common factor greater than 1. However, this approach has a quadratic time complexity, which might not be efficient for large arrays. An optimization can be to factorize each number into its prime factors and use these factors to connect numbers sharing at least one common prime factor.

### Step 4: Finding Connected Components

After constructing the graph, the next step is to find all connected components within it. This can be achieved using either Depth-First Search (DFS) or Breadth-First Search (BFS) algorithms. Starting from an unvisited node, you explore as far as possible along each branch before backtracking, marking nodes as visited. This process helps in identifying all nodes that are part of the same connected component.

### Step 5: Calculating the Size of the Largest Connected Component

As you identify each connected component using DFS or BFS, you can keep track of the number of nodes in it. The size of the largest connected component is simply the maximum number of nodes in any of the connected components identified.

### Relevant Information

- **Efficiency of Prime Factorization**: For large numbers, prime factorization can be time-consuming. Efficient algorithms for factorization or using precomputed prime tables can help.
- **Graph Data Structure**: Choosing an efficient data structure for the graph is crucial. An adjacency list is typically more space-efficient than an adjacency matrix for sparse graphs (graphs with relatively few edges compared to the number of nodes).

### Conclusion

To solve the problem, we need to efficiently build a graph based on common factors, find all connected components, and determine the size of the largest one. The key challenges include efficient factorization of numbers and graph traversal to find connected components. Optimizing these steps is crucial for handling large arrays and numbers within the given constraints.
```

### Metrics

```
recip_rank: 0.0714
P_1: 0.0000
P_5: 0.0000
P_10: 0.0000
P_25: 0.0400
P_50: 0.0200
P_100: 0.0100
recall_1: 0.0000
recall_5: 0.0000
recall_10: 0.0000
recall_25: 0.5000
recall_50: 0.5000
recall_100: 0.5000
ndcg_cut_1: 0.0000
ndcg_cut_5: 0.0000
ndcg_cut_10: 0.0000
ndcg_cut_25: 0.1569
ndcg_cut_50: 0.1569
ndcg_cut_100: 0.1569
map_cut_1: 0.0000
map_cut_5: 0.0000
map_cut_10: 0.0000
map_cut_25: 0.0357
map_cut_50: 0.0357
map_cut_100: 0.0357
```

## Retrieval Results

### DOC[1] (IRRELEVANT) leetcode/csn_python_train_314887.txt
> def min_vertex_coloring(G, sampler=None, sampler_args):<br>    """Returns an approximate minimum vertex coloring.<br><br>    Vertex coloring is the problem of assigning a color to the<br>    vertices of a graph in a way that no adjacent vertices have the<br>    same color. A minimum vertex coloring is the problem of solving<br>    the vertex coloring problem using the smallest number of colors.<br><br>    Since neighboring vertices must satisfy a constraint of having<br>    different colors, the problem can be posed as a binary constraint<br>    satisfaction problem.<br><br>    Defines a QUBO with ground states corresponding to minimum<br>    vertex colorings and uses the sampler to sample from it.<br><br>    Parameters<br>    ----------<br>    G : NetworkX graph<br>        The graph on which to find a minimum vertex coloring.<br><br>    sampler<br>        A binary quadratic model sampler. A sampler is a process that<br>        samples from low energy states in models defined by an Ising<br>        equation or a Quadratic Unconstrained Binary Optimization<br>        Problem (QUBO). A sampler is expected to have a 'sample_qubo'<br>        and 'sample_ising' method. A sampler is expected to return an<br>        iterable of samples, in order of increasing energy. If no<br>        sampler is provided, one must be provided using the<br>        `set_default_sampler` function.<br><br>    sampler_args<br>        Additional keyword parameters are passed to the sampler.<br><br>    Returns<br>    -------<br>    coloring : dict<br>        A coloring for each vertex in G such that no adjacent nodes<br>        share the same color. A dict of the form {node: color, ...}<br><br>    Example<br>    -------<br>    This example colors a single Chimera unit cell. It colors the four<br>    horizontal qubits one color (0) and the four vertical qubits another (1).<br><br>     # Set up a sampler; this example uses a sampler from dimod https://github.com/dwavesystems/dimod<br>     import dimod<br>     import dwave_networkx as dnx<br>     samplerSA = dimod.SimulatedAnnealingSampler()<br>     # Create a graph and color it<br>     G = dnx.chimera_graph(1, 1, 4)<br>     colors = dnx.min_vertex_coloring(G, sampler=samplerSA)<br>     colors<br>    {0: 0, 1: 0, 2: 0, 3: 0, 4: 1, 5: 1, 6: 1, 7: 1}<br><br>    References<br>    ----------<br>    .. [DWMP] Dahl, E., "Programming the D-Wave: Map Coloring Problem",<br>       https://www.dwavesys.com/sites/default/files/Map%20Coloring%20WP2.pdf<br><br>    Notes<br>    -----<br>    Samplers by their nature may not return the optimal solution. This<br>    function does not attempt to confirm the quality of the returned<br>    sample.<br><br>    """<br><br>    # if the given graph is not connected, apply the function to each connected component<br>    # seperately.<br>    if not nx.is_connected(G):<br>        coloring = {}<br>        for subG in (G.subgraph(c).copy() for c in nx.connected_components(G)):<br>            sub_coloring = min_vertex_coloring(subG, sampler, sampler_args)<br>            coloring.update(sub_coloring)<br>        return coloring<br><br>    n_nodes = len(G)  # number of nodes<br>    n_edges = len(G.edges)  # number of edges<br><br>    # ok, first up, we can eliminate a few graph types trivially<br><br>    # Graphs with no edges, have chromatic number 1<br>    if not n_edges:<br>        return {node: 0 for node in G}<br><br>    # Complete graphs have chromatic number N<br>    if n_edges == n_nodes  (n_nodes - 1) // 2:<br>        return {node: color for color, node in enumerate(G)}<br><br>    # The number of variables in the QUBO is approximately the number of nodes in the graph<br>    # times the number of potential colors, so we want as tight an upper bound on the<br>    # chromatic number (chi) as possible<br>    chi_ub = _chromatic_number_upper_bound(G, n_nodes, n_edges)<br><br>    # now we can start coloring. Without loss of generality, we can determine some of<br>    # the node colors before trying to solve.<br>    partial_coloring, possible_colors, chi_lb = _partial_precolor(G, chi_ub)<br><br>    # ok, to get the rest of the coloring, we need to start building the QUBO. We do this<br>    # by assigning a variable x_v_c for each node v and color c. This variable will be 1<br>    # when node v is colored c, and 0 otherwise.<br><br>    # let's assign an index to each of the variables<br>    counter = itertools.count()<br>    x_vars = {v: {c: next(counter) for c in possible_colors[v]} for v in possible_colors}<br><br>    # now we have three different constraints we wish to add.<br><br>    # the first constraint enforces the coloring rule, that for each pair of vertices<br>    # u, v that share an edge, they should be different colors<br>    Q_neighbor = _vertex_different_colors_qubo(G, x_vars)<br><br>    # the second constraint enforces that each vertex has a single color assigned<br>    Q_vertex = _vertex_one_color_qubo(x_vars)<br><br>    # the third constraint is that we want a minimum vertex coloring, so we want to<br>    # disincentivize the colors we might not need.<br>    Q_min_color = _minimum_coloring_qubo(x_vars, chi_lb, chi_ub, magnitude=.75)<br><br>    # combine all three constraints<br>    Q = Q_neighbor<br>    for (u, v), bias in iteritems(Q_vertex):<br>        if (u, v) in Q:<br>            Q[(u, v)] += bias<br>        elif (v, u) in Q:<br>            Q[(v, u)] += bias<br>        else:<br>            Q[(u, v)] = bias<br>    for (v, v), bias in iteritems(Q_min_color):<br>        if (v, v) in Q:<br>            Q[(v, v)] += bias<br>        else:<br>            Q[(v, v)] = bias<br><br>    # use the sampler to find low energy states<br>    response = sampler.sample_qubo(Q, sampler_args)<br><br>    # we want the lowest energy sample<br>    sample = next(iter(response))<br><br>    # read off the coloring<br>    for v in x_vars:<br>        for c in x_vars[v]:<br>            if sample[x_vars[v][c]]:<br>                partial_coloring[v] = c<br><br>    return partial_coloring

### DOC[2] (IRRELEVANT) leetcode/leetcode_2322.txt
> def dfs(node, parent, xor_values, tree):<br>    """There is an undirected connected tree with `n` nodes labeled from `0` to `n - 1` and `n - 1` edges.<br><br>You are given a 0-indexed integer array `nums` of length `n` where `nums[i]` represents the value of the `ith` node. You are also given a 2D integer array `edges` of length `n - 1` where `edges[i] = [ai, bi]` indicates that there is an edge between nodes `ai` and `bi` in the tree.<br><br>Remove two distinct edges of the tree to form three connected components. For a pair of removed edges, the following steps are defined:<br><br>1.  Get the XOR of all the values of the nodes for each of the three components respectively.<br>2.  The difference between the largest XOR value and the smallest XOR value is the score of the pair.<br><br>   For example, say the three components have the node values: `[4,5,7]`, `[1,9]`, and `[3,3,3]`. The three XOR values are `4 ^ 5 ^ 7 = 6`, `1 ^ 9 = 8`, and `3 ^ 3 ^ 3 = 3`. The largest XOR value is `8` and the smallest XOR value is `3`. The score is then `8 - 3 = 5`.<br><br>Return _the minimum score of any possible pair of edge removals on the given tree_.<br><br>Example 1:<br><br>Input: nums = \[1,5,5,4,11\], edges = \[\[0,1\],\[1,2\],\[1,3\],\[3,4\]\]<br>Output: 9<br>Explanation: The diagram above shows a way to make a pair of removals.<br>- The 1st component has nodes \[1,3,4\] with values \[5,4,11\]. Its XOR value is 5 ^ 4 ^ 11 = 10.<br>- The 2nd component has node \[0\] with value \[1\]. Its XOR value is 1 = 1.<br>- The 3rd component has node \[2\] with value \[5\]. Its XOR value is 5 = 5.<br>The score is the difference between the largest and smallest XOR value which is 10 - 1 = 9.<br>It can be shown that no other pair of removals will obtain a smaller score than 9.<br><br>Example 2:<br><br>Input: nums = \[5,5,2,4,4,2\], edges = \[\[0,1\],\[1,2\],\[5,2\],\[4,3\],\[1,3\]\]<br>Output: 0<br>Explanation: The diagram above shows a way to make a pair of removals.<br>- The 1st component has nodes \[3,4\] with values \[4,4\]. Its XOR value is 4 ^ 4 = 0.<br>- The 2nd component has nodes \[1,0\] with values \[5,5\]. Its XOR value is 5 ^ 5 = 0.<br>- The 3rd component has nodes \[2,5\] with values \[2,2\]. Its XOR value is 2 ^ 2 = 0.<br>The score is the difference between the largest and smallest XOR value which is 0 - 0 = 0.<br>We cannot obtain a smaller score than 0.<br><br>Constraints:<br><br>   `n == nums.length`<br>   `3 <= n <= 1000`<br>   `1 <= nums[i] <= 108`<br>   `edges.length == n - 1`<br>   `edges[i].length == 2`<br>   `0 <= ai, bi < n`<br>   `ai != bi`<br>   `edges` represents a valid tree."""<br><br>    xor_value = xor_values[node]<br>    for child in tree[node]:<br>        if child != parent:<br>            xor_value ^= dfs(child, node, xor_values, tree)<br>    return xor_value<br><br><br>def minimumScore(nums, edges):<br>    n = len(nums)<br>    tree = [[] for _ in range(n)]<br>    <br>    for edge in edges:<br>        tree[edge[0]].append(edge[1])<br>        tree[edge[1]].append(edge[0])<br>    <br>    xor_values = [dfs(i, -1, nums, tree) for i in range(n)]<br>    <br>    ans = float('inf')<br>    for i in range(n):<br>        for j in range(i + 1, n):<br>            xor1 = xor_values[i]<br>            xor2 = xor_values[j] ^ nums[i]<br>            xor3 = nums[i] ^ nums[j]<br>            max_xor = max(xor1, xor2, xor3)<br>            min_xor = min(xor1, xor2, xor3)<br>            ans = min(ans, max_xor - min_xor)<br>    <br>    return ans

### DOC[3] (IRRELEVANT) leetcode/leetcode_1766.txt
> from bisect import bisect_left<br>    """There is a tree (i.e., a connected, undirected graph that has no cycles) consisting of `n` nodes numbered from `0` to `n - 1` and exactly `n - 1` edges. Each node has a value associated with it, and the root of the tree is node `0`.<br><br>To represent this tree, you are given an integer array `nums` and a 2D array `edges`. Each `nums[i]` represents the `ith` node's value, and each `edges[j] = [uj, vj]` represents an edge between nodes `uj` and `vj` in the tree.<br><br>Two values `x` and `y` are coprime if `gcd(x, y) == 1` where `gcd(x, y)` is the greatest common divisor of `x` and `y`.<br><br>An ancestor of a node `i` is any other node on the shortest path from node `i` to the root. A node is not considered an ancestor of itself.<br><br>Return _an array_ `ans` _of size_ `n`, _where_ `ans[i]` _is the closest ancestor to node_ `i` _such that_ `nums[i]` _and_ `nums[ans[i]]` are coprime, or `-1` _if there is no such ancestor_.<br><br>Example 1:<br><br>Input: nums = \[2,3,3,2\], edges = \[\[0,1\],\[1,2\],\[1,3\]\]<br>Output: \[-1,0,0,1\]<br>Explanation: In the above figure, each node's value is in parentheses.<br>- Node 0 has no coprime ancestors.<br>- Node 1 has only one ancestor, node 0. Their values are coprime (gcd(2,3) == 1).<br>- Node 2 has two ancestors, nodes 1 and 0. Node 1's value is not coprime (gcd(3,3) == 3), but node 0's<br>  value is (gcd(2,3) == 1), so node 0 is the closest valid ancestor.<br>- Node 3 has two ancestors, nodes 1 and 0. It is coprime with node 1 (gcd(3,2) == 1), so node 1 is its<br>  closest valid ancestor.<br><br>Example 2:<br><br>Input: nums = \[5,6,10,2,3,6,15\], edges = \[\[0,1\],\[0,2\],\[1,3\],\[1,4\],\[2,5\],\[2,6\]\]<br>Output: \[-1,0,-1,0,0,0,-1\]<br><br>Constraints:<br><br>   `nums.length == n`<br>   `1 <= nums[i] <= 50`<br>   `1 <= n <= 105`<br>   `edges.length == n - 1`<br>   `edges[j].length == 2`<br>   `0 <= uj, vj < n`<br>   `uj != vj`"""<br><br><br>def minimum_mountain_removals(nums):<br>    n = len(nums)<br>    left, right = [0]  n, [0]  n<br>    for i in range(n):<br>        left[i] = bisect_left(left[:i], nums[i])<br>        right[n - 1 - i] = bisect_left(right[n - i:], nums[n - 1 - i])<br><br>    return n - max(left[i] + right[i] for i in range(1, n - 1)) - 1

### DOC[4] (IRRELEVANT) leetcode/csn_python_train_226291.txt
> def find_prime_polynomials(generator=2, c_exp=8, fast_primes=False, single=False):<br>    '''Compute the list of prime polynomials for the given generator and galois field characteristic exponent.'''<br>    # fast_primes will output less results but will be significantly faster.<br>    # single will output the first prime polynomial found, so if all you want is to just find one prime polynomial to generate the LUT for Reed-Solomon to work, then just use that.<br><br>    # A prime polynomial (necessarily irreducible) is necessary to reduce the multiplications in the Galois Field, so as to avoid overflows.<br>    # Why do we need a "prime polynomial"? Can't we just reduce modulo 255 (for GF(2^8) for example)? Because we need the values to be unique.<br>    # For example: if the generator (alpha) = 2 and c_exp = 8 (GF(2^8) == GF(256)), then the generated Galois Field (0, 1, α, α^1, α^2, ..., α^(p-1)) will be galois field it becomes 0, 1, 2, 4, 8, 16, etc. However, upon reaching 128, the next value will be doubled (ie, next power of 2), which will give 256. Then we must reduce, because we have overflowed above the maximum value of 255. But, if we modulo 255, this will generate 256 == 1. Then 2, 4, 8, 16, etc. giving us a repeating pattern of numbers. This is very bad, as it's then not anymore a bijection (ie, a non-zero value doesn't have a unique index). That's why we can't just modulo 255, but we need another number above 255, which is called the prime polynomial.<br>    # Why so much hassle? Because we are using precomputed look-up tables for multiplication: instead of multiplying ab, we precompute alpha^a, alpha^b and alpha^(a+b), so that we can just use our lookup table at alpha^(a+b) and get our result. But just like in our original field we had 0,1,2,...,p-1 distinct unique values, in our "LUT" field using alpha we must have unique distinct values (we don't care that they are different from the original field as long as they are unique and distinct). That's why we need to avoid duplicated values, and to avoid duplicated values we need to use a prime irreducible polynomial.<br><br>    # Here is implemented a bruteforce approach to find all these prime polynomials, by generating every possible prime polynomials (ie, every integers between field_charac+1 and field_charac2), and then we build the whole Galois Field, and we reject the candidate prime polynomial if it duplicates even one value or if it generates a value above field_charac (ie, cause an overflow).<br>    # Note that this algorithm is slow if the field is too big (above 12), because it's an exhaustive search algorithm. There are probabilistic approaches, and almost surely prime approaches, but there is no determistic polynomial time algorithm to find irreducible monic polynomials. More info can be found at: http://people.mpi-inf.mpg.de/~csaha/lectures/lec9.pdf<br>    # Another faster algorithm may be found at Adleman, Leonard M., and Hendrik W. Lenstra. "Finding irreducible polynomials over finite fields." Proceedings of the eighteenth annual ACM symposium on Theory of computing. ACM, 1986.<br><br>    # Prepare the finite field characteristic (2^p - 1), this also represent the maximum possible value in this field<br>    root_charac = 2 # we're in GF(2)<br>    field_charac = int(root_characc_exp - 1)<br>    field_charac_next = int(root_charac(c_exp+1) - 1)<br><br>    prim_candidates = []<br>    if fast_primes:<br>        prim_candidates = rwh_primes1(field_charac_next) # generate maybe prime polynomials and check later if they really are irreducible<br>        prim_candidates = [x for x in prim_candidates if x  field_charac] # filter out too small primes<br>    else:<br>        prim_candidates = _range(field_charac+2, field_charac_next, root_charac) # try each possible prime polynomial, but skip even numbers (because divisible by 2 so necessarily not irreducible)<br><br>    # Start of the main loop<br>    correct_primes = []<br>    for prim in prim_candidates: # try potential candidates primitive irreducible polys<br>        seen = bytearray(field_charac+1) # memory variable to indicate if a value was already generated in the field (value at index x is set to 1) or not (set to 0 by default)<br>        conflict = False # flag to know if there was at least one conflict<br><br>        # Second loop, build the whole Galois Field<br>        x = GF2int(1)<br>        for i in _range(field_charac):<br>            # Compute the next value in the field (ie, the next power of alpha/generator)<br>            x = x.multiply(generator, prim, field_charac+1)<br><br>            # Rejection criterion: if the value overflowed (above field_charac) or is a duplicate of a previously generated power of alpha, then we reject this polynomial (not prime)<br>            if x  field_charac or seen[x] == 1:<br>                conflict = True<br>                break<br>            # Else we flag this value as seen (to maybe detect future duplicates), and we continue onto the next power of alpha<br>            else:<br>                seen[x] = 1<br><br>        # End of the second loop: if there's no conflict (no overflow nor duplicated value), this is a prime polynomial!<br>        if not conflict: <br>            correct_primes.append(prim)<br>            if single: return prim<br><br>    # Return the list of all prime polynomials<br>    return correct_primes

### DOC[5] (IRRELEVANT) leetcode/csn_python_train_226519.txt
> def find_prime_polys(generator=2, c_exp=8, fast_primes=False, single=False):<br>    '''Compute the list of prime polynomials for the given generator and galois field characteristic exponent.'''<br>    # fast_primes will output less results but will be significantly faster.<br>    # single will output the first prime polynomial found, so if all you want is to just find one prime polynomial to generate the LUT for Reed-Solomon to work, then just use that.<br><br>    # A prime polynomial (necessarily irreducible) is necessary to reduce the multiplications in the Galois Field, so as to avoid overflows.<br>    # Why do we need a "prime polynomial"? Can't we just reduce modulo 255 (for GF(2^8) for example)? Because we need the values to be unique.<br>    # For example: if the generator (alpha) = 2 and c_exp = 8 (GF(2^8) == GF(256)), then the generated Galois Field (0, 1, α, α^1, α^2, ..., α^(p-1)) will be galois field it becomes 0, 1, 2, 4, 8, 16, etc. However, upon reaching 128, the next value will be doubled (ie, next power of 2), which will give 256. Then we must reduce, because we have overflowed above the maximum value of 255. But, if we modulo 255, this will generate 256 == 1. Then 2, 4, 8, 16, etc. giving us a repeating pattern of numbers. This is very bad, as it's then not anymore a bijection (ie, a non-zero value doesn't have a unique index). That's why we can't just modulo 255, but we need another number above 255, which is called the prime polynomial.<br>    # Why so much hassle? Because we are using precomputed look-up tables for multiplication: instead of multiplying ab, we precompute alpha^a, alpha^b and alpha^(a+b), so that we can just use our lookup table at alpha^(a+b) and get our result. But just like in our original field we had 0,1,2,...,p-1 distinct unique values, in our "LUT" field using alpha we must have unique distinct values (we don't care that they are different from the original field as long as they are unique and distinct). That's why we need to avoid duplicated values, and to avoid duplicated values we need to use a prime irreducible polynomial.<br><br>    # Here is implemented a bruteforce approach to find all these prime polynomials, by generating every possible prime polynomials (ie, every integers between field_charac+1 and field_charac2), and then we build the whole Galois Field, and we reject the candidate prime polynomial if it duplicates even one value or if it generates a value above field_charac (ie, cause an overflow).<br>    # Note that this algorithm is slow if the field is too big (above 12), because it's an exhaustive search algorithm. There are probabilistic approaches, and almost surely prime approaches, but there is no determistic polynomial time algorithm to find irreducible monic polynomials. More info can be found at: http://people.mpi-inf.mpg.de/~csaha/lectures/lec9.pdf<br>    # Another faster algorithm may be found at Adleman, Leonard M., and Hendrik W. Lenstra. "Finding irreducible polynomials over finite fields." Proceedings of the eighteenth annual ACM symposium on Theory of computing. ACM, 1986.<br><br>    # Prepare the finite field characteristic (2^p - 1), this also represent the maximum possible value in this field<br>    root_charac = 2 # we're in GF(2)<br>    field_charac = int(root_characc_exp - 1)<br>    field_charac_next = int(root_charac(c_exp+1) - 1)<br><br>    prim_candidates = []<br>    if fast_primes:<br>        prim_candidates = rwh_primes1(field_charac_next) # generate maybe prime polynomials and check later if they really are irreducible<br>        prim_candidates = [x for x in prim_candidates if x  field_charac] # filter out too small primes<br>    else:<br>        prim_candidates = xrange(field_charac+2, field_charac_next, root_charac) # try each possible prime polynomial, but skip even numbers (because divisible by 2 so necessarily not irreducible)<br><br>    # Start of the main loop<br>    correct_primes = []<br>    for prim in prim_candidates: # try potential candidates primitive irreducible polys<br>        seen = bytearray(field_charac+1) # memory variable to indicate if a value was already generated in the field (value at index x is set to 1) or not (set to 0 by default)<br>        conflict = False # flag to know if there was at least one conflict<br><br>        # Second loop, build the whole Galois Field<br>        x = 1<br>        for i in xrange(field_charac):<br>            # Compute the next value in the field (ie, the next power of alpha/generator)<br>            x = gf_mult_noLUT(x, generator, prim, field_charac+1)<br><br>            # Rejection criterion: if the value overflowed (above field_charac) or is a duplicate of a previously generated power of alpha, then we reject this polynomial (not prime)<br>            if x  field_charac or seen[x] == 1:<br>                conflict = True<br>                break<br>            # Else we flag this value as seen (to maybe detect future duplicates), and we continue onto the next power of alpha<br>            else:<br>                seen[x] = 1<br><br>        # End of the second loop: if there's no conflict (no overflow nor duplicated value), this is a prime polynomial!<br>        if not conflict: <br>            correct_primes.append(prim)<br>            if single: return prim<br><br>    # Return the list of all prime polynomials<br>    return correct_primes


## Ground Truth

### GROUND TRUTH 0, ranked not in top 100, leetcode/leetcode_2157.txt
> from heapq import heappop, heappush<br>    """You are given a 0-indexed array of strings `words`. Each string consists of lowercase English letters only. No letter occurs more than once in any string of `words`.<br><br>Two strings `s1` and `s2` are said to be connected if the set of letters of `s2` can be obtained from the set of letters of `s1` by any one of the following operations:<br><br>   Adding exactly one letter to the set of the letters of `s1`.<br>   Deleting exactly one letter from the set of the letters of `s1`.<br>   Replacing exactly one letter from the set of the letters of `s1` with any letter, including itself.<br><br>The array `words` can be divided into one or more non-intersecting groups. A string belongs to a group if any one of the following is true:<br><br>   It is connected to at least one other string of the group.<br>   It is the only string present in the group.<br><br>Note that the strings in `words` should be grouped in such a manner that a string belonging to a group cannot be connected to a string present in any other group. It can be proved that such an arrangement is always unique.<br><br>Return _an array_ `ans` _of size_ `2` _where:_<br><br>   `ans[0]` _is the maximum number of groups_ `words` _can be divided into, and_<br>   `ans[1]` _is the size of the largest group_.<br><br>Example 1:<br><br>Input: words = \[ "a ", "b ", "ab ", "cde "\]<br>Output: \[2,3\]<br>Explanation:<br>- words\[0\] can be used to obtain words\[1\] (by replacing 'a' with 'b'), and words\[2\] (by adding 'b'). So words\[0\] is connected to words\[1\] and words\[2\].<br>- words\[1\] can be used to obtain words\[0\] (by replacing 'b' with 'a'), and words\[2\] (by adding 'a'). So words\[1\] is connected to words\[0\] and words\[2\].<br>- words\[2\] can be used to obtain words\[0\] (by deleting 'b'), and words\[1\] (by deleting 'a'). So words\[2\] is connected to words\[0\] and words\[1\].<br>- words\[3\] is not connected to any string in words.<br>Thus, words can be divided into 2 groups \[ "a ", "b ", "ab "\] and \[ "cde "\]. The size of the largest group is 3.  <br><br>Example 2:<br><br>Input: words = \[ "a ", "ab ", "abc "\]<br>Output: \[1,3\]<br>Explanation:<br>- words\[0\] is connected to words\[1\].<br>- words\[1\] is connected to words\[0\] and words\[2\].<br>- words\[2\] is connected to words\[1\].<br>Since all strings are connected to each other, they should be grouped together.<br>Thus, the size of the largest group is 3.<br><br>Constraints:<br><br>   `1 <= words.length <= 2  104`<br>   `1 <= words[i].length <= 26`<br>   `words[i]` consists of lowercase English letters only.<br>   No letter occurs more than once in `words[i]`."""<br><br><br>def smallest_subsequence(s, k, letter, repetition):<br>    result = []<br>    letter_count = s.count(letter)<br><br>    pq = []<br>    for c in s:<br>        if c <= letter or letter_count  repetition:<br>            while pq and pq[0]  c:<br>                if heappop(pq) == letter:<br>                    letter_count -= 1<br>            heappush(pq, c)<br>            if len(pq)  k:<br>                heappop(pq)<br>        if k - len(pq) == repetition:<br>            letter_count -= 1<br>        repetition = max(0, repetition)<br><br>    return "".join(pq)

### GROUND TRUTH 1, ranked 13, leetcode/leetcode_2521.txt
> def count_distinct_prime_factors(nums):<br>    """Given an array of positive integers `nums`, return _the number of distinct prime factors in the product of the elements of_ `nums`.<br><br>Note that:<br><br>   A number greater than `1` is called prime if it is divisible by only `1` and itself.<br>   An integer `val1` is a factor of another integer `val2` if `val2 / val1` is an integer.<br><br>Example 1:<br><br>Input: nums = \[2,4,3,7,10,6\]<br>Output: 4<br>Explanation:<br>The product of all the elements in nums is: 2 \ 4 \ 3 \ 7 \ 10 \ 6 = 10080 = 25 \ 32 \ 5 \ 7.<br>There are 4 distinct prime factors so we return 4.<br><br>Example 2:<br><br>Input: nums = \[2,4,8,16\]<br>Output: 1<br>Explanation:<br>The product of all the elements in nums is: 2 \ 4 \ 8 \ 16 = 1024 = 210.<br>There is 1 distinct prime factor so we return 1.<br><br>Constraints:<br><br>   `1 <= nums.length <= 104`<br>   `2 <= nums[i] <= 1000`"""<br><br>    prime_factors = set()<br>    for n in nums:<br>        for divisor in range(2, int(n0.5) + 1):<br>            if n % divisor == 0:<br>                prime_factors.add(divisor)<br>                prime_factors.add(n // divisor)<br>    return len(prime_factors)
