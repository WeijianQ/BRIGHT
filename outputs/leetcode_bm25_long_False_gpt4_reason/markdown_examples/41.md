# Query `41`

## Original Question

*There is an undirected connected tree with `n` nodes labeled from `0` to `n - 1` and `n - 1` edges.

You are given the integer `n` and the array `edges` where `edges[i] = [ai, bi]` indicates that there is an edge between nodes `ai` and `bi` in the tree.

Return an array `answer` of length `n` where `answer[i]` is the sum of the distances between the `ith` node in the tree and all other nodes.

Example 1:

Input: n = 6, edges = \[\[0,1\],\[0,2\],\[2,3\],\[2,4\],\[2,5\]\]
Output: \[8,12,6,10,10,10\]
Explanation: The tree is shown above.
We can see that dist(0,1) + dist(0,2) + dist(0,3) + dist(0,4) + dist(0,5)
equals 1 + 1 + 2 + 2 + 2 = 8.
Hence, answer\[0\] = 8, and so on.

Example 2:

Input: n = 1, edges = \[\]
Output: \[0\]

Example 3:

Input: n = 2, edges = \[\[1,0\]\]
Output: \[1,1\]

Constraints:

   `1 <= n <= 3  104`
   `edges.length == n - 1`
   `edges[i].length == 2`
   `0 <= ai, bi < n`
   `ai != bi`
   The given input represents a valid tree.*

## gpt4 Reasoning

```markdown
The essential problem here is to calculate the sum of distances from each node to all other nodes in an undirected connected tree. The main challenge arises from the need to efficiently calculate these distances without redundantly traversing the same paths multiple times, especially considering the constraint that `n` can be as large as `3 * 10^4`.

### Step-by-step Solution

1. **Understand Tree Properties**: In a tree, there is exactly one path between any two nodes. This means we can use depth-first search (DFS) or breadth-first search (BFS) to find distances between nodes. However, calculating the distance from each node to all others individually would result in a time complexity of O(n^2), which is inefficient for large `n`.

2. **Optimize with Post-order and Pre-order Traversals**: To optimize, we can use a two-pass DFS approach (similar to combining post-order and pre-order traversals) to calculate distances in a more efficient manner.

    - **First Pass (Post-order Traversal)**: Calculate the size of each subtree and the sum of distances from each node to nodes in its subtree. In this pass, we essentially calculate for each node, how many nodes are below it in the tree (including itself) and the sum of distances from it to these nodes.
    
    - **Second Pass (Pre-order Traversal)**: Use the information from the first pass to calculate the answer for each node. The idea is to propagate the distances calculated for the parent node to its children, adjusting for the fact that moving from a parent to a child increases the distance by 1 for nodes in the subtree rooted at the child, but decreases it by 1 for all other nodes in the tree.

3. **Implementation Details**:
    - During the first pass, for each node, we keep track of the count of nodes in its subtree (including itself) and the total distance of these nodes from it.
    - During the second pass, when moving from a parent node to a child node, we know the total number of nodes in the tree (`n`), and we have calculated the total number of nodes in the subtree of the child. With this, we can calculate the sum of distances for the child node based on the parent's distances.

4. **Algorithm**:
    - Initialize two arrays, `count` and `res`, both of size `n`. `count[i]` will store the number of nodes in the subtree rooted at `i`, and `res[i]` will store the sum of distances from node `i` to all nodes in its subtree.
    - Perform a DFS from the root (any node can be considered as the root, but typically we start from 0), to fill out `count` and `res`.
    - Perform another DFS to calculate the final distances for each node using the `count` and `res` arrays, adjusting the distances based on whether nodes are within the subtree or outside it.
    - Return the `res` array as the answer.

### Complexity Analysis

- **Time Complexity**: O(n). Each node is visited exactly twice in the DFS traversals, making the algorithm linear in the number of nodes.
- **Space Complexity**: O(n). Apart from the input, the space is used for the `count` and `res` arrays, and the recursive call stack during DFS, which in the worst case (completely unbalanced tree) could go up to `n`.

### Conclusion

This approach efficiently calculates the required distances by leveraging the structure of the tree and the properties of distances within it. By avoiding redundant calculations and using a two-pass DFS, we can solve the problem within the given constraints.
```

### Metrics

```
recip_rank: 0.3333
P_1: 0.0000
P_5: 0.2000
P_10: 0.3000
P_25: 0.1200
P_50: 0.0600
P_100: 0.0300
recall_1: 0.0000
recall_5: 0.3333
recall_10: 1.0000
recall_25: 1.0000
recall_50: 1.0000
recall_100: 1.0000
ndcg_cut_1: 0.0000
ndcg_cut_5: 0.2346
ndcg_cut_10: 0.5582
ndcg_cut_25: 0.5582
ndcg_cut_50: 0.5582
ndcg_cut_100: 0.5582
map_cut_1: 0.0000
map_cut_5: 0.1111
map_cut_10: 0.3651
map_cut_25: 0.3651
map_cut_50: 0.3651
map_cut_100: 0.3651
```

## Retrieval Results

### DOC[1] (IRRELEVANT) leetcode/csn_python_train_222703.txt
> def get_children( self, kwargs ):<br>        ''' Recursively collects and returns all subtrees of given tree (if no <br>            arguments are given), or, alternatively, collects and returns subtrees <br>            satisfying some specific criteria (pre-specified in the arguments);<br>            <br>            Parameters<br>            -----------<br>            depth_limit : int<br>                Specifies how deep into the subtrees of this tree the search goes;<br>                Examples:<br>                 depth_limit=2 -- children of this node, and also children's<br>                                  direct children are considered as collectibles;<br>                 depth_limit=1 -- only children of this node are considered;<br>                 depth_limit=0 -- the end of search (only this node is considered);<br>                Default: unbounded ( the search is not limited by depth )<br>            <br>            include_self : bool <br>                Specifies whether this tree should also be included as a collectible<br>                subtree. If this tree is includes, it still must satisfy all the <br>                criteria before it is included in the collection;<br>                Default: False<br>            <br>            sorted : bool<br>                Specifies returned trees should be sorted in the ascending order of <br>                word_ids (basically: by the order of words in the text);<br>                If sorting is not applied, there is no guarantee that resulting trees<br>                follow the order of words in text;<br>                Default: False<br>                <br>            Following parameters can be used to set conditions for subtrees:<br>            -----------------------------------------------------------------<br>            label : str<br>                Syntactic label (e.g. '@SUBJ', '@OBJ' etc.) that the node <br>                must have within its analysis; If the node does not have the<br>                label, the node will be discarded;<br>            <br>            label_regexp : str<br>                A regular expression pattern (as string) describing the <br>                syntactic label (e.g. '@SUBJ', '@OBJ' etc.) that the node <br>                must have within its analysis; <br>                If none of the node's labels matches the pattern, the node<br>                will be discarded;<br>            <br>            word_template : estnltk.mw_verbs.utils.WordTemplate<br>                A WordTemplate describing morphological constraints imposed<br>                to the word of the node;<br>                If the word's morphological features do not match the template, <br>                the node will be discarded;<br>            <br>        '''<br>        depth_limit  = kwargs.get('depth_limit', 922337203685477580) # Just a nice big number to<br>                                                                     # assure that by default, <br>                                                                     # there is no depth limit ...<br>        include_self = kwargs.get('include_self', False)<br>        sorted_by_word_ids = kwargs.get('sorted', False)<br>        subtrees = []<br>        if include_self:<br>            if self._satisfies_conditions( self, kwargs ):<br>                subtrees.append( self )<br>        if depth_limit = 1 and self.children:<br>            # 1) Add children of given tree<br>            for child in self.children:<br>                if self._satisfies_conditions( child, kwargs ):<br>                    subtrees.append(child)<br>            # 2) Collect children of given tree's children<br>            kwargs['include_self'] = False<br>            kwargs['depth_limit']  = depth_limit - 1 <br>            for child in self.children:<br>                childs_results = child.get_children( kwargs )<br>                if childs_results:<br>                    subtrees.extend(childs_results)<br>        if sorted_by_word_ids:<br>            # Sort by word_id-s, in ascending order<br>            subtrees = sorted(subtrees, key=lambda x: x.word_id)<br>        return subtrees

### DOC[2] (IRRELEVANT) leetcode/csn_python_train_144454.txt
> def avoid_dead_links(root, machine, wrap_around=False):<br>    """Modify a RoutingTree to route-around dead links in a Machine.<br><br>    Uses A to reconnect disconnected branches of the tree (due to dead links<br>    in the machine).<br><br>    Parameters<br>    ----------<br>    root : :py:class:`~rig.place_and_route.routing_tree.RoutingTree`<br>        The root of the RoutingTree which contains nothing but RoutingTrees<br>        (i.e. no vertices and links).<br>    machine : :py:class:`~rig.place_and_route.Machine`<br>        The machine in which the routes exist.<br>    wrap_around : bool<br>        Consider wrap-around links in pathfinding heuristics.<br><br>    Returns<br>    -------<br>    (:py:class:`~.rig.place_and_route.routing_tree.RoutingTree`,<br>     {(x,y): :py:class:`~.rig.place_and_route.routing_tree.RoutingTree`, ...})<br>        A new RoutingTree is produced rooted as before. A dictionarry mapping<br>        from (x, y) to the associated RoutingTree is provided for convenience.<br><br>    Raises<br>    ------<br>    :py:class:~rig.place_and_route.exceptions.MachineHasDisconnectedSubregion`<br>        If a path to reconnect the tree cannot be found.<br>    """<br>    # Make a copy of the RoutingTree with all broken parts disconnected<br>    root, lookup, broken_links = copy_and_disconnect_tree(root, machine)<br><br>    # For each disconnected subtree, use A to connect the tree to any other<br>    # disconnected subtree. Note that this process will eventually result in<br>    # all disconnected subtrees being connected, the result is a fully<br>    # connected tree.<br>    for parent, child in broken_links:<br>        child_chips = set(c.chip for c in lookup[child])<br><br>        # Try to reconnect broken links to any other part of the tree<br>        # (excluding this broken subtree itself since that would create a<br>        # cycle).<br>        path = a_star(child, parent,<br>                      set(lookup).difference(child_chips),<br>                      machine, wrap_around)<br><br>        # Add new RoutingTree nodes to reconnect the child to the tree.<br>        last_node = lookup[path[0][1]]<br>        last_direction = path[0][0]<br>        for direction, (x, y) in path[1:]:<br>            if (x, y) not in child_chips:<br>                # This path segment traverses new ground so we must create a<br>                # new RoutingTree for the segment.<br>                new_node = RoutingTree((x, y))<br>                # A will not traverse anything but chips in this tree so this<br>                # assert is meerly a sanity check that this ocurred correctly.<br>                assert (x, y) not in lookup, "Cycle created."<br>                lookup[(x, y)] = new_node<br>            else:<br>                # This path segment overlaps part of the disconnected tree<br>                # (A doesn't know where the disconnected tree is and thus<br>                # doesn't avoid it). To prevent cycles being introduced, this<br>                # overlapped node is severed from its parent and merged as part<br>                # of the A path.<br>                new_node = lookup[(x, y)]<br><br>                # Find the node's current parent and disconnect it.<br>                for node in lookup[child]:  # pragma: no branch<br>                    dn = [(d, n) for d, n in node.children if n == new_node]<br>                    assert len(dn) <= 1<br>                    if dn:<br>                        node.children.remove(dn[0])<br>                        # A node can only have one parent so we can stop now.<br>                        break<br>            last_node.children.append((Routes(last_direction), new_node))<br>            last_node = new_node<br>            last_direction = direction<br>        last_node.children.append((last_direction, lookup[child]))<br><br>    return (root, lookup)

### DOC[3] (GROUND TRUTH) leetcode/leetcode_2603.txt
> from collections import defaultdict<br>    """There exists an undirected and unrooted tree with `n` nodes indexed from `0` to `n - 1`. You are given an integer `n` and a 2D integer array edges of length `n - 1`, where `edges[i] = [ai, bi]` indicates that there is an edge between nodes `ai` and `bi` in the tree. You are also given an array `coins` of size `n` where `coins[i]` can be either `0` or `1`, where `1` indicates the presence of a coin in the vertex `i`.<br><br>Initially, you choose to start at any vertex in the tree. Then, you can perform the following operations any number of times:<br><br>   Collect all the coins that are at a distance of at most `2` from the current vertex, or<br>   Move to any adjacent vertex in the tree.<br><br>Find _the minimum number of edges you need to go through to collect all the coins and go back to the initial vertex_.<br><br>Note that if you pass an edge several times, you need to count it into the answer several times.<br><br>Example 1:<br><br>Input: coins = \[1,0,0,0,0,1\], edges = \[\[0,1\],\[1,2\],\[2,3\],\[3,4\],\[4,5\]\]<br>Output: 2<br>Explanation: Start at vertex 2, collect the coin at vertex 0, move to vertex 3, collect the coin at vertex 5 then move back to vertex 2.<br><br>Example 2:<br><br>Input: coins = \[0,0,0,1,1,0,0,1\], edges = \[\[0,1\],\[0,2\],\[1,3\],\[1,4\],\[2,5\],\[5,6\],\[5,7\]\]<br>Output: 2<br>Explanation: Start at vertex 0, collect the coins at vertices 4 and 3, move to vertex 2,  collect the coin at vertex 7, then move back to vertex 0.<br><br>Constraints:<br><br>   `n == coins.length`<br>   `1 <= n <= 3  104`<br>   `0 <= coins[i] <= 1`<br>   `edges.length == n - 1`<br>   `edges[i].length == 2`<br>   `0 <= ai, bi < n`<br>   `ai != bi`<br>   `edges` represents a valid tree."""<br><br><br>def min_edges_to_collect_coins(coins, edges):<br>    adj = defaultdict(list)<br>    for a, b in edges:<br>        adj[a].append(b)<br>        adj[b].append(a)<br>    return dfs(adj, coins, 0, -1)[1] // 2<br><br>def dfs(adj, coins, node, parent):<br>    sum_coins = coins[node]<br>    distance = 0<br>    for neighbor in adj[node]:<br>        if neighbor != parent:<br>            result = dfs(adj, coins, neighbor, node)<br>            sum_coins += result[0]<br>            distance += 2  result[0] + result[1]<br>    return (sum_coins, distance)

### DOC[4] (IRRELEVANT) leetcode/csn_python_train_320959.txt
> def cut_nodes_edges2(graph):<br>    """Bi-connected components, alternative recursive implementation<br><br>    :param graph: undirected graph. in listlist format. Cannot be in listdict format.<br>    :assumes: graph has about 5000 vertices at most, otherwise memory limit is reached<br>    :returns: a tuple with the list of cut-nodes and the list of cut-edges<br>    :complexity: `O(|V|+|E|)` in average, `O(|V|+|E|^2)` in worst case due to use of dictionary<br>    """<br>    N = len(graph)<br>    assert N <= 5000<br>    recursionlimit = getrecursionlimit()<br>    setrecursionlimit(max(recursionlimit, N + 42))<br>    edges = set((i, j) for i in range(N) for j in graph[i] if i <= j)<br>    nodes = set()<br>    NOT = -2  # not visited yet; -1 would be buggy `marked[v] != prof - 1`<br>    FIN = -3  # already visited<br>    marked = [NOT]  N  # if = 0, it means depth within the DFS<br><br>    def DFS(n, prof=0):<br>        """<br>        Recursively search graph, update edge list and returns the first<br>        node the first edge within search to which we can come back.<br>        """<br>        if marked[n] == FIN:<br>            return  # only when there are several connected components<br>        if marked[n] != NOT:<br>            return marked[n]<br>        marked[n] = prof<br>        m = float('inf')<br>        count = 0  # useful only for prof == 0<br>        for v in graph[n]:<br>            if marked[v] != FIN and marked[v] != prof - 1:<br>                count += 1<br>                r = DFS(v, prof+1)<br>                if r <= prof:<br>                    edges.discard(tuple(sorted((n, v))))<br>                if prof and r = prof:  # only if we are not at root<br>                    nodes.add(n)<br>                m = min(m, r)<br>        # root is an articulation point iff it has more than 2 childs<br>        if prof == 0 and count = 2:<br>            nodes.add(n)<br>        marked[n] = FIN<br>        return m<br>    for r in range(N):<br>        DFS(r)  # we can count connected components by nb += DFS(r)<br>    setrecursionlimit(recursionlimit)<br>    return nodes, edges

### DOC[5] (IRRELEVANT) leetcode/csn_python_train_15659.txt
> def create(dataset, label=None, features=None, distance=None, method='auto',<br>           verbose=True, kwargs):<br>    """<br>    Create a nearest neighbor model, which can be searched efficiently and<br>    quickly for the nearest neighbors of a query observation. If the `method`<br>    argument is specified as `auto`, the type of model is chosen automatically<br>    based on the type of data in `dataset`.<br><br>    .. warning::<br><br>        The 'dot_product' distance is deprecated and will be removed in future<br>        versions of Turi Create. Please use 'transformed_dot_product'<br>        distance instead, although note that this is more than a name change;<br>        it is a different transformation of the dot product of two vectors.<br>        Please see the distances module documentation for more details.<br><br>    Parameters<br>    ----------<br>    dataset : SFrame<br>        Reference data. If the features for each observation are numeric, they<br>        may be in separate columns of 'dataset' or a single column with lists<br>        of values. The features may also be in the form of a column of sparse<br>        vectors (i.e. dictionaries), with string keys and numeric values.<br><br>    label : string, optional<br>        Name of the SFrame column with row labels. If 'label' is not specified,<br>        row numbers are used to identify reference dataset rows when the model<br>        is queried.<br><br>    features : list[string], optional<br>        Name of the columns with features to use in computing distances between<br>        observations and the query points. 'None' (the default) indicates that<br>        all columns except the label should be used as features. Each column<br>        can be one of the following types:<br><br>        - Numeric: values of numeric type integer or float.<br><br>        - Array: list of numeric (integer or float) values. Each list element<br>          is treated as a separate variable in the model.<br><br>        - Dictionary: key-value pairs with numeric (integer or float) values.<br>          Each key indicates a separate variable in the model.<br><br>        - List: list of integer or string values. Each element is treated as<br>          a separate variable in the model.<br><br>        - String: string values.<br><br>        Please note: if a composite distance is also specified, this parameter<br>        is ignored.<br><br>    distance : string, function, or list[list], optional<br>        Function to measure the distance between any two input data rows. This<br>        may be one of three types:<br><br>        - String: the name of a standard distance function. One of<br>          'euclidean', 'squared_euclidean', 'manhattan', 'levenshtein',<br>          'jaccard', 'weighted_jaccard', 'cosine', 'dot_product' (deprecated),<br>          or 'transformed_dot_product'.<br><br>        - Function: a function handle from the<br>          :mod:`~turicreate.toolkits.distances` module.<br><br>        - Composite distance: the weighted sum of several standard distance<br>          functions applied to various features. This is specified as a list of<br>          distance components, each of which is itself a list containing three<br>          items:<br><br>          1. list or tuple of feature names (strings)<br><br>          2. standard distance name (string)<br><br>          3. scaling factor (int or float)<br><br>        For more information about Turi Create distance functions, please<br>        see the :py:mod:`~turicreate.toolkits.distances` module.<br><br>        If 'distance' is left unspecified or set to 'auto', a composite<br>        distance is constructed automatically based on feature types.<br><br>    method : {'auto', 'ball_tree', 'brute_force', 'lsh'}, optional<br>        Method for computing nearest neighbors. The options are:<br><br>        - auto (default): the method is chosen automatically, based on the<br>          type of data and the distance. If the distance is 'manhattan' or<br>          'euclidean' and the features are numeric or vectors of numeric<br>          values, then the 'ball_tree' method is used. Otherwise, the<br>          'brute_force' method is used.<br><br>        - ball_tree: use a tree structure to find the k-closest neighbors to<br>          each query point. The ball tree model is slower to construct than the<br>          brute force model, but queries are faster than linear time. This<br>          method is not applicable for the cosine and dot product distances.<br>          See `Liu, et al (2004)<br>          <http://papers.nips.cc/paper/2666-an-investigation-of-p<br>          ractical-approximat e-nearest-neighbor-algorithms`_ for<br>          implementation details.<br><br>        - brute_force: compute the distance from a query point to all<br>          reference observations. There is no computation time for model<br>          creation with the brute force method (although the reference data is<br>          held in the model, but each query takes linear time.<br><br>        - lsh: use Locality Sensitive Hashing (LSH) to find approximate<br>          nearest neighbors efficiently. The LSH model supports 'euclidean',<br>          'squared_euclidean', 'manhattan', 'cosine', 'jaccard', 'dot_product'<br>          (deprecated), and 'transformed_dot_product' distances. Two options<br>          are provided for LSH -- ``num_tables`` and<br>          ``num_projections_per_table``. See the notes below for details.<br><br>    verbose: bool, optional<br>        If True, print progress updates and model details.<br><br>    kwargs : optional<br>        Options for the distance function and query method.<br><br>        - leaf_size: for the ball tree method, the number of points in each<br>          leaf of the tree. The default is to use the max of 1,000 and<br>          n/(2^11), which ensures a maximum tree depth of 12.<br><br>        - num_tables: For the LSH method, the number of hash tables<br>          constructed. The default value is 20. We recommend choosing values<br>          from 10 to 30.<br><br>        - num_projections_per_table: For the LSH method, the number of<br>          projections/hash functions for each hash table. The default value is<br>          4 for 'jaccard' distance, 16 for 'cosine' distance and 8 for other<br>          distances. We recommend using number 2 ~ 6 for 'jaccard' distance, 8<br>          ~ 20 for 'cosine' distance and 4 ~ 12 for other distances.<br><br>    Returns<br>    -------<br>    out : NearestNeighborsModel<br>        A structure for efficiently computing the nearest neighbors in 'dataset'<br>        of new query points.<br><br>    See Also<br>    --------<br>    NearestNeighborsModel.query, turicreate.toolkits.distances<br><br>    Notes<br>    -----<br>    - Missing data is not allowed in the 'dataset' provided to this function.<br>      Please use the :func:`turicreate.SFrame.fillna` and<br>      :func:`turicreate.SFrame.dropna` utilities to handle missing data before<br>      creating a nearest neighbors model.<br><br>    - Missing keys in sparse vectors are assumed to have value 0.<br><br>    - The `composite_params` parameter was removed as of Turi Create<br>      version 1.5. The `distance` parameter now accepts either standard or<br>      composite distances. Please see the :mod:`~turicreate.toolkits.distances`<br>      module documentation for more information on composite distances.<br><br>    - If the features should be weighted equally in the distance calculations<br>      but are measured on different scales, it is important to standardize the<br>      features. One way to do this is to subtract the mean of each column and<br>      divide by the standard deviation.<br><br>    Locality Sensitive Hashing (LSH)<br><br>    There are several efficient nearest neighbors search algorithms that work<br>    well for data with low dimensions :math:`d` (approximately 50). However,<br>    most of the solutions suffer from either space or query time that is<br>    exponential in :math:`d`. For large :math:`d`, they often provide little,<br>    if any, improvement over the 'brute_force' method. This is a well-known<br>    consequence of the phenomenon called `The Curse of Dimensionality`.<br><br>    `Locality Sensitive Hashing (LSH)<br>    <https://en.wikipedia.org/wiki/Locality-sensitive_hashing`_ is an approach<br>    that is designed to efficiently solve the approximate nearest neighbor<br>    search problem for high dimensional data. The key idea of LSH is to hash<br>    the data points using several hash functions, so that the probability of<br>    collision is much higher for data points which are close to each other than<br>    those which are far apart.<br><br>    An LSH family is a family of functions :math:`h` which map points from the<br>    metric space to a bucket, so that<br><br>    - if :math:`d(p, q) \\leq R`, then :math:`h(p) = h(q)` with at least probability :math:`p_1`.<br>    - if :math:`d(p, q) \\geq cR`, then :math:`h(p) = h(q)` with probability at most :math:`p_2`.<br><br>    LSH for efficient approximate nearest neighbor search:<br><br>    - We define a new family of hash functions :math:`g`, where each<br>      function :math:`g` is obtained by concatenating :math:`k` functions<br>      :math:`h_1, ..., h_k`, i.e., :math:`g(p)=[h_1(p),...,h_k(p)]`.<br>      The algorithm constructs :math:`L` hash tables, each of which<br>      corresponds to a different randomly chosen hash function :math:`g`.<br>      There are :math:`k \\cdot L` hash functions used in total.<br><br>    - In the preprocessing step, we hash all :math:`n` reference points<br>      into each of the :math:`L` hash tables.<br><br>    - Given a query point :math:`q`, the algorithm iterates over the<br>      :math:`L` hash functions :math:`g`. For each :math:`g` considered, it<br>      retrieves the data points that are hashed into the same bucket as q.<br>      These data points from all the :math:`L` hash tables are considered as<br>      candidates that are then re-ranked by their real distances with the query<br>      data.<br><br>    Note that the number of tables :math:`L` and the number of hash<br>    functions per table :math:`k` are two main parameters. They can be set<br>    using the options ``num_tables`` and ``num_projections_per_table``<br>    respectively.<br><br>    Hash functions for different distances:<br><br>    - `euclidean` and `squared_euclidean`:<br>      :math:`h(q) = \\lfloor \\frac{a \\cdot q + b}{w} \\rfloor` where<br>      :math:`a` is a vector, of which the elements are independently<br>      sampled from normal distribution, and :math:`b` is a number<br>      uniformly sampled from :math:`[0, r]`. :math:`r` is a parameter for the<br>      bucket width. We set :math:`r` using the average all-pair `euclidean`<br>      distances from a small randomly sampled subset of the reference data.<br><br>    - `manhattan`: The hash function of `manhattan` is similar with that of<br>      `euclidean`. The only difference is that the elements of `a` are sampled<br>      from Cauchy distribution, instead of normal distribution.<br><br>    - `cosine`: Random Projection is designed to approximate the cosine<br>      distance between vectors. The hash function is :math:`h(q) = sgn(a \\cdot<br>      q)`, where :math:`a` is randomly sampled normal unit vector.<br><br>    - `jaccard`: We use a recently proposed method one permutation hashing by<br>      Shrivastava and Li. See the paper `[Shrivastava and Li, UAI 2014]<br>      <http://www.auai.org/uai2014/proceedings/individuals/225.pdf`_ for<br>      details.<br><br>    - `dot_product`: The reference data points are first transformed to<br>      fixed-norm vectors, and then the minimum `dot_product` distance search<br>      problem can be solved via finding the reference data with smallest<br>      `cosine` distances. See the paper `[Neyshabur and Srebro, ICML 2015]<br>      <http://proceedings.mlr.press/v37/neyshabur15.html`_ for details.<br><br>    References<br>    ----------<br>    - `Wikipedia - nearest neighbor<br>      search <http://en.wikipedia.org/wiki/Nearest_neighbor_search`_<br><br>    - `Wikipedia - ball tree <http://en.wikipedia.org/wiki/Ball_tree`_<br><br>    - Ball tree implementation: Liu, T., et al. (2004) `An Investigation of<br>      Practical Approximate Nearest Neighbor Algorithms<br>      <http://papers.nips.cc/paper/2666-an-investigation-of-p<br>      ractical-approximat e-nearest-neighbor-algorithms`_. Advances in Neural<br>      Information Processing Systems pp. 825-832.<br><br>    - `Wikipedia - Jaccard distance<br>      <http://en.wikipedia.org/wiki/Jaccard_index`_<br><br>    - Weighted Jaccard distance: Chierichetti, F., et al. (2010) `Finding the<br>      Jaccard Median<br>      <http://theory.stanford.edu/~sergei/papers/soda10-jaccard.pdf`_.<br>      Proceedings of the Twenty-First Annual ACM-SIAM Symposium on Discrete<br>      Algorithms. Society for Industrial and Applied Mathematics.<br><br>    - `Wikipedia - Cosine distance<br>      <http://en.wikipedia.org/wiki/Cosine_similarity`_<br><br>    - `Wikipedia - Levenshtein distance<br>      <http://en.wikipedia.org/wiki/Levenshtein_distance`_<br><br>    - Locality Sensitive Hashing : Chapter 3 of the book `Mining Massive<br>      Datasets <http://infolab.stanford.edu/~ullman/mmds/ch3.pdf`_.<br><br>    Examples<br>    --------<br>    Construct a nearest neighbors model with automatically determined method<br>    and distance:<br><br>     sf = turicreate.SFrame({'X1': [0.98, 0.62, 0.11],<br>    ...                       'X2': [0.69, 0.58, 0.36],<br>    ...                       'str_feature': ['cat', 'dog', 'fossa']})<br>     model = turicreate.nearest_neighbors.create(sf, features=['X1', 'X2'])<br><br>    For datasets with a large number of rows and up to about 100 variables, the<br>    ball tree method often leads to much faster queries.<br><br>     model = turicreate.nearest_neighbors.create(sf, features=['X1', 'X2'],<br>    ...                                           method='ball_tree')<br><br>    Often the final determination of a neighbor is based on several distance<br>    computations over different sets of features. Each part of this composite<br>    distance may have a different relative weight.<br><br>     my_dist = [[['X1', 'X2'], 'euclidean', 2.],<br>    ...            [['str_feature'], 'levenshtein', 3.]]<br>    ...<br>     model = turicreate.nearest_neighbors.create(sf, distance=my_dist)<br>    """<br><br>    ## Validate the 'dataset' input<br>    _tkutl._raise_error_if_not_sframe(dataset, "dataset")<br>    _tkutl._raise_error_if_sframe_empty(dataset, "dataset")<br><br>    ## Basic validation of the features input<br>    if features is not None and not isinstance(features, list):<br>        raise TypeError("If specified, input 'features' must be a list of " +<br>                        "strings.")<br><br>    ## Clean the method options and create the options dictionary<br>    allowed_kwargs = ['leaf_size', 'num_tables', 'num_projections_per_table']<br>    _method_options = {}<br><br>    for k, v in kwargs.items():<br>        if k in allowed_kwargs:<br>            _method_options[k] = v<br>        else:<br>            raise _ToolkitError("'{}' is not a valid keyword argument".format(k) +<br>                                " for the nearest neighbors model. Please " +<br>                                "check for capitalization and other typos.")<br><br><br>    ## Exclude inappropriate combinations of method an distance<br>    if method == 'ball_tree' and (distance == 'cosine'<br>                                  or distance == _turicreate.distances.cosine<br>                                  or distance == 'dot_product'<br>                                  or distance == _turicreate.distances.dot_product<br>                                  or distance == 'transformed_dot_product'<br>                                  or distance == _turicreate.distances.transformed_dot_product):<br>        raise TypeError("The ball tree method does not work with 'cosine' " +<br>                        "'dot_product', or 'transformed_dot_product' distance." +<br>                        "Please use the 'brute_force' method for these distances.")<br><br><br>    if method == 'lsh' and ('num_projections_per_table' not in _method_options):<br>        if distance == 'jaccard' or distance == _turicreate.distances.jaccard:<br>            _method_options['num_projections_per_table'] = 4<br>        elif distance == 'cosine' or distance == _turicreate.distances.cosine:<br>            _method_options['num_projections_per_table'] = 16<br>        else:<br>            _method_options['num_projections_per_table'] = 8<br><br>    ## Initial validation and processing of the label<br>    if label is None:<br>        _label = _robust_column_name('__id', dataset.column_names())<br>        _dataset = dataset.add_row_number(_label)<br>    else:<br>        _label = label<br>        _dataset = _copy.copy(dataset)<br><br>    col_type_map = {c:_dataset[c].dtype for c in _dataset.column_names()}<br>    _validate_row_label(_label, col_type_map)<br>    ref_labels = _dataset[_label]<br><br><br>    ## Determine the internal list of available feature names (may still include<br>    #  the row label name).<br>    if features is None:<br>        _features = _dataset.column_names()<br>    else:<br>        _features = _copy.deepcopy(features)<br><br><br>    ## Check if there's only one feature and it's the same as the row label.<br>    #  This would also be trapped by the composite distance validation, but the<br>    #  error message is not very informative for the user.<br>    free_features = set(_features).difference([_label])<br>    if len(free_features) < 1:<br>        raise _ToolkitError("The only available feature is the same as the " +<br>                            "row label column. Please specify features " +<br>                            "that are not also row labels.")<br><br><br>    ### Validate and preprocess the distance function<br>    ### ---------------------------------------------<br>    # - The form of the 'distance' controls how we interact with the 'features'<br>    #   parameter as well.<br>    # - At this point, the row label 'label' may still be in the list(s) of<br>    #   features.<br><br>    ## Convert any distance function input into a single composite distance.<br>    # distance is already a composite distance<br>    if isinstance(distance, list):<br>        distance = _copy.deepcopy(distance)<br><br>    # distance is a single name (except 'auto') or function handle.<br>    elif (hasattr(distance, '__call__') or<br>        (isinstance(distance, str) and not distance == 'auto')):<br>        distance = [[_features, distance, 1]]<br><br>    # distance is unspecified and needs to be constructed.<br>    elif distance is None or distance == 'auto':<br>        sample = _dataset.head()<br>        distance = _construct_auto_distance(_features,<br>                                            _dataset.column_names(),<br>                                            _dataset.column_types(),<br>                                            sample)<br><br>    else:<br>        raise TypeError("Input 'distance' not understood. The 'distance' "<br>                        " argument must be a string, function handle, or " +<br>                        "composite distance.")<br><br>    ## Basic composite distance validation, remove the row label from all<br>    #  feature lists, and convert string distance names into distance functions.<br>    distance = _scrub_composite_distance_features(distance, [_label])<br>    distance = _convert_distance_names_to_functions(distance)<br>    _validate_composite_distance(distance)<br><br>    ## Raise an error if any distances are used with non-lists<br>    list_features_to_check = []<br>    sparse_distances = ['jaccard', 'weighted_jaccard', 'cosine', 'dot_product', 'transformed_dot_product']<br>    sparse_distances = [_turicreate.distances.__dict__[k] for k in sparse_distances]<br>    for d in distance:<br>        feature_names, dist, _ = d<br>        list_features = [f for f in feature_names if _dataset[f].dtype == list]<br>        for f in list_features:<br>            if dist in sparse_distances:<br>                list_features_to_check.append(f)<br>            else:<br>                raise TypeError("The chosen distance cannot currently be used " +<br>                                "on list-typed columns.")<br>    for f in list_features_to_check:<br>        only_str_lists = _validate_lists(_dataset[f], [str])<br>        if not only_str_lists:<br>            raise TypeError("Distances for sparse data, such as jaccard " +<br>                            "and weighted_jaccard, can only be used on " +<br>                            "lists containing only strings. Please modify " +<br>                            "any list features accordingly before creating " +<br>                            "the nearest neighbors model.")<br><br>    ## Raise an error if any component has string features are in single columns<br>    for d in distance:<br>        feature_names, dist, _ = d<br><br>        if (len(feature_names)  1) and (dist == _turicreate.distances.levenshtein):<br>            raise ValueError("Levenshtein distance cannot be used with multiple " +<br>                             "columns. Please concatenate strings into a single " +<br>                             "column before creating the nearest neighbors model.")<br><br>    ## Get the union of feature names and make a clean dataset.<br>    clean_features = _get_composite_distance_features(distance)<br>    sf_clean = _tkutl._toolkits_select_columns(_dataset, clean_features)<br><br><br>    ## Decide which method to use<br>    ## - If more than one distance component (specified either directly or<br>    #  generated automatically because distance set to 'auto'), then do brute<br>    #  force.<br>    if len(distance)  1:<br>        _method = 'brute_force'<br><br>        if method != 'brute_force' and verbose is True:<br>            print("Defaulting to brute force instead of ball tree because " +\<br>                "there are multiple distance components.")<br><br>    else:<br>        if method == 'auto':<br><br>            # get the total number of variables. Assume the number of elements in<br>            # array type columns does not change<br>            num_variables = sum([len(x) if hasattr(x, '__iter__') else 1<br>                for x in _six.itervalues(sf_clean[0])])<br><br>            # flag if all the features in the single composite are of numeric<br>            # type.<br>            numeric_type_flag = all([x in [int, float, list, array.array]<br>                for x in sf_clean.column_types()])<br><br>            ## Conditions necessary for ball tree to work and be worth it<br>            if ((distance[0][1] in ['euclidean',<br>                                    'manhattan',<br>                                    _turicreate.distances.euclidean,<br>                                    _turicreate.distances.manhattan])<br>                    and numeric_type_flag is True<br>                    and num_variables <= 200):<br><br>                    _method = 'ball_tree'<br><br>            else:<br>                _method = 'brute_force'<br><br>        else:<br>            _method = method<br><br><br>    ## Pick the right model name for the method<br>    if _method == 'ball_tree':<br>        model_name = 'nearest_neighbors_ball_tree'<br><br>    elif _method == 'brute_force':<br>        model_name = 'nearest_neighbors_brute_force'<br><br>    elif _method == 'lsh':<br>        model_name = 'nearest_neighbors_lsh'<br><br>    else:<br>        raise ValueError("Method must be 'auto', 'ball_tree', 'brute_force', " +<br>                         "or 'lsh'.")<br><br><br>    ## Package the model options<br>    opts = {}<br>    opts.update(_method_options)<br>    opts.update(<br>        {'model_name': model_name,<br>        'ref_labels': ref_labels,<br>        'label': label,<br>        'sf_features': sf_clean,<br>        'composite_params': distance})<br><br>    ## Construct the nearest neighbors model<br>    with QuietProgress(verbose):<br>        result = _turicreate.extensions._nearest_neighbors.train(opts)<br><br>    model_proxy = result['model']<br>    model = NearestNeighborsModel(model_proxy)<br><br>    return model


## Ground Truth

### GROUND TRUTH 0, ranked 5, leetcode/leetcode_979.txt
> def decode_permutation(s: str):<br>    """You are given the `root` of a binary tree with `n` nodes where each `node` in the tree has `node.val` coins. There are `n` coins in total throughout the whole tree.<br><br>In one move, we may choose two adjacent nodes and move one coin from one node to another. A move may be from parent to child, or from child to parent.<br><br>Return _the minimum number of moves required to make every node have exactly one coin_.<br><br>Example 1:<br><br>Input: root = \[3,0,0\]<br>Output: 2<br>Explanation: From the root of the tree, we move one coin to its left child, and one coin to its right child.<br><br>Example 2:<br><br>Input: root = \[0,3,0\]<br>Output: 3<br>Explanation: From the left child of the root, we move two coins to the root \[taking two moves\]. Then, we move one coin from the root of the tree to the right child.<br><br>Constraints:<br><br>   The number of nodes in the tree is `n`.<br>   `1 <= n <= 100`<br>   `0 <= Node.val <= n`<br>   The sum of all `Node.val` is `n`."""<br><br>    n = len(s)<br>    perm = [0]  (n + 1)<br>    next_zero, next_one = 0, n<br><br>    for c in s:<br>        if c == '0':<br>            perm[next_zero] = next_one<br>            next_zero += 1<br>            next_one -= 1<br>        else:<br>            perm[next_one] = next_zero<br>            next_one -= 1<br>            next_zero += 1<br><br>    perm[next_zero] = next_one<br>    return perm

### GROUND TRUTH 1, ranked 6, leetcode/leetcode_2049.txt
> def eliminate_monsters(dist, speed):<br>    """There is a binary tree rooted at `0` consisting of `n` nodes. The nodes are labeled from `0` to `n - 1`. You are given a 0-indexed integer array `parents` representing the tree, where `parents[i]` is the parent of node `i`. Since node `0` is the root, `parents[0] == -1`.<br><br>Each node has a score. To find the score of a node, consider if the node and the edges connected to it were removed. The tree would become one or more non-empty subtrees. The size of a subtree is the number of the nodes in it. The score of the node is the product of the sizes of all those subtrees.<br><br>Return _the number of nodes that have the highest score_.<br><br>Example 1:<br><br>Input: parents = \[-1,2,0,2,0\]<br>Output: 3<br>Explanation:<br>- The score of node 0 is: 3 \ 1 = 3<br>- The score of node 1 is: 4 = 4<br>- The score of node 2 is: 1 \ 1 \ 2 = 2<br>- The score of node 3 is: 4 = 4<br>- The score of node 4 is: 4 = 4<br>The highest score is 4, and three nodes (node 1, node 3, and node 4) have the highest score.<br><br>Example 2:<br><br>Input: parents = \[-1,2,0\]<br>Output: 2<br>Explanation:<br>- The score of node 0 is: 2 = 2<br>- The score of node 1 is: 2 = 2<br>- The score of node 2 is: 1 \ 1 = 1<br>The highest score is 2, and two nodes (node 0 and node 1) have the highest score.<br><br>Constraints:<br><br>   `n == parents.length`<br>   `2 <= n <= 105`<br>   `parents[0] == -1`<br>   `0 <= parents[i] <= n - 1` for `i != 0`<br>   `parents` represents a valid binary tree."""<br><br>    n = len(dist)<br>    time_to_reach = sorted(dist[i] / speed[i] for i in range(n))<br>    monsters_eliminated = 0<br>    for time in time_to_reach:<br>        if monsters_eliminated < time:<br>            monsters_eliminated += 1<br>    return monsters_eliminated

### GROUND TRUTH 2, ranked 2, leetcode/leetcode_2603.txt
> from collections import defaultdict<br>    """There exists an undirected and unrooted tree with `n` nodes indexed from `0` to `n - 1`. You are given an integer `n` and a 2D integer array edges of length `n - 1`, where `edges[i] = [ai, bi]` indicates that there is an edge between nodes `ai` and `bi` in the tree. You are also given an array `coins` of size `n` where `coins[i]` can be either `0` or `1`, where `1` indicates the presence of a coin in the vertex `i`.<br><br>Initially, you choose to start at any vertex in the tree. Then, you can perform the following operations any number of times:<br><br>   Collect all the coins that are at a distance of at most `2` from the current vertex, or<br>   Move to any adjacent vertex in the tree.<br><br>Find _the minimum number of edges you need to go through to collect all the coins and go back to the initial vertex_.<br><br>Note that if you pass an edge several times, you need to count it into the answer several times.<br><br>Example 1:<br><br>Input: coins = \[1,0,0,0,0,1\], edges = \[\[0,1\],\[1,2\],\[2,3\],\[3,4\],\[4,5\]\]<br>Output: 2<br>Explanation: Start at vertex 2, collect the coin at vertex 0, move to vertex 3, collect the coin at vertex 5 then move back to vertex 2.<br><br>Example 2:<br><br>Input: coins = \[0,0,0,1,1,0,0,1\], edges = \[\[0,1\],\[0,2\],\[1,3\],\[1,4\],\[2,5\],\[5,6\],\[5,7\]\]<br>Output: 2<br>Explanation: Start at vertex 0, collect the coins at vertices 4 and 3, move to vertex 2,  collect the coin at vertex 7, then move back to vertex 0.<br><br>Constraints:<br><br>   `n == coins.length`<br>   `1 <= n <= 3  104`<br>   `0 <= coins[i] <= 1`<br>   `edges.length == n - 1`<br>   `edges[i].length == 2`<br>   `0 <= ai, bi < n`<br>   `ai != bi`<br>   `edges` represents a valid tree."""<br><br><br>def min_edges_to_collect_coins(coins, edges):<br>    adj = defaultdict(list)<br>    for a, b in edges:<br>        adj[a].append(b)<br>        adj[b].append(a)<br>    return dfs(adj, coins, 0, -1)[1] // 2<br><br>def dfs(adj, coins, node, parent):<br>    sum_coins = coins[node]<br>    distance = 0<br>    for neighbor in adj[node]:<br>        if neighbor != parent:<br>            result = dfs(adj, coins, neighbor, node)<br>            sum_coins += result[0]<br>            distance += 2  result[0] + result[1]<br>    return (sum_coins, distance)
