# Query `3`

## Original Question

*Given an array of integers `heights` representing the histogram's bar height where the width of each bar is `1`, return _the area of the largest rectangle in the histogram_.

Example 1:

Input: heights = \[2,1,5,6,2,3\]
Output: 10
Explanation: The above is a histogram where width of each bar is 1.
The largest rectangle is shown in the red area, which has an area = 10 units.

Example 2:

Input: heights = \[2,4\]
Output: 4

Constraints:

   `1 <= heights.length <= 105`
   `0 <= heights[i] <= 104`*

## gpt4 Reasoning

```markdown
The essential problem is to find the area of the largest rectangle that can be formed within the bounds of a histogram represented by an array of integers, where each integer represents the height of a histogram bar and the width of each bar is 1.

To solve this problem, we need to consider each bar as a potential candidate for either the height of the largest rectangle or part of the base of the largest rectangle. The key is to find for each bar, how far we can extend to the left and to the right without dropping below the height of the current bar, because the height of the largest rectangle that can be formed with the current bar as the lowest bar is limited by the shortest bar in that rectangle.

### Step by Step Approach:

1. **Initialize Variables**: Start by initializing a variable to keep track of the maximum area found so far. This will be updated as we iterate through the bars.

2. **Use a Stack**: A stack can be very useful in this problem to keep track of bars that have not yet found a smaller bar to their right. We push indices onto the stack, not the heights themselves, for easier calculation of widths.

3. **Iterate Through Bars**: For each bar, we do the following:
    - While the stack is not empty and the current bar's height is less than or equal to the height of the bar at the index on the top of the stack, it means we've found a smaller bar for the bars in the stack. For each of these bars, we calculate the area of the largest rectangle that can be formed with that bar as the smallest bar by popping from the stack and calculate the width as the difference between the current index and the index just below the top of the stack after popping (this gives us the 'left boundary'). The height is the height of the popped bar.
    - After processing the bars that are taller than the current bar, push the current index onto the stack.

4. **Clear the Stack**: After iterating through all the bars, there might still be some indices in the stack. These represent bars that didn't find any smaller bar to their right. For each of these, calculate the area assuming the rectangle extends all the way to the end of the histogram.

5. **Calculate Widths Carefully**: When calculating the width of the rectangle, consider the following:
    - If the stack is empty after popping, it means the current bar (the one being calculated for area) extends all the way to the left of the histogram.
    - Otherwise, the width of the rectangle is the difference between the current index (for bars still in the stack after iterating, this is the length of the histogram) and the index on the top of the stack minus one.

### Relevant Information:

- The stack is used to efficiently find the next smaller element to the left and right for each bar, which is crucial in determining the maximum width of the rectangle that can be formed with a given bar as the shortest bar.
- The area of a rectangle is calculated as width * height, where height is the height of the current bar (or the shortest bar in the rectangle), and width is the number of consecutive bars including and adjacent to the current bar that are of equal or greater height.

### Example:

Given `heights = [2,1,5,6,2,3]`, the largest rectangle can be formed by bars with heights `[5,6]` for an area of `5*2=10`. The algorithm effectively identifies the optimal starting and ending indices for the rectangle through the stack-based approach, ensuring efficient computation even for large arrays.

By systematically considering each bar and efficiently finding the bounds within which each bar can extend to form a rectangle, we can identify the area of the largest rectangle in the histogram.
```

### Metrics

```
recip_rank: 0.0000
P_1: 0.0000
P_5: 0.0000
P_10: 0.0000
P_25: 0.0000
P_50: 0.0000
P_100: 0.0000
recall_1: 0.0000
recall_5: 0.0000
recall_10: 0.0000
recall_25: 0.0000
recall_50: 0.0000
recall_100: 0.0000
ndcg_cut_1: 0.0000
ndcg_cut_5: 0.0000
ndcg_cut_10: 0.0000
ndcg_cut_25: 0.0000
ndcg_cut_50: 0.0000
ndcg_cut_100: 0.0000
map_cut_1: 0.0000
map_cut_5: 0.0000
map_cut_10: 0.0000
map_cut_25: 0.0000
map_cut_50: 0.0000
map_cut_100: 0.0000
```

## Retrieval Results

### DOC[1] (IRRELEVANT) leetcode/csn_python_train_144450.txt
> def ner_net(source, destinations, width, height, wrap_around=False, radius=10):<br>    """Produce a shortest path tree for a given net using NER.<br><br>    This is the kernel of the NER algorithm.<br><br>    Parameters<br>    ----------<br>    source : (x, y)<br>        The coordinate of the source vertex.<br>    destinations : iterable([(x, y), ...])<br>        The coordinates of destination vertices.<br>    width : int<br>        Width of the system (nodes)<br>    height : int<br>        Height of the system (nodes)<br>    wrap_around : bool<br>        True if wrap-around links should be used, false if they should be<br>        avoided.<br>    radius : int<br>        Radius of area to search from each node. 20 is arbitrarily selected in<br>        the paper and shown to be acceptable in practice.<br><br>    Returns<br>    -------<br>    (:py:class:`~.rig.place_and_route.routing_tree.RoutingTree`,<br>     {(x,y): :py:class:`~.rig.place_and_route.routing_tree.RoutingTree`, ...})<br>        A RoutingTree is produced rooted at the source and visiting all<br>        destinations but which does not contain any vertices etc. For<br>        convenience, a dictionarry mapping from destination (x, y) coordinates<br>        to the associated RoutingTree is provided to allow the caller to insert<br>        these items.<br>    """<br>    # Map from (x, y) to RoutingTree objects<br>    route = {source: RoutingTree(source)}<br><br>    # Handle each destination, sorted by distance from the source, closest<br>    # first.<br>    for destination in sorted(destinations,<br>                              key=(lambda destination:<br>                                   shortest_mesh_path_length(<br>                                       to_xyz(source), to_xyz(destination))<br>                                   if not wrap_around else<br>                                   shortest_torus_path_length(<br>                                       to_xyz(source), to_xyz(destination),<br>                                       width, height))):<br>        # We shall attempt to find our nearest neighbouring placed node.<br>        neighbour = None<br><br>        # Try to find a nearby (within radius hops) node in the routing tree<br>        # that we can route to (falling back on just routing to the source).<br>        #<br>        # In an implementation according to the algorithm's original<br>        # specification looks for nodes at each point in a growing set of rings<br>        # of concentric hexagons. If it doesn't find any destinations this<br>        # means an awful lot of checks: 1261 for the default radius of 20.<br>        #<br>        # An alternative (but behaviourally identical) implementation scans the<br>        # list of all route nodes created so far and finds the closest node<br>        # which is < radius hops (falling back on the origin if no node is<br>        # closer than radius hops).  This implementation requires one check per<br>        # existing route node. In most routes this is probably a lot less than<br>        # 1261 since most routes will probably have at most a few hundred route<br>        # nodes by the time the last destination is being routed.<br>        #<br>        # Which implementation is best is a difficult question to answer:<br>        #  In principle nets with quite localised connections (e.g.<br>        #   nearest-neighbour or centroids traffic) may route slightly more<br>        #   quickly with the original algorithm since it may very quickly find<br>        #   a neighbour.<br>        #  In nets which connect very spaced-out destinations the second<br>        #   implementation may be quicker since in such a scenario it is<br>        #   unlikely that a neighbour will be found.<br>        #  In extremely high-fan-out nets (e.g. broadcasts), the original<br>        #   method is very likely to perform far better than the alternative<br>        #   method since most iterations will complete immediately while the<br>        #   alternative method must scan all the route vertices.<br>        # As such, it should be clear that neither method alone is 'best' and<br>        # both have degenerate performance in certain completely reasonable<br>        # styles of net. As a result, a simple heuristic is used to decide<br>        # which technique to use.<br>        #<br>        # The following micro-benchmarks are crude estimate of the<br>        # runtime-per-iteration of each approach (at least in the case of a<br>        # torus topology)::<br>        #<br>        #     $ # Original approach<br>        #     $ python -m timeit --setup 'x, y, w, h, r = 1, 2, 5, 10, \<br>        #                                     {x:None for x in range(10)}' \<br>        #                        'x += 1; y += 1; x %= w; y %= h; (x, y) in r'<br>        #     1000000 loops, best of 3: 0.207 usec per loop<br>        #     $ # Alternative approach<br>        #     $ python -m timeit --setup 'from rig.geometry import \<br>        #                                 shortest_torus_path_length' \<br>        #                        'shortest_torus_path_length( \<br>        #                             (0, 1, 2), (3, 2, 1), 10, 10)'<br>        #     1000000 loops, best of 3: 0.666 usec per loop<br>        #<br>        # From this we can approximately suggest that the alternative approach<br>        # is 3x more expensive per iteration. A very crude heuristic is to use<br>        # the original approach when the number of route nodes is more than<br>        # 1/3rd of the number of routes checked by the original method.<br>        concentric_hexagons = memoized_concentric_hexagons(radius)<br>        if len(concentric_hexagons) < len(route) / 3:<br>            # Original approach: Start looking for route nodes in a concentric<br>            # spiral pattern out from the destination node.<br>            for x, y in concentric_hexagons:<br>                x += destination[0]<br>                y += destination[1]<br>                if wrap_around:<br>                    x %= width<br>                    y %= height<br>                if (x, y) in route:<br>                    neighbour = (x, y)<br>                    break<br>        else:<br>            # Alternative approach: Scan over every route node and check to see<br>            # if any are < radius, picking the closest one if so.<br>            neighbour = None<br>            neighbour_distance = None<br>            for candidate_neighbour in route:<br>                if wrap_around:<br>                    distance = shortest_torus_path_length(<br>                        to_xyz(candidate_neighbour), to_xyz(destination),<br>                        width, height)<br>                else:<br>                    distance = shortest_mesh_path_length(<br>                        to_xyz(candidate_neighbour), to_xyz(destination))<br><br>                if distance <= radius and (neighbour is None or<br>                                           distance < neighbour_distance):<br>                    neighbour = candidate_neighbour<br>                    neighbour_distance = distance<br><br>        # Fall back on routing directly to the source if no nodes within radius<br>        # hops of the destination was found.<br>        if neighbour is None:<br>            neighbour = source<br><br>        # Find the shortest vector from the neighbour to this destination<br>        if wrap_around:<br>            vector = shortest_torus_path(to_xyz(neighbour),<br>                                         to_xyz(destination),<br>                                         width, height)<br>        else:<br>            vector = shortest_mesh_path(to_xyz(neighbour), to_xyz(destination))<br><br>        # The longest-dimension-first route may inadvertently pass through an<br>        # already connected node. If the route is allowed to pass through that<br>        # node it would create a cycle in the route which would be VeryBad(TM).<br>        # As a result, we work backward through the route and truncate it at<br>        # the first point where the route intersects with a connected node.<br>        ldf = longest_dimension_first(vector, neighbour, width, height)<br>        i = len(ldf)<br>        for direction, (x, y) in reversed(ldf):<br>            i -= 1<br>            if (x, y) in route:<br>                # We've just bumped into a node which is already part of the<br>                # route, this becomes our new neighbour and we truncate the LDF<br>                # route. (Note ldf list is truncated just after the current<br>                # position since it gives (direction, destination) pairs).<br>                neighbour = (x, y)<br>                ldf = ldf[i + 1:]<br>                break<br><br>        # Take the longest dimension first route.<br>        last_node = route[neighbour]<br>        for direction, (x, y) in ldf:<br>            this_node = RoutingTree((x, y))<br>            route[(x, y)] = this_node<br><br>            last_node.children.append((Routes(direction), this_node))<br>            last_node = this_node<br><br>    return (route[source], route)

### DOC[2] (IRRELEVANT) leetcode/csn_python_train_37296.txt
> def histogram(self,axis=None, kargs):<br>        """<br>        - histogram(axis=None, kargs): It computes and shows the histogram of the image. This is <br>        usefull for choosing a proper scale to the output, or for clipping some values. If <br>        axis is None, it selects the current axis to plot the histogram.<br>        <br>        Keyword arguments:<br>        <br>        bins:<br>        Either an integer number of bins or a sequence giving the<br>        bins.  If bins is an integer, bins + 1 bin edges<br>        will be returned, consistent with :func:`numpy.histogram`<br>        for numpy version = 1.3, and with the new = True argument<br>        in earlier versions.<br>        Unequally spaced bins are supported if bins is a sequence.<br>        <br>        range:<br>        The lower and upper range of the bins. Lower and upper outliers<br>        are ignored. If not provided, range is (x.min(), x.max()).<br>        Range has no effect if bins is a sequence.<br>        <br>        If bins is a sequence or range is specified, autoscaling<br>        is based on the specified bin range instead of the<br>        range of x.<br>        <br>        normed:<br>        If True, the first element of the return tuple will<br>        be the counts normalized to form a probability density, i.e.,<br>        ``n/(len(x)dbin)``.  In a probability density, the integral of<br>        the histogram should be 1; you can verify that with a<br>        trapezoidal integration of the probability density function::<br>        <br>        pdf, bins, patches = ax.hist(...)<br>        print(np.sum(pdf  np.diff(bins)))<br>        <br>        .. note::<br>        <br>        Until numpy release 1.5, the underlying numpy<br>        histogram function was incorrect with normed=True<br>        if bin sizes were unequal.  MPL inherited that<br>        error.  It is now corrected within MPL when using<br>        earlier numpy versions<br>        <br>        weights:<br>        An array of weights, of the same shape as x.  Each value in<br>        x only contributes its associated weight towards the bin<br>        count (instead of 1).  If normed is True, the weights are<br>        normalized, so that the integral of the density over the range<br>        remains 1.<br>        <br>        cumulative:<br>        If True, then a histogram is computed where each bin<br>        gives the counts in that bin plus all bins for smaller values.<br>        The last bin gives the total number of datapoints.  If normed<br>        is also True then the histogram is normalized such that the<br>        last bin equals 1. If cumulative evaluates to less than 0<br>        (e.g. -1), the direction of accumulation is reversed.  In this<br>        case, if normed is also True, then the histogram is normalized<br>        such that the first bin equals 1.<br>        <br>        histtype: [ 'bar' | 'barstacked' | 'step' | 'stepfilled' ]<br>        The type of histogram to draw.<br>        <br>        - 'bar' is a traditional bar-type histogram.  If multiple data<br>        are given the bars are aranged side by side.<br>        <br>        - 'barstacked' is a bar-type histogram where multiple<br>        data are stacked on top of each other.<br>        <br>        - 'step' generates a lineplot that is by default<br>        unfilled.<br>        <br>        - 'stepfilled' generates a lineplot that is by default<br>        filled.<br>        <br>        align: ['left' | 'mid' | 'right' ]<br>        Controls how the histogram is plotted.<br>        <br>        - 'left': bars are centered on the left bin edges.<br>        <br>        - 'mid': bars are centered between the bin edges.<br>        <br>        - 'right': bars are centered on the right bin edges.<br>        <br>        orientation: [ 'horizontal' | 'vertical' ]<br>        If 'horizontal', :func:`~matplotlib.pyplot.barh` will be<br>        used for bar-type histograms and the bottom kwarg will be<br>        the left edges.<br>        <br>        rwidth:<br>        The relative width of the bars as a fraction of the bin<br>        width.  If None, automatically compute the width. Ignored<br>        if histtype = 'step' or 'stepfilled'.<br>        <br>        log:<br>        If True, the histogram axis will be set to a log scale.<br>        If log is True and x is a 1D array, empty bins will<br>        be filtered out and only the non-empty (n, bins,<br>        patches) will be returned.<br>        <br>        color:<br>        Color spec or sequence of color specs, one per<br>        dataset.  Default (None) uses the standard line<br>        color sequence.<br>        <br>        label:<br>        String, or sequence of strings to match multiple<br>        datasets.  Bar charts yield multiple patches per<br>        dataset, but only the first gets the label, so<br>        that the legend command will work as expected::<br>        <br>        ax.hist(10+2np.random.randn(1000), label='men')<br>        ax.hist(12+3np.random.randn(1000), label='women', alpha=0.5)<br>        ax.legend()<br>        <br>        <br>        kwargs are used to update the properties of the<br>        :class:`~matplotlib.patches.Patch` instances returned by hist:<br>        <br>        agg_filter: unknown<br>        alpha: float or None         <br>        animated: [True | False]         <br>        antialiased or aa: [True | False]  or None for default         <br>        axes: an :class:`~matplotlib.axes.Axes` instance         <br>        clip_box: a :class:`matplotlib.transforms.Bbox` instance         <br>        clip_on: [True | False]         <br>        clip_path: [ (:class:`~matplotlib.path.Path`,         :class:`~matplotlib.transforms.Transform`) |         :class:`~matplotlib.patches.Patch` | None ]         <br>        color: matplotlib color spec<br>        contains: a callable function         <br>        edgecolor or ec: mpl color spec, or None for default, or 'none' for no color         <br>        facecolor or fc: mpl color spec, or None for default, or 'none' for no color         <br>        figure: a :class:`matplotlib.figure.Figure` instance         <br>        fill: [True | False]         <br>        gid: an id string         <br>        hatch: [ '/' | '\\' | '|' | '-' | '+' | 'x' | 'o' | 'O' | '.' | '' ]         <br>        label: any string         <br>        linestyle or ls: ['solid' | 'dashed' | 'dashdot' | 'dotted']         <br>        linewidth or lw: float or None for default         <br>        lod: [True | False]         <br>        path_effects: unknown<br>        picker: [None|float|boolean|callable]         <br>        rasterized: [True | False | None]         <br>        snap: unknown<br>        transform: :class:`~matplotlib.transforms.Transform` instance         <br>        url: a url string         <br>        visible: [True | False]         <br>        zorder: any number <br>        """<br>        if(axis == None):<br>            axis = plt.gca()<br>        axis.hist(self.__image.ravel(), kargs)

### DOC[3] (IRRELEVANT) leetcode/csn_python_train_173803.txt
> def processFrame(frame):<br>    """Simulate a left and right sensor output (from 0 to 1) given the input image."""<br>    # The pixels are grey-scale values from 0-255 - white = 255, black = 0<br>    # We want to turn the image into two values, one for the left "sensor" and one for the right.<br>    # There are many possible ways to do this. The very simplest way would be<br>    # to examine the values of two pixels - one in the centre of the left half of the image,<br>    # and one in the centre of the right half. What are the obvious problems with this?<br><br>    # NB: The pixels are stored in a flat (1 dimensional) array, so to calculate the index of the pixels<br>    # at (x,y), we do:<br>    # index = x + (y  width)<br><br>    width = frame.width<br>    height = frame.height<br>    pixels = frame.pixels<br><br>    USE_SIMPLE_APPROACH = False  # Change this to False to use more sophisticated approach.<br><br>    if USE_SIMPLE_APPROACH:<br>        # Simplest approach.<br>        left_centre_x = int(width / 4)      # Centre of left half<br>        right_centre_x = int(3  width / 4) # Centre of right half<br>        centre_y = int(height / 2)          # Middle row<br>        left_pixel_index = left_centre_x + (centre_y  width)<br>        right_pixel_index = right_centre_x + (centre_y  width)<br>        left_sensor = float(pixels[left_pixel_index]) / 255.0<br>        right_sensor = float(pixels[right_pixel_index]) / 255.0<br>    else:<br>        # Obviously, the simple approach misses a lot of data, and is very susceptible to noise.<br>        # A better approach would be to consider more pixels.<br>        # You could take the average of all the pixels - it's slower but better.<br>        # Or you could use the median value, which is less noisy than the mean.<br>        # Here we calculate both, and estimate the median using histograms:<br>        left_total = 0<br>        right_total = 0<br>        left_hist = [0 for i in range(256)]<br>        right_hist = [0 for i in range(256)]<br>        # Create a histogram for each half of the image:<br>        for y in range(height):<br>            for x in range(int(width/2)):<br>                i = pixels[x + ywidth]<br>                left_hist[i] += 1<br>                left_total += float(i)/255.0<br>            for x in range(int(width/2), width):<br>                i = pixels[x + ywidth]<br>                right_hist[i] += 1<br>                right_total += float(i)/255.0<br>        # Calculate the mean values:<br>        left_mean, right_mean = left_total / (widthheight/2), right_total / (widthheight/2)<br>        # Now use the histogram to estimate the median value<br>        left_total, right_total = 0, 0<br>        pixels_per_half = width  height / 2<br>        cut_off_value = pixels_per_half / 2<br>        left_cut_off_point, right_cut_off_point = 0, 0<br>        while (left_total < cut_off_value):<br>            left_total += left_hist[left_cut_off_point]<br>            left_cut_off_point += 1<br>        while(right_total < cut_off_value):<br>            right_total += right_hist[right_cut_off_point]<br>            right_cut_off_point += 1<br>        left_median, right_median = left_cut_off_point / 255.0, right_cut_off_point / 255.0<br>        <br>        # Use the median values:<br>        left_sensor, right_sensor = left_median, right_median<br>        # Or uncomment this line to use the mean values:<br>        # left_sensor, right_sensor = left_mean, right_mean<br>    <br>    # In our gloomy arena, we never get particularly bright, so the sensor values tend to be low.<br>    # To get more action from our vehicle, we can scale up (keeping 1.0 as the max).<br>    # What values work well for GAIN? What happens if it's too high or too low?<br>    GAIN = 1.8<br>    left_sensor = min(1, left_sensor  GAIN)<br>    right_sensor = min(1, right_sensor  GAIN)<br>    # Done - return the values:<br>    return left_sensor, right_sensor

### DOC[4] (IRRELEVANT) leetcode/csn_python_train_324710.txt
> def bar(args, kwargs):<br>    """<br>    Creates a bar plot, with white outlines and a fill color that defaults to<br>     the first teal-ish green in ColorBrewer's Set2. Optionally accepts<br>     grid='y' or grid='x' to draw a white grid over the bars,<br>     to show the scale. Almost like "erasing" some of the plot,<br>     but it adds more information!<br><br>    Can also add an annotation of the height of the barplots directly onto<br>    the bars with the `annotate` parameter, which can either be True,<br>    which will annotate the values, or a list of strings, which will annotate<br>    with the supplied strings.<br><br>    Can support stacked bars with the value of each stack shown on the stack<br>    (Added by Salil Banerjee)<br><br>    @param ax: matplotlib.axes instance<br>    @param left: Vector of values of where to put the left side of the bar<br>    @param height: Vector of values of the bar heights<br>    @param kwargs: Besides xticklabels, which is a prettyplotlib-specific<br>    argument, any additional arguments to matplotlib.bar(): http://matplotlib<br>    .org/api/axes_api.html#matplotlib.axes.Axes.bar is accepted.<br>    """<br>    ax, args, kwargs = maybe_get_ax(args, kwargs)<br>    kwargs.setdefault('color', set2[0])<br>    kwargs.setdefault('edgecolor', 'white')<br>    middle = 0.4 if 'width' not in kwargs else kwargs['width']/2.0<br><br>    # Check if data contains stacks<br>    stacked = kwargs.pop('stacked',False)<br>    # Check if stack text should be included<br>    stack_text = kwargs.pop('stack_text',False)<br>    # Get legend if available<br>    legend = kwargs.pop('legend',False)<br><br>    left = args[0]<br>    height = np.array(args[1])<br><br>    # Label each individual bar, if xticklabels is provided<br>    xtickabels = kwargs.pop('xticklabels', None)<br>    # left+0.4 is the center of the bar<br>    xticks = np.array(left) + middle<br><br>    # Whether or not to annotate each bar with the height value<br>    annotate = kwargs.pop('annotate', False)<br><br>    show_ticks = kwargs.pop('show_ticks', False)<br><br>    # If no grid specified, don't draw one.<br>    grid = kwargs.pop('grid', None)<br><br>    cmap = kwargs.pop('cmap', False)<br>    if cmap:<br>        kwargs['edgecolor'] = almost_black<br>        if not stacked:<br>            kwargs['color'] = getcolors(cmap, height, 0)<br><br>    # Check if stacked and plot data accordingly<br>    color = kwargs.get('color', None)<br>    if stacked:<br>        num_stacks, num_data = height.shape<br>        bottom = np.zeros(num_data)<br>        for i in np.arange(num_stacks):<br>            lst = list(args)<br>            lst[1] = height[i]<br>            args = tuple(lst)<br>            # make sure number of user specified colors equals to the stacks <br>            if not color or len(color) != num_stacks:<br>                if cmap:<br>                    kwargs['color'] = getcolors(cmap, height[i], i)<br>                else:<br>                    kwargs['color'] = set2[i]<br>            else:<br>                kwargs['color'] = color[i]<br>            kwargs['bottom'] = bottom<br>            rectangles = ax.bar(args, kwargs)<br>            bottom += height[i]<br>    else:<br>        rectangles = ax.bar(args, kwargs)<br>   <br>    # add legend<br>    if isinstance(legend, collections.Iterable):<br>        ax.legend(legend,loc='upper center',bbox_to_anchor=(0.5,1.11), ncol=5)<br><br>    # add whitespace padding on left<br>    xmin, xmax = ax.get_xlim()<br>    xmin -= 0.2<br>    if stacked:<br>        xmax = num_data<br>    ax.set_xlim(xmin, xmax)<br><br>    # If the user is only plotting one bar, make it an iterable<br>    if not isinstance(height, collections.Iterable):<br>        height = [height]<br><br><br>    # If there are negative counts, remove the bottom axes<br>    # and add a line at y=0<br>    if any(h < 0 for h in height.tolist()):<br>        axes_to_remove = ['top', 'right', 'bottom']<br>        ax.hlines(y=0, xmin=xmin, xmax=xmax,<br>                      linewidths=0.75)<br>    else:<br>        axes_to_remove = ['top', 'right']<br><br>    # Remove excess axes<br>    remove_chartjunk(ax, axes_to_remove, grid=grid, show_ticks=show_ticks)<br><br>    if stacked:<br>        data = height<br>        height = height.sum(axis=0)<br><br>    # Add the xticklabels if they are there<br>    if xtickabels is not None:<br>        ax.set_xticks(xticks)<br>        ax.set_xticklabels(xtickabels)<br><br>    if annotate or isinstance(annotate, collections.Iterable):<br>        annotate_yrange_factor = 0.025<br>        ymin, ymax = ax.get_ylim()<br>        yrange = ymax - ymin<br><br>        # Reset ymax and ymin so there's enough room to see the annotation of<br>        # the top-most<br>        if ymax  0:<br>            ymax += yrange  0.1<br>        if ymin < 0:<br>            ymin -= yrange  0.1<br>        ax.set_ylim(ymin, ymax)<br>        yrange = ymax - ymin<br><br>        if kwargs.get('log') == True:<br>            offset_ = np.log(yrange)  annotate_yrange_factor<br>        else:<br>            offset_ = yrange  annotate_yrange_factor<br><br>        if isinstance(annotate, collections.Iterable):<br>            annotations = map(str, annotate)<br>        else:<br>            annotations = ['%.3f' % h if type(h) is np.float_ else str(h)<br>                               for h in height]<br><br>        for x, h, annotation in zip(xticks, height, annotations):<br>            # Adjust the offset to account for negative bars<br>            offset = offset_ if h = 0 else -1  offset_<br>            verticalalignment = 'bottom' if h = 0 else 'top'<br><br>            # Finally, add the text to the axes<br>            ax.annotate(annotation, (x, h + offset),<br>                        verticalalignment=verticalalignment,<br>                        horizontalalignment='center',<br>                        color=almost_black)<br><br>    # Text for each block of stack<br>    # This was partially inspired by the following article by Tableau software<br>    # http://www.tableausoftware.com/about/blog/2014/1/new-whitepaper-survey-data-less-ugly-more-understandable-27812<br>    if stack_text:<br>        bottom = np.zeros(num_data)<br>        max_h = max(height)<br>        for i in np.arange(num_stacks):<br>            for x, d, b in zip(xticks, data[i], bottom):<br>                if (d100.0/max_h)  4.0:<br>                    ax.text(x,b+d/2.0,d, ha='center', va='center', color=almost_black)<br>            bottom += data[i]<br>    return rectangles

### DOC[5] (IRRELEVANT) leetcode/csn_python_train_254560.txt
> def blit(self, source, x=0, y=0, width=None, height=None, srcX=0, srcY=0,<br>             fg_alpha=1.0, bg_alpha=1.0):<br>        """Blit another console or Window onto the current console.<br><br>        By default it blits the entire source to the topleft corner.<br><br>        Args:<br>            source (Union[tdl.Console, tdl.Window]): The blitting source.<br>                A console can blit to itself without any problems.<br>            x (int): x-coordinate of this console to blit on.<br>            y (int): y-coordinate of this console to blit on.<br>            width (Optional[int]): Width of the rectangle.<br><br>                Can be None to extend as far as possible to the<br>                bottom right corner of the blit area or can be a negative<br>                number to be sized reltive to the total size of the<br>                B{destination} console.<br>            height (Optional[int]): Height of the rectangle.<br>            srcX (int):  x-coordinate of the source region to blit.<br>            srcY (int):  y-coordinate of the source region to blit.<br>            fg_alpha (float): The foreground alpha.<br>        """<br>        assert isinstance(source, (Console, Window)), "source muse be a Window or Console instance"<br><br>        # handle negative indexes and rects<br>        # negative width and height will be set realtive to the destination<br>        # and will also be clamped to the smallest Console<br>        x, y, width, height = self._normalizeRect(x, y, width, height)<br>        srcX, srcY, width, height = source._normalizeRect(srcX, srcY, width, height)<br><br>        # translate source and self if any of them are Window instances<br>        srcX, srcY = source._translate(srcX, srcY)<br>        source = source.console<br>        x, y = self._translate(x, y)<br>        self = self.console<br><br>        if self == source:<br>            # if we are the same console then we need a third console to hold<br>            # onto the data, otherwise it tries to copy into itself and<br>            # starts destroying everything<br>            tmp = Console(width, height)<br>            _lib.TCOD_console_blit(source.console_c,<br>                                   srcX, srcY, width, height,<br>                                   tmp.console_c, 0, 0, fg_alpha, bg_alpha)<br>            _lib.TCOD_console_blit(tmp.console_c, 0, 0, width, height,<br>                                   self.console_c, x, y, fg_alpha, bg_alpha)<br>        else:<br>            _lib.TCOD_console_blit(source.console_c,<br>                                   srcX, srcY, width, height,<br>                                   self.console_c, x, y, fg_alpha, bg_alpha)


## Ground Truth

### GROUND TRUTH 0, ranked not in top 100, leetcode/leetcode_85.txt
> def maximalRectangle(matrix):<br>    """Given a `rows x cols` binary `matrix` filled with `0`'s and `1`'s, find the largest rectangle containing only `1`'s and return _its area_.<br><br>Example 1:<br><br>Input: matrix = \[\[ "1 ", "0 ", "1 ", "0 ", "0 "\],\[ "1 ", "0 ", "1 ", "1 ", "1 "\],\[ "1 ", "1 ", "1 ", "1 ", "1 "\],\[ "1 ", "0 ", "0 ", "1 ", "0 "\]\]<br>Output: 6<br>Explanation: The maximal rectangle is shown in the above picture.<br><br>Example 2:<br><br>Input: matrix = \[\[ "0 "\]\]<br>Output: 0<br><br>Example 3:<br><br>Input: matrix = \[\[ "1 "\]\]<br>Output: 1<br><br>Constraints:<br><br>   `rows == matrix.length`<br>   `cols == matrix[i].length`<br>   `1 <= row, cols <= 200`<br>   `matrix[i][j]` is `'0'` or `'1'`."""<br><br>    if not matrix:<br>        return 0<br><br>    m = len(matrix)<br>    n = len(matrix[0])<br>    height = [0]  (n + 1)<br>    max_area = 0<br><br>    for i in range(m):<br>        s = []<br>        for j in range(n + 1):<br>            if j < n:<br>                height[j] = height[j] + 1 if matrix[i][j] == '1' else 0<br>            while s and height[j] < height[s[-1]]:<br>                h = height[s.pop()]<br>                w = j if not s else j - s[-1] - 1<br>                max_area = max(max_area, h  w)<br>            s.append(j)<br><br>    return max_area

### GROUND TRUTH 1, ranked not in top 100, leetcode/leetcode_1793.txt
> def min_moves(nums, limit):<br>    """You are given an array of integers `nums` (0-indexed) and an integer `k`.<br><br>The score of a subarray `(i, j)` is defined as `min(nums[i], nums[i+1], ..., nums[j])  (j - i + 1)`. A good subarray is a subarray where `i <= k <= j`.<br><br>Return _the maximum possible score of a good subarray._<br><br>Example 1:<br><br>Input: nums = \[1,4,3,7,4,5\], k = 3<br>Output: 15<br>Explanation: The optimal subarray is (1, 5) with a score of min(4,3,7,4,5) \ (5-1+1) = 3 \ 5 = 15. <br><br>Example 2:<br><br>Input: nums = \[5,5,4,5,4,1,1,1\], k = 0<br>Output: 20<br>Explanation: The optimal subarray is (0, 4) with a score of min(5,5,4,5,4) \ (4-0+1) = 4 \ 5 = 20.<br><br>Constraints:<br><br>   `1 <= nums.length <= 105`<br>   `1 <= nums[i] <= 2  104`<br>   `0 <= k < nums.length`"""<br><br>    n = len(nums)<br>    delta = [0]  (2  limit + 2)<br><br>    for i in range(n // 2):<br>        lo = min(nums[i], nums[n - 1 - i]) + 1<br>        hi = max(nums[i], nums[n - 1 - i]) + limit<br>        delta[lo] -= 1<br>        delta[nums[i] + nums[n - 1 - i]] -= 1<br>        delta[hi + 1] += 1<br><br>    moves, current = n, n<br>    for i in range(2, 2  limit + 1):<br>        current += delta[i]<br>        moves = min(moves, current)<br><br>    return moves
