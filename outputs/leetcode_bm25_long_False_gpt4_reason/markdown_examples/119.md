# Query `119`

## Original Question

*You are given two integers `m` and `n` representing a 0-indexed `m x n` grid. You are also given two 2D integer arrays `guards` and `walls` where `guards[i] = [rowi, coli]` and `walls[j] = [rowj, colj]` represent the positions of the `ith` guard and `jth` wall respectively.

A guard can see every cell in the four cardinal directions (north, east, south, or west) starting from their position unless obstructed by a wall or another guard. A cell is guarded if there is at least one guard that can see it.

Return _the number of unoccupied cells that are not guarded._

Example 1:

Input: m = 4, n = 6, guards = \[\[0,0\],\[1,1\],\[2,3\]\], walls = \[\[0,1\],\[2,2\],\[1,4\]\]
Output: 7
Explanation: The guarded and unguarded cells are shown in red and green respectively in the above diagram.
There are a total of 7 unguarded cells, so we return 7.

Example 2:

Input: m = 3, n = 3, guards = \[\[1,1\]\], walls = \[\[0,1\],\[1,0\],\[2,1\],\[1,2\]\]
Output: 4
Explanation: The unguarded cells are shown in green in the above diagram.
There are a total of 4 unguarded cells, so we return 4.

Constraints:

   `1 <= m, n <= 105`
   `2 <= m  n <= 105`
   `1 <= guards.length, walls.length <= 5  104`
   `2 <= guards.length + walls.length <= m  n`
   `guards[i].length == walls[j].length == 2`
   `0 <= rowi, rowj < m`
   `0 <= coli, colj < n`
   All the positions in `guards` and `walls` are unique.*

## gpt4 Reasoning

```markdown
The essential problem here is to determine how many cells in a given grid are not guarded by guards, given the positions of guards, walls, and the grid's dimensions. The presence of walls and guards affects the visibility of guards to other cells, making this a problem of calculating visibility and obstructions within a grid.

To address this problem, we can follow these steps:

1. **Initialize the Grid:** First, we create a representation of the grid using a 2D array or a similar data structure, marking empty cells, guard positions, and wall positions. This step is crucial for visualizing the problem and implementing the solution.

2. **Marking Guarded Areas:**
   - For each guard, we need to explore in the four cardinal directions (north, east, south, west) and mark all cells that the guard can see as guarded. This exploration stops when we hit a wall or the grid's edge.
   - It's essential to account for the fact that another guard also acts as an obstruction, similar to a wall. Thus, the exploration in a direction should stop upon encountering either a wall or another guard.

3. **Handling Obstructions:** While marking guarded areas, if a cell that is being checked for visibility contains a wall or another guard, the current direction's exploration stops. This is because walls and guards obstruct the line of sight.

4. **Counting Unguarded Cells:** After marking all possible guarded cells, we iterate through the grid to count cells that are neither guarded, walls, nor occupied by guards. These are the unguarded cells.

5. **Return the Count:** The final step is to return the count of unguarded cells.

**Relevant Information:**
- The size of the grid (`m x n`) gives us the bounds for our exploration.
- The positions of guards and walls are critical since they directly influence which cells are guarded.
- Since the guards and walls are uniquely positioned, we don't need to worry about overlapping positions in our initial setup.
- The constraint that the total number of guards and walls is less than the number of cells ensures there's always space to have unguarded cells.

**Challenges and Considerations:**
- Efficiently marking the guarded areas is crucial. One way to do this is by iterating from each guard's position until hitting a wall, another guard, or the grid's boundary. This could potentially be optimized further with more advanced data structures or algorithms.
- Handling the grid's boundaries requires careful checks to avoid indexing errors.
- Since the grid could be large (`1 <= m, n <= 10^5`), the solution needs to be optimized for performance to handle the worst-case scenario efficiently.

By following these steps and considerations, we can develop a solution to identify and count the unguarded cells in the grid, ensuring we account for all constraints and requirements of the problem.
```

### Metrics

```
recip_rank: 0.0435
P_1: 0.0000
P_5: 0.0000
P_10: 0.0000
P_25: 0.0400
P_50: 0.0200
P_100: 0.0100
recall_1: 0.0000
recall_5: 0.0000
recall_10: 0.0000
recall_25: 1.0000
recall_50: 1.0000
recall_100: 1.0000
ndcg_cut_1: 0.0000
ndcg_cut_5: 0.0000
ndcg_cut_10: 0.0000
ndcg_cut_25: 0.2181
ndcg_cut_50: 0.2181
ndcg_cut_100: 0.2181
map_cut_1: 0.0000
map_cut_5: 0.0000
map_cut_10: 0.0000
map_cut_25: 0.0435
map_cut_50: 0.0435
map_cut_100: 0.0435
```

## Retrieval Results

### DOC[1] (IRRELEVANT) leetcode/csn_python_train_154085.txt
> def _conc_alloc_size(self, sim_size):<br>        """<br>        Concretizes a size argument, if necessary, to something that makes sense when allocating space. Here we just<br>        maximize its potential size up to the maximum variable size specified in the libc plugin.<br><br>        TODO:<br>        Further consideration of the tradeoffs of this approach is probably warranted. SimHeapPTMalloc especially makes<br>        a lot of different concretization strategy assumptions, but this function handles one of the more important<br>        problems that any heap implementation will face: how to decide the amount of space to allocate upon request for<br>        a symbolic size. Either we do as we do here and silently constrain the amount returned to a default max value,<br>        or we could add a path constraint to the state to prevent exploration of any paths that would have legitimately<br>        occurred given a larger allocation size.<br><br>        The first approach (the silent maximum) has its benefit in that the explored state space will not be<br>        constrained. Sometimes this could work out, as when an allocation is returned that is smaller than requested but<br>        which the program doesn't end up making full use of anyways. Alternatively, this lack of fidelity could cause<br>        the program to overwrite other allocations made, since it should be able to assume the allocation is as large as<br>        it requested it be.<br><br>        The second approach (the path constraint) has its benefit in that no paths will be explored that could fail<br>        when an allocation is made too small. On the other hand, as stated above, some of these paths might not have<br>        failed anyways, and doing this causes us to lose the opportunity to explore those paths.<br><br>        Perhaps these behaviors could be parameterized in the future?<br>        """<br>        if self.state.solver.symbolic(sim_size):<br>            size = self.state.solver.max_int(sim_size)<br>            if size  self.state.libc.max_variable_size:<br>                l.warning("Allocation request of %d bytes exceeded maximum of %d bytes; allocating %d bytes",<br>                          size, self.state.libc.max_variable_size, size)<br>                size = self.state.libc.max_variable_size<br>        else:<br>            size = self.state.solver.eval(sim_size)<br>        return size

### DOC[2] (IRRELEVANT) leetcode/csn_python_train_144360.txt
> def place(vertices_resources, nets, machine, constraints,<br>          effort=1.0, random=default_random, on_temperature_change=None,<br>          kernel=default_kernel, kernel_kwargs={}):<br>    """A flat Simulated Annealing based placement algorithm.<br><br>    This placement algorithm uses simulated annealing directly on the supplied<br>    problem graph with the objective of reducing wire lengths (and thus,<br>    indirectly, the potential for congestion). Though computationally<br>    expensive, this placer produces relatively good placement solutions.<br><br>    The annealing temperature schedule used by this algorithm is taken from<br>    "VPR: A New Packing, Placement and Routing Tool for FPGA Research" by<br>    Vaughn Betz and Jonathan Rose from the "1997 International Workshop on<br>    Field Programmable Logic and Applications".<br><br>    Two implementations of the algorithm's kernel are available:<br><br>     :py:class:`~rig.place_and_route.place.sa.python_kernel.PythonKernel` A<br>      pure Python implementation which is available on all platforms supported<br>      by Rig.<br>     :py:class:`~rig.place_and_route.place.sa.c_kernel.CKernel` A C<br>      implementation which is typically 50-150x faster than the basic Python<br>      kernel. Since this implementation requires a C compiler during<br>      installation, it is an optional feature of Rig. See the<br>      :py:class:`CKernel's documentation<br>      <rig.place_and_route.place.sa.c_kernel.CKernel` for details.<br><br>    The fastest kernel installed is used by default and can be manually chosen<br>    using the ``kernel`` argument.<br><br>    This algorithm produces INFO level logging information describing the<br>    progress made by the algorithm.<br><br>    .. warning:<br>        This algorithm does not attempt to produce good solutions to the<br>        bin-packing problem of optimally fitting vertices into chips and it may<br>        fail if a good placement requires good bin packing.<br><br>    Parameters<br>    ----------<br>    effort : float<br>        A scaling factor for the number of iterations the algorithm should run<br>        for. 1.0 is probably about as low as you'll want to go in practice and<br>        runtime increases linearly as you increase this parameter.<br>    random : :py:class:`random.Random`<br>        A Python random number generator. Defaults to ``import random`` but can<br>        be set to your own instance of :py:class:`random.Random` to allow you<br>        to control the seed and produce deterministic results. For results to<br>        be deterministic, vertices_resources must be supplied as an<br>        :py:class:`collections.OrderedDict`.<br>    on_temperature_change : callback_function or None<br>        An (optional) callback function which is called every time the<br>        temperature is changed. This callback can be used to provide status<br>        updates<br><br>        The callback function is passed the following arguments:<br><br>         ``iteration_count``: the number of iterations the placer has<br>          attempted (integer)<br>         ``placements``: The current placement solution.<br>         ``cost``: the weighted sum over all nets of bounding-box size.<br>          (float)<br>         ``acceptance_rate``: the proportion of iterations which have resulted<br>          in an accepted change since the last callback call. (float between<br>          0.0 and 1.0)<br>         ``temperature``: The current annealing temperature. (float)<br>         ``distance_limit``: The maximum distance any swap may be made over.<br>          (integer)<br><br>        If the callback returns False, the anneal is terminated immediately and<br>        the current solution is returned.<br>    kernel : :py:class:`~rig.place_and_route.place.sa.kernel.Kernel`<br>        A simulated annealing placement kernel. A sensible default will be<br>        chosen based on the available kernels on this machine. The kernel may<br>        not be used if the placement problem has a trivial solution.<br>    kernel_kwargs : dict<br>        Optional kernel-specific keyword arguments to pass to the kernel<br>        constructor.<br>    """<br>    # Special case: just return immediately when there's nothing to place<br>    if len(vertices_resources) == 0:<br>        return {}<br><br>    # Within the algorithm we modify the resource availability values in the<br>    # machine to account for the effects of the current placement. As a result,<br>    # an internal copy of the structure must be made.<br>    machine = machine.copy()<br><br>    # {vertex: (x, y), ...} gives the location of all vertices whose position<br>    # is fixed by a LocationConstraint.<br>    fixed_vertices = {}<br><br>    # Handle constraints<br>    vertices_resources, nets, constraints, substitutions = \<br>        apply_same_chip_constraints(vertices_resources, nets, constraints)<br>    for constraint in constraints:<br>        if isinstance(constraint, LocationConstraint):<br>            # Location constraints are handled by recording the set of fixed<br>            # vertex locations and subtracting their resources from the chips<br>            # they're allocated to. These vertices will then not be added to<br>            # the internal placement data structure to prevent annealing from<br>            # moving them. They will be re-introduced at the last possible<br>            # moment.<br>            location = constraint.location<br>            if location not in machine:<br>                raise InvalidConstraintError(<br>                    "Chip requested by {} unavailable".format(machine))<br>            vertex = constraint.vertex<br><br>            # Record the constrained vertex's location<br>            fixed_vertices[vertex] = location<br><br>            # Make sure the vertex fits at the requested location (updating the<br>            # resource availability after placement)<br>            resources = vertices_resources[vertex]<br>            machine[location] = subtract_resources(machine[location],<br>                                                   resources)<br>            if overallocated(machine[location]):<br>                raise InsufficientResourceError(<br>                    "Cannot meet {}".format(constraint))<br>        elif isinstance(constraint,  # pragma: no branch<br>                        ReserveResourceConstraint):<br>            apply_reserve_resource_constraint(machine, constraint)<br><br>    # Initially randomly place the movable vertices<br>    movable_vertices = {v for v in vertices_resources<br>                        if v not in fixed_vertices}<br>    initial_placements = _initial_placement(movable_vertices,<br>                                            vertices_resources,<br>                                            machine, random)<br><br>    # Include the fixed vertices in initial placement<br>    initial_placements.update(fixed_vertices)<br><br>    # Filter out empty or singleton nets and those weighted as zero since they<br>    # cannot influence placement.<br>    nets = [n for n in nets if len(set(n))  1 and n.weight  0.0]<br><br>    # Special cases where no placement effort is required:<br>    #  There is only one chip<br>    #  There are no resource types to be consumed<br>    #  No effort is to be made<br>    #  No movable vertices<br>    #  There are no nets (and moving things has no effect)<br>    trivial = ((machine.width, machine.height) == (1, 1) or<br>               len(machine.chip_resources) == 0 or<br>               effort == 0.0 or<br>               len(movable_vertices) == 0 or<br>               len(nets) == 0)<br>    if trivial:<br>        logger.info("Placement has trivial solution. SA not used.")<br>        finalise_same_chip_constraints(substitutions, initial_placements)<br>        return initial_placements<br><br>    # Intialise the algorithm kernel<br>    k = kernel(vertices_resources, movable_vertices, set(fixed_vertices),<br>               initial_placements, nets, machine, random, kernel_kwargs)<br><br>    logger.info("SA placement kernel: %s", kernel.__name__)<br><br>    # Specifies the maximum distance any swap can span. Initially consider<br>    # swaps that span the entire machine.<br>    distance_limit = max(machine.width, machine.height)<br><br>    # Determine initial temperature according to the heuristic used by VPR: 20<br>    # times the standard deviation of len(movable_vertices) random swap costs.<br>    # The arbitrary very-high temperature is used to cause "all" swaps to be<br>    # accepted.<br>    _0, _1, cost_delta_sd = k.run_steps(len(movable_vertices),<br>                                        distance_limit,<br>                                        1e100)<br>    temperature = 20.0  cost_delta_sd<br><br>    # The number of swap-attempts between temperature changes is selected by<br>    # the heuristic used by VPR. This value is scaled linearly by the effort<br>    # parameter.<br>    num_steps = max(1, int(effort  len(vertices_resources)1.33))<br><br>    logger.info("Initial placement temperature: %0.1f", temperature)<br><br>    # Counter for the number of swap attempts made (used for diagnostic<br>    # purposes)<br>    iteration_count = 0<br><br>    # Holds the total cost of the current placement. This default value chosen<br>    # to ensure the loop below iterates at least once.<br>    current_cost = 0.0<br><br>    # The annealing algorithm runs until a heuristic termination condition<br>    # (taken from VPR) is hit. The heuristic waits until the temperature falls<br>    # below a small fraction of the average net cost.<br>    while temperature  (0.005  current_cost) / len(nets):<br>        # Run an iteration at the current temperature<br>        num_accepted, current_cost, _ = k.run_steps(<br>            num_steps, int(math.ceil(distance_limit)), temperature)<br><br>        # The ratio of accepted-to-not-accepted changes<br>        r_accept = num_accepted / float(num_steps)<br><br>        # Special case: Can't do better than 0 cost! This is a special case<br>        # since the normal termination condition will not terminate if the cost<br>        # doesn't drop below 0.<br>        if current_cost == 0:<br>            break<br><br>        # The temperature is reduced by a factor heuristically based on the<br>        # acceptance rate. The schedule below attempts to maximise the time<br>        # spent at temperatures where a large portion (but not all) of changes<br>        # are being accepted. If lots of changes are being accepted (e.g.<br>        # during high-temperature periods) then most of them are likely not to<br>        # be beneficial. If few changes are being accepted, we're probably<br>        # pretty close to the optimal placement.<br>        if r_accept  0.96:<br>            alpha = 0.5<br>        elif r_accept  0.8:<br>            alpha = 0.9<br>        elif r_accept  0.15:<br>            alpha = 0.95<br>        else:<br>            alpha = 0.8<br>        temperature = alpha  temperature<br><br>        # According to:<br>        #  M. Huang, F. Romeo, and A. Sangiovanni-Vincentelli, "An Efficient<br>        #   General Cooling Schedule for Simulated Annealing" ICCAD, 1986, pp.<br>        #   381 - 384 and J. Lam<br>        #  J. Delosme, "Performance of a New Annealing Schedule" DAC, 1988,<br>        #   pp. 306 - 311.<br>        # It is desirable to keep the acceptance ratio as close to 0.44 for as<br>        # long as possible. As a result, when r_accept falls below this we can<br>        # help increase the acceptance rate by reducing the set of possible<br>        # swap candidates based on the observation that near the end of<br>        # placement, most things are near their optimal location and thus long<br>        # distance swaps are unlikely to be useful.<br>        distance_limit = 1.0 - 0.44 + r_accept<br>        distance_limit = min(max(distance_limit, 1.0),<br>                             max(machine.width, machine.height))<br><br>        iteration_count += num_steps<br>        logger.debug("Iteration: %d, "<br>                     "Cost: %0.1f, "<br>                     "Kept: %0.1f%%, "<br>                     "Temp: %0.3f, "<br>                     "Dist: %d.",<br>                     iteration_count, current_cost,<br>                     r_accept100, temperature, math.ceil(distance_limit))<br><br>        # Call the user callback before the next iteration, terminating if<br>        # requested.<br>        if on_temperature_change is not None:<br>            placements = k.get_placements().copy()<br>            finalise_same_chip_constraints(substitutions, placements)<br>            ret_val = on_temperature_change(iteration_count,<br>                                            placements,<br>                                            current_cost,<br>                                            r_accept,<br>                                            temperature,<br>                                            distance_limit)<br>            if ret_val is False:<br>                break<br><br>    logger.info("Anneal terminated after %d iterations.", iteration_count)<br><br>    placements = k.get_placements()<br>    finalise_same_chip_constraints(substitutions, placements)<br><br>    return placements

### DOC[3] (IRRELEVANT) leetcode/csn_python_train_385093.txt
> def generate_ANSI_to_move_cursor(cur_x, cur_y, target_x, target_y):<br>    """<br>        Note that x positions are absolute (0=SOL) while y positions are relative. That is,<br>        we move the y position the relative distance between cur_y and target_y. It doesn't<br>        mean that cur_y=0 means we are on the first line of the screen. We have no way of<br>        knowing how tall the screen is, etc. at draw-time so we can't know this. <br>    """<br><br><br>    """<br>        SIZE - this code (in concert with its caller) implements what I would call "local optimizations"<br>        to try to minimize the number and size of cursor movements outputted. It does not attempt "global<br>        optimizations" which I think are rarely going to be worthwhile. See the DESIGN NOTE on global<br>        optimizations in this file for more details <br>    """        <br><br><br>    string = ""<br><br>    if cur_y < target_y:    # MOVE DOWN<br>        y_dist = target_y - cur_y<br><br>        # See if we can optimize moving x and y together<br>        if cur_x == target_x: <br>        <br>            # Need to move in y only<br>            if target_x != 0: <br>                # Already in correct x position which is NOT SOL. Just output code to move cursor <br>                # down. No special optimization is possible since \n would take us to SOL and then <br>                # we'd also need to output a move for x. <br>                return "\x1b[{0}B".format(y_dist)  # ANSI code to move down N lines<br>            else:<br>                # Already in correct x position which is SOL. Output efficient code to move down.<br>                return generate_optimized_y_move_down_x_SOL(y_dist)<br>        else:<br>        <br>            # Need to move in x and y<br>            if target_x != 0: <br>                # x move is going to be required so we'll move y efficiently and as a side<br>                # effect, x will become 0. Code below will move x to the right place<br>                string += generate_optimized_y_move_down_x_SOL(y_dist)<br>                cur_x = 0<br>            else:<br>                # Output move down that brings x to SOL. Then we're done.<br>                return generate_optimized_y_move_down_x_SOL(y_dist)<br>                <br>    elif cur_y  target_y:  # MOVE UP<br>        if target_x == 0:        <br>            # We want to move up and be at the SOL. That can be achieved with one command so we're<br>            # done and we return it. However note that some terminals may not support this so we<br>            # might have to remove this optimization or make it optional if that winds up mattering for terminals we care about.  <br>            return "\x1b[{0}F".format(cur_y - target_y)     # ANSI code to move up N lines and move x to SOL<br>        else:<br>            string += "\x1b[{0}A".format(cur_y - target_y)  # ANSI code to move up N lines <br><br>    if cur_x < target_x:    # MOVE RIGHT<br>        # SIZE - Note that when the bgcolor is specified (not None) and not overdrawing another drawing (as in an animation case)<br>        # an optimization could be performed to draw spaces rather than output cursor advances. This would use less<br>        # size when advancing less than 3 columns since the min escape sequence here is len 4. Not implementing this now<br>        # \t (tab) could also be a cheap way to move forward, but not clear we can determine how far it goes or if that would<br>        # be consistent, nor whether it is ever destructive.<br>        string += "\x1b[{0}C".format(target_x - cur_x)  # ANSI code to move cursor right N columns<br>    elif cur_x  target_x:  # MOVE LEFT<br>        # SIZE - potential optimizations: \b (backspace) could be a cheaper way to move backwards when there is only a short<br>        # way to go. However, not sure if it is ever destructive so not bothering with it now.    <br>        # If we need to move to x=0, \r could be a cheap way to get there. However not entirely clear whether some terminals<br>        # will move to next line as well, and might sometimes be destructive. Not going to research this so not doing it now. <br>        string += "\x1b[{0}D".format(cur_x - target_x)  # ANSI code to move cursor left N columns <br><br>    return string

### DOC[4] (IRRELEVANT) leetcode/leetcode_1610.txt
> def xor_operation(n, start):<br>    """You are given an array `points`, an integer `angle`, and your `location`, where `location = [posx, posy]` and `points[i] = [xi, yi]` both denote integral coordinates on the X-Y plane.<br><br>Initially, you are facing directly east from your position. You cannot move from your position, but you can rotate. In other words, `posx` and `posy` cannot be changed. Your field of view in degrees is represented by `angle`, determining how wide you can see from any given view direction. Let `d` be the amount in degrees that you rotate counterclockwise. Then, your field of view is the inclusive range of angles `[d - angle/2, d + angle/2]`.<br><br>Your browser does not support the video tag or this video format.<br><br>You can see some set of points if, for each point, the angle formed by the point, your position, and the immediate east direction from your position is in your field of view.<br><br>There can be multiple points at one coordinate. There may be points at your location, and you can always see these points regardless of your rotation. Points do not obstruct your vision to other points.<br><br>Return _the maximum number of points you can see_.<br><br>Example 1:<br><br>Input: points = \[\[2,1\],\[2,2\],\[3,3\]\], angle = 90, location = \[1,1\]<br>Output: 3<br>Explanation: The shaded region represents your field of view. All points can be made visible in your field of view, including \[3,3\] even though \[2,2\] is in front and in the same line of sight.<br><br>Example 2:<br><br>Input: points = \[\[2,1\],\[2,2\],\[3,4\],\[1,1\]\], angle = 90, location = \[1,1\]<br>Output: 4<br>Explanation: All points can be made visible in your field of view, including the one at your location.<br><br>Example 3:<br><br>Input: points = \[\[1,0\],\[2,1\]\], angle = 13, location = \[1,1\]<br>Output: 1<br>Explanation: You can only see one of the two points, as shown above.<br><br>Constraints:<br><br>   `1 <= points.length <= 105`<br>   `points[i].length == 2`<br>   `location.length == 2`<br>   `0 <= angle < 360`<br>   `0 <= posx, posy, xi, yi <= 100`"""<br><br>    xor_result = 0<br>    for i in range(n):<br>        xor_result ^= (start + 2  i)<br>    return xor_result

### DOC[5] (IRRELEVANT) leetcode/csn_python_train_309604.txt
> def calcSegments(x, v):<br>    """<br>    Find index vectors `rise` and `fall` such that `rise` holds the indeces `i`<br>    such that x[i+1]x[i] and `fall` holds indeces `j` such that either<br>    - x[j+1] < x[j] or,<br>    - x[j]x[j-1] and v[j]<v[j-1].<br><br>    The vectors are essential to the DCEGM algorithm, as they definite the<br>    relevant intervals to be used to construct the upper envelope of potential<br>    solutions to the (necessary) first order conditions.<br><br>    Parameters<br>    ----------<br>    x : np.ndarray<br>        array of points where `v` is evaluated<br>    v : np.ndarray<br>        array of values of some function of `x`<br><br>    Returns<br>    -------<br>    rise : np.ndarray<br>        see description above<br>    fall : np.ndarray<br>        see description above<br>    """<br>    # NOTE: assumes that the first segment is in fact increasing (forced in EGM<br>    # by augmentation with the constrained segment).<br>    # elements in common grid g<br><br>    # Identify index intervals of falling and rising regions<br>    # We need these to construct the upper envelope because we need to discard<br>    # solutions from the inverted Euler equations that do not represent optimal<br>    # choices (the FOCs are only necessary in these models).<br>    #<br>    # `fall` is a vector of indeces that represent the first elements in all<br>    # of the falling segments (the curve can potentially fold several times)<br>    fall = np.empty(0, dtype=int) # initialize with empty and then add the last point below while-loop<br><br>    rise = np.array([0]) # Initialize such thatthe lowest point is the first grid point<br>    i = 1 # Initialize<br>    while i <= len(x) - 2:<br>        # Check if the next (`ip1` stands for i plus 1) grid point is below the<br>        # current one, such that the line is folding back.<br>        ip1_falls = x[i+1] < x[i] # true if grid decreases on index increment<br>        i_rose = x[i]  x[i-1] # true if grid decreases on index decrement<br>        val_fell = v[i] < v[i-1] # true if value rises on index decrement<br><br>        if (ip1_falls and i_rose) or (val_fell and i_rose):<br><br>            # we are in a region where the endogenous grid is decreasing or<br>            # the value function rises by stepping back in the grid.<br>            fall = np.append(fall, i) # add the index to the vector<br><br>            # We now iterate from the current index onwards until we find point<br>            # where resources rises again. Unfortunately, we need to check<br>            # each points, as there can be multiple spells of falling endogenous<br>            # grids, so we cannot use bisection or some other fast algorithm.<br>            k = i<br>            while x[k+1] < x[k]:<br>                k = k + 1<br>            # k now holds either the next index the starts a new rising<br>            # region, or it holds the length of M, `m_len`.<br><br>            rise = np.append(rise, k)<br><br>            # Set the index to the point where resources again is rising<br>            i = k<br><br>        i = i + 1<br><br>    # Add the last index for convenience (then all segments are complete, as<br>    # len(fall) == len(rise), and we can form them by range(rise[j], fall[j]+1).<br>    fall = np.append(fall, len(v)-1)<br><br>    return rise, fall


## Ground Truth

### GROUND TRUTH 0, ranked 22, leetcode/leetcode_999.txt
> def regionsBySlashes(grid):<br>    """On an `8 x 8` chessboard, there is exactly one white rook `'R'` and some number of white bishops `'B'`, black pawns `'p'`, and empty squares `'.'`.<br><br>When the rook moves, it chooses one of four cardinal directions (north, east, south, or west), then moves in that direction until it chooses to stop, reaches the edge of the board, captures a black pawn, or is blocked by a white bishop. A rook is considered attacking a pawn if the rook can capture the pawn on the rook's turn. The number of available captures for the white rook is the number of pawns that the rook is attacking.<br><br>Return _the number of available captures for the white rook_.<br><br>Example 1:<br><br>Input: board = \[\[ ". ", ". ", ". ", ". ", ". ", ". ", ". ", ". "\],\[ ". ", ". ", ". ", "p ", ". ", ". ", ". ", ". "\],\[ ". ", ". ", ". ", "R ", ". ", ". ", ". ", "p "\],\[ ". ", ". ", ". ", ". ", ". ", ". ", ". ", ". "\],\[ ". ", ". ", ". ", ". ", ". ", ". ", ". ", ". "\],\[ ". ", ". ", ". ", "p ", ". ", ". ", ". ", ". "\],\[ ". ", ". ", ". ", ". ", ". ", ". ", ". ", ". "\],\[ ". ", ". ", ". ", ". ", ". ", ". ", ". ", ". "\]\]<br>Output: 3<br>Explanation: In this example, the rook is attacking all the pawns.<br><br>Example 2:<br><br>Input: board = \[\[ ". ", ". ", ". ", ". ", ". ", ". ", ". ", ". "\],\[ ". ", "p ", "p ", "p ", "p ", "p ", ". ", ". "\],\[ ". ", "p ", "p ", "B ", "p ", "p ", ". ", ". "\],\[ ". ", "p ", "B ", "R ", "B ", "p ", ". ", ". "\],\[ ". ", "p ", "p ", "B ", "p ", "p ", ". ", ". "\],\[ ". ", "p ", "p ", "p ", "p ", "p ", ". ", ". "\],\[ ". ", ". ", ". ", ". ", ". ", ". ", ". ", ". "\],\[ ". ", ". ", ". ", ". ", ". ", ". ", ". ", ". "\]\]<br>Output: 0<br>Explanation: The bishops are blocking the rook from attacking any of the pawns.<br><br>Example 3:<br><br>Input: board = \[\[ ". ", ". ", ". ", ". ", ". ", ". ", ". ", ". "\],\[ ". ", ". ", ". ", "p ", ". ", ". ", ". ", ". "\],\[ ". ", ". ", ". ", "p ", ". ", ". ", ". ", ". "\],\[ "p ", "p ", ". ", "R ", ". ", "p ", "B ", ". "\],\[ ". ", ". ", ". ", ". ", ". ", ". ", ". ", ". "\],\[ ". ", ". ", ". ", "B ", ". ", ". ", ". ", ". "\],\[ ". ", ". ", ". ", "p ", ". ", ". ", ". ", ". "\],\[ ". ", ". ", ". ", ". ", ". ", ". ", ". ", ". "\]\]<br>Output: 3<br>Explanation: The rook is attacking the pawns at positions b5, d6, and f5.<br><br>Constraints:<br><br>   `board.length == 8`<br>   `board[i].length == 8`<br>   `board[i][j]` is either `'R'`, `'.'`, `'B'`, or `'p'`<br>   There is exactly one cell with `board[i][j] == 'R'`"""<br><br>    n = len(grid)<br>    graph = [[0]  (n  3) for _ in range(n  3)]<br><br>    for i in range(n):<br>        for j in range(n):<br>            if grid[i][j] == '/':<br>                graph[i  3][j  3 + 2] = graph[i  3 + 1][j  3 + 1] = graph[i  3 + 2][j  3] = 1<br>            if grid[i][j] == '\\':<br>                graph[i  3][j  3] = graph[i  3 + 1][j  3 + 1] = graph[i  3 + 2][j  3 + 2] = 1<br><br>    regions = 0<br>    for i in range(n  3):<br>        for j in range(n  3):<br>            if not graph[i][j]:<br>                regions += 1<br>                dfs(graph, i, j)<br><br>    return regions<br><br>def dfs(graph, i, j):<br>    n = len(graph)<br>    if i < 0 or j < 0 or i = n or j = n or graph[i][j]:<br>        return<br><br>    graph[i][j] = 1<br>    dfs(graph, i - 1, j)<br>    dfs(graph, i + 1, j)<br>    dfs(graph, i, j - 1)<br>    dfs(graph, i, j + 1)
