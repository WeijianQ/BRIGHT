# Query `140`

## Original Question

*There exists an undirected and unrooted tree with `n` nodes indexed from `0` to `n - 1`. You are given an integer `n` and a 2D integer array edges of length `n - 1`, where `edges[i] = [ai, bi]` indicates that there is an edge between nodes `ai` and `bi` in the tree. You are also given an array `coins` of size `n` where `coins[i]` can be either `0` or `1`, where `1` indicates the presence of a coin in the vertex `i`.

Initially, you choose to start at any vertex in the tree. Then, you can perform the following operations any number of times:

   Collect all the coins that are at a distance of at most `2` from the current vertex, or
   Move to any adjacent vertex in the tree.

Find _the minimum number of edges you need to go through to collect all the coins and go back to the initial vertex_.

Note that if you pass an edge several times, you need to count it into the answer several times.

Example 1:

Input: coins = \[1,0,0,0,0,1\], edges = \[\[0,1\],\[1,2\],\[2,3\],\[3,4\],\[4,5\]\]
Output: 2
Explanation: Start at vertex 2, collect the coin at vertex 0, move to vertex 3, collect the coin at vertex 5 then move back to vertex 2.

Example 2:

Input: coins = \[0,0,0,1,1,0,0,1\], edges = \[\[0,1\],\[0,2\],\[1,3\],\[1,4\],\[2,5\],\[5,6\],\[5,7\]\]
Output: 2
Explanation: Start at vertex 0, collect the coins at vertices 4 and 3, move to vertex 2,  collect the coin at vertex 7, then move back to vertex 0.

Constraints:

   `n == coins.length`
   `1 <= n <= 3  104`
   `0 <= coins[i] <= 1`
   `edges.length == n - 1`
   `edges[i].length == 2`
   `0 <= ai, bi < n`
   `ai != bi`
   `edges` represents a valid tree.*

## gpt4 Reasoning

```markdown
To address this problem effectively, we need to break it down into manageable parts and identify the key challenges it presents. The essential problem is finding the minimum number of edges that need to be traversed to collect all coins and return to the starting vertex in an undirected, unrooted tree.

### Step 1: Understanding the Tree Structure

The first step involves understanding the structure of the tree given by the `edges` array. A tree is a special type of graph that is connected and acyclic, meaning there is exactly one path between any two nodes. This property will be crucial in determining the optimal path for collecting coins.

### Step 2: Identifying Coin Locations

The `coins` array indicates which vertices have coins (denoted by `1`). The distribution of coins will heavily influence the choice of the starting vertex and the path taken. Vertices with coins that are isolated or far from others will be more costly to reach.

### Step 3: Choosing a Starting Vertex

Choosing an optimal starting vertex is not straightforward because it depends on the distribution of coins and the tree's structure. However, a good heuristic might be to start at or near a vertex that is centrally located among all the vertices with coins. This minimizes the maximum distance to any coin.

### Step 4: Strategy for Collecting Coins

Given the operations available, the strategy involves two parts:
- **Collecting coins within a distance of 2:** From any vertex, we can collect coins from the vertex itself, any adjacent vertex, and any vertex that is two edges away. This operation does not require moving and thus does not add to the count of edges traversed.
- **Moving to adjacent vertices:** To collect coins not within the immediate reach, we need to move across edges. The goal is to minimize these movements while ensuring all coins are collected.

### Step 5: Minimizing Edge Traversals

To minimize the number of edges traversed, one approach is to create a "virtual" center or centers by identifying vertices that can act as collection pointsâ€”vertices from which multiple coins can be collected with minimal movement. Then, plan a route that connects these centers in a way that minimizes backtracking.

### Step 6: Returning to the Starting Vertex

After collecting all coins, returning to the starting vertex requires traversing the same path back if the path is linear or choosing the shortest path back if the tree has branches. This should be factored into the initial planning to avoid unnecessary edge traversals.

### Algorithmic Approach

1. **Build the tree:** Represent the tree using adjacency lists to easily navigate between vertices.
2. **Find coin distribution:** Identify which vertices have coins and their distribution relative to each other.
3. **Identify potential starting vertices:** Look for vertices that are central to the distribution of coins. This might involve calculating the centroid of the tree or finding vertices with the highest number of coins within a distance of 2.
4. **Plan the route:** Starting from the chosen vertex, plan a route that collects coins efficiently, possibly using depth-first search (DFS) or breadth-first search (BFS) strategies to explore the tree. Keep track of vertices visited and coins collected to avoid unnecessary movements.
5. **Calculate edge traversals:** As the route is planned, count the number of edge traversals required to collect all coins and return to the starting point.

### Conclusion

This problem combines elements of graph theory with strategic planning. The key to solving it lies in understanding the tree's structure, the distribution of coins, and devising an efficient route that minimizes backtracking. While the exact solution may vary depending on the tree's shape and coin distribution, the approach outlined provides a framework for tackling similar problems.
```

### Metrics

```
recip_rank: 0.0625
P_1: 0.0000
P_5: 0.0000
P_10: 0.0000
P_25: 0.0400
P_50: 0.0200
P_100: 0.0100
recall_1: 0.0000
recall_5: 0.0000
recall_10: 0.0000
recall_25: 0.5000
recall_50: 0.5000
recall_100: 0.5000
ndcg_cut_1: 0.0000
ndcg_cut_5: 0.0000
ndcg_cut_10: 0.0000
ndcg_cut_25: 0.1500
ndcg_cut_50: 0.1500
ndcg_cut_100: 0.1500
map_cut_1: 0.0000
map_cut_5: 0.0000
map_cut_10: 0.0000
map_cut_25: 0.0312
map_cut_50: 0.0312
map_cut_100: 0.0312
```

## Retrieval Results

### DOC[1] (IRRELEVANT) leetcode/csn_python_train_333992.txt
> def canonical_order(self):<br>        """The vertices in a canonical or normalized order.<br><br>           This routine will return a list of vertices in an order that does not<br>           depend on the initial order, but only depends on the connectivity and<br>           the return values of the function self.get_vertex_string.<br><br>           Only the vertices that are involved in edges will be included. The<br>           result can be given as first argument to self.get_subgraph, with<br>           reduce=True as second argument. This will return a complete canonical<br>           graph.<br><br>           The routine is designed not to use symmetry relations that are<br>           obtained with the GraphSearch routine. We also tried to create an<br>           ordering that feels like natural, i.e. starting in the center and<br>           pushing vertices with few equivalents to the front. If necessary, the<br>           nature of the vertices and  their bonds to atoms closer to the center<br>           will also play a role, but only as a last resort.<br>        """<br>        # A) find an appropriate starting vertex.<br>        # Here we take a central vertex that has a minimal number of symmetrical<br>        # equivalents, 'the highest atom number', and the highest fingerprint.<br>        # Note that the symmetrical equivalents are computed from the vertex<br>        # fingerprints, i.e. without the GraphSearch.<br>        starting_vertex = max(<br>            (<br>                -len(self.equivalent_vertices[vertex]),<br>                self.get_vertex_string(vertex),<br>                self.vertex_fingerprints[vertex].tobytes(),<br>                vertex<br>            ) for vertex in self.central_vertices<br>        )[-1]<br><br>        # B) sort all vertices based on<br>        #      1) distance from central vertex<br>        #      2) number of equivalent vertices<br>        #      3) vertex string, (higher atom numbers come first)<br>        #      4) fingerprint<br>        #      5) vertex index<br>        # The last field is only included to collect the result of the sort.<br>        # The fingerprint on itself would be sufficient, but the three first are<br>        # there to have a naturally appealing result.<br>        l = [<br>            [<br>                -distance,<br>                -len(self.equivalent_vertices[vertex]),<br>                self.get_vertex_string(vertex),<br>                self.vertex_fingerprints[vertex].tobytes(),<br>                vertex<br>            ] for vertex, distance in self.iter_breadth_first(starting_vertex)<br>            if len(self.neighbors[vertex])  0<br>        ]<br>        l.sort(reverse=True)<br><br>        # C) The order of some vertices is still not completely set. e.g.<br>        # consider the case of allene. The four hydrogen atoms are equivalent,<br>        # but one can have two different orders: make geminiles consecutive or<br>        # don't. It is more trikcy than one would think at first sight. In the<br>        # case of allene, geminility could easily solve the problem. Consider a<br>        # big flat rotationally symmetric molecule (order 2). The first five<br>        # shells are order 4 and one would just give a random order to four<br>        # segemnts in the first shell. Only when one reaches the outer part that<br>        # has order two, it turns out that the arbitrary choices in the inner<br>        # shell play a role. So it does not help to look at relations with<br>        # vertices at inner or current shells only. One has to consider the<br>        # whole picture. (unit testing reveals troubles like these)<br><br>        # I need some sleep now. The code below checks for potential fuzz and<br>        # will raise an error if the ordering is not fully determined yet. One<br>        # day, I'll need this code more than I do now, and I'll fix things up.<br>        # I know how to do this, but I don't care enough right now.<br>        # -- Toon<br>        for i in range(1, len(l)):<br>            if l[i][:-1] == l[i-1][:-1]:<br>                raise NotImplementedError<br><br>        # D) Return only the vertex indexes.<br>        return [record[-1] for record in l]

### DOC[2] (IRRELEVANT) leetcode/csn_python_train_144360.txt
> def place(vertices_resources, nets, machine, constraints,<br>          effort=1.0, random=default_random, on_temperature_change=None,<br>          kernel=default_kernel, kernel_kwargs={}):<br>    """A flat Simulated Annealing based placement algorithm.<br><br>    This placement algorithm uses simulated annealing directly on the supplied<br>    problem graph with the objective of reducing wire lengths (and thus,<br>    indirectly, the potential for congestion). Though computationally<br>    expensive, this placer produces relatively good placement solutions.<br><br>    The annealing temperature schedule used by this algorithm is taken from<br>    "VPR: A New Packing, Placement and Routing Tool for FPGA Research" by<br>    Vaughn Betz and Jonathan Rose from the "1997 International Workshop on<br>    Field Programmable Logic and Applications".<br><br>    Two implementations of the algorithm's kernel are available:<br><br>     :py:class:`~rig.place_and_route.place.sa.python_kernel.PythonKernel` A<br>      pure Python implementation which is available on all platforms supported<br>      by Rig.<br>     :py:class:`~rig.place_and_route.place.sa.c_kernel.CKernel` A C<br>      implementation which is typically 50-150x faster than the basic Python<br>      kernel. Since this implementation requires a C compiler during<br>      installation, it is an optional feature of Rig. See the<br>      :py:class:`CKernel's documentation<br>      <rig.place_and_route.place.sa.c_kernel.CKernel` for details.<br><br>    The fastest kernel installed is used by default and can be manually chosen<br>    using the ``kernel`` argument.<br><br>    This algorithm produces INFO level logging information describing the<br>    progress made by the algorithm.<br><br>    .. warning:<br>        This algorithm does not attempt to produce good solutions to the<br>        bin-packing problem of optimally fitting vertices into chips and it may<br>        fail if a good placement requires good bin packing.<br><br>    Parameters<br>    ----------<br>    effort : float<br>        A scaling factor for the number of iterations the algorithm should run<br>        for. 1.0 is probably about as low as you'll want to go in practice and<br>        runtime increases linearly as you increase this parameter.<br>    random : :py:class:`random.Random`<br>        A Python random number generator. Defaults to ``import random`` but can<br>        be set to your own instance of :py:class:`random.Random` to allow you<br>        to control the seed and produce deterministic results. For results to<br>        be deterministic, vertices_resources must be supplied as an<br>        :py:class:`collections.OrderedDict`.<br>    on_temperature_change : callback_function or None<br>        An (optional) callback function which is called every time the<br>        temperature is changed. This callback can be used to provide status<br>        updates<br><br>        The callback function is passed the following arguments:<br><br>         ``iteration_count``: the number of iterations the placer has<br>          attempted (integer)<br>         ``placements``: The current placement solution.<br>         ``cost``: the weighted sum over all nets of bounding-box size.<br>          (float)<br>         ``acceptance_rate``: the proportion of iterations which have resulted<br>          in an accepted change since the last callback call. (float between<br>          0.0 and 1.0)<br>         ``temperature``: The current annealing temperature. (float)<br>         ``distance_limit``: The maximum distance any swap may be made over.<br>          (integer)<br><br>        If the callback returns False, the anneal is terminated immediately and<br>        the current solution is returned.<br>    kernel : :py:class:`~rig.place_and_route.place.sa.kernel.Kernel`<br>        A simulated annealing placement kernel. A sensible default will be<br>        chosen based on the available kernels on this machine. The kernel may<br>        not be used if the placement problem has a trivial solution.<br>    kernel_kwargs : dict<br>        Optional kernel-specific keyword arguments to pass to the kernel<br>        constructor.<br>    """<br>    # Special case: just return immediately when there's nothing to place<br>    if len(vertices_resources) == 0:<br>        return {}<br><br>    # Within the algorithm we modify the resource availability values in the<br>    # machine to account for the effects of the current placement. As a result,<br>    # an internal copy of the structure must be made.<br>    machine = machine.copy()<br><br>    # {vertex: (x, y), ...} gives the location of all vertices whose position<br>    # is fixed by a LocationConstraint.<br>    fixed_vertices = {}<br><br>    # Handle constraints<br>    vertices_resources, nets, constraints, substitutions = \<br>        apply_same_chip_constraints(vertices_resources, nets, constraints)<br>    for constraint in constraints:<br>        if isinstance(constraint, LocationConstraint):<br>            # Location constraints are handled by recording the set of fixed<br>            # vertex locations and subtracting their resources from the chips<br>            # they're allocated to. These vertices will then not be added to<br>            # the internal placement data structure to prevent annealing from<br>            # moving them. They will be re-introduced at the last possible<br>            # moment.<br>            location = constraint.location<br>            if location not in machine:<br>                raise InvalidConstraintError(<br>                    "Chip requested by {} unavailable".format(machine))<br>            vertex = constraint.vertex<br><br>            # Record the constrained vertex's location<br>            fixed_vertices[vertex] = location<br><br>            # Make sure the vertex fits at the requested location (updating the<br>            # resource availability after placement)<br>            resources = vertices_resources[vertex]<br>            machine[location] = subtract_resources(machine[location],<br>                                                   resources)<br>            if overallocated(machine[location]):<br>                raise InsufficientResourceError(<br>                    "Cannot meet {}".format(constraint))<br>        elif isinstance(constraint,  # pragma: no branch<br>                        ReserveResourceConstraint):<br>            apply_reserve_resource_constraint(machine, constraint)<br><br>    # Initially randomly place the movable vertices<br>    movable_vertices = {v for v in vertices_resources<br>                        if v not in fixed_vertices}<br>    initial_placements = _initial_placement(movable_vertices,<br>                                            vertices_resources,<br>                                            machine, random)<br><br>    # Include the fixed vertices in initial placement<br>    initial_placements.update(fixed_vertices)<br><br>    # Filter out empty or singleton nets and those weighted as zero since they<br>    # cannot influence placement.<br>    nets = [n for n in nets if len(set(n))  1 and n.weight  0.0]<br><br>    # Special cases where no placement effort is required:<br>    #  There is only one chip<br>    #  There are no resource types to be consumed<br>    #  No effort is to be made<br>    #  No movable vertices<br>    #  There are no nets (and moving things has no effect)<br>    trivial = ((machine.width, machine.height) == (1, 1) or<br>               len(machine.chip_resources) == 0 or<br>               effort == 0.0 or<br>               len(movable_vertices) == 0 or<br>               len(nets) == 0)<br>    if trivial:<br>        logger.info("Placement has trivial solution. SA not used.")<br>        finalise_same_chip_constraints(substitutions, initial_placements)<br>        return initial_placements<br><br>    # Intialise the algorithm kernel<br>    k = kernel(vertices_resources, movable_vertices, set(fixed_vertices),<br>               initial_placements, nets, machine, random, kernel_kwargs)<br><br>    logger.info("SA placement kernel: %s", kernel.__name__)<br><br>    # Specifies the maximum distance any swap can span. Initially consider<br>    # swaps that span the entire machine.<br>    distance_limit = max(machine.width, machine.height)<br><br>    # Determine initial temperature according to the heuristic used by VPR: 20<br>    # times the standard deviation of len(movable_vertices) random swap costs.<br>    # The arbitrary very-high temperature is used to cause "all" swaps to be<br>    # accepted.<br>    _0, _1, cost_delta_sd = k.run_steps(len(movable_vertices),<br>                                        distance_limit,<br>                                        1e100)<br>    temperature = 20.0  cost_delta_sd<br><br>    # The number of swap-attempts between temperature changes is selected by<br>    # the heuristic used by VPR. This value is scaled linearly by the effort<br>    # parameter.<br>    num_steps = max(1, int(effort  len(vertices_resources)1.33))<br><br>    logger.info("Initial placement temperature: %0.1f", temperature)<br><br>    # Counter for the number of swap attempts made (used for diagnostic<br>    # purposes)<br>    iteration_count = 0<br><br>    # Holds the total cost of the current placement. This default value chosen<br>    # to ensure the loop below iterates at least once.<br>    current_cost = 0.0<br><br>    # The annealing algorithm runs until a heuristic termination condition<br>    # (taken from VPR) is hit. The heuristic waits until the temperature falls<br>    # below a small fraction of the average net cost.<br>    while temperature  (0.005  current_cost) / len(nets):<br>        # Run an iteration at the current temperature<br>        num_accepted, current_cost, _ = k.run_steps(<br>            num_steps, int(math.ceil(distance_limit)), temperature)<br><br>        # The ratio of accepted-to-not-accepted changes<br>        r_accept = num_accepted / float(num_steps)<br><br>        # Special case: Can't do better than 0 cost! This is a special case<br>        # since the normal termination condition will not terminate if the cost<br>        # doesn't drop below 0.<br>        if current_cost == 0:<br>            break<br><br>        # The temperature is reduced by a factor heuristically based on the<br>        # acceptance rate. The schedule below attempts to maximise the time<br>        # spent at temperatures where a large portion (but not all) of changes<br>        # are being accepted. If lots of changes are being accepted (e.g.<br>        # during high-temperature periods) then most of them are likely not to<br>        # be beneficial. If few changes are being accepted, we're probably<br>        # pretty close to the optimal placement.<br>        if r_accept  0.96:<br>            alpha = 0.5<br>        elif r_accept  0.8:<br>            alpha = 0.9<br>        elif r_accept  0.15:<br>            alpha = 0.95<br>        else:<br>            alpha = 0.8<br>        temperature = alpha  temperature<br><br>        # According to:<br>        #  M. Huang, F. Romeo, and A. Sangiovanni-Vincentelli, "An Efficient<br>        #   General Cooling Schedule for Simulated Annealing" ICCAD, 1986, pp.<br>        #   381 - 384 and J. Lam<br>        #  J. Delosme, "Performance of a New Annealing Schedule" DAC, 1988,<br>        #   pp. 306 - 311.<br>        # It is desirable to keep the acceptance ratio as close to 0.44 for as<br>        # long as possible. As a result, when r_accept falls below this we can<br>        # help increase the acceptance rate by reducing the set of possible<br>        # swap candidates based on the observation that near the end of<br>        # placement, most things are near their optimal location and thus long<br>        # distance swaps are unlikely to be useful.<br>        distance_limit = 1.0 - 0.44 + r_accept<br>        distance_limit = min(max(distance_limit, 1.0),<br>                             max(machine.width, machine.height))<br><br>        iteration_count += num_steps<br>        logger.debug("Iteration: %d, "<br>                     "Cost: %0.1f, "<br>                     "Kept: %0.1f%%, "<br>                     "Temp: %0.3f, "<br>                     "Dist: %d.",<br>                     iteration_count, current_cost,<br>                     r_accept100, temperature, math.ceil(distance_limit))<br><br>        # Call the user callback before the next iteration, terminating if<br>        # requested.<br>        if on_temperature_change is not None:<br>            placements = k.get_placements().copy()<br>            finalise_same_chip_constraints(substitutions, placements)<br>            ret_val = on_temperature_change(iteration_count,<br>                                            placements,<br>                                            current_cost,<br>                                            r_accept,<br>                                            temperature,<br>                                            distance_limit)<br>            if ret_val is False:<br>                break<br><br>    logger.info("Anneal terminated after %d iterations.", iteration_count)<br><br>    placements = k.get_placements()<br>    finalise_same_chip_constraints(substitutions, placements)<br><br>    return placements

### DOC[3] (IRRELEVANT) leetcode/csn_python_train_59640.txt
> def mesh_register(mesh, field, max_steps=2000, max_step_size=0.05, max_pe_change=1,<br>                  method='random', return_report=False, initial_coordinates=None):<br>    '''<br>    mesh_register(mesh, field) yields the mesh that results from registering the given mesh by<br>    minimizing the given potential field description over the position of the vertices in the<br>    mesh. The mesh argument must be a Mesh object (see neuropythy.geometry) such as can be read<br>    from FreeSurfer using the neuropythy.freesurfer_subject function. The field argument must be<br>    a list of field names and arguments; with the exception of 'mesh' (or 'standard'), the <br>    arguments must be a list, the first element of which is the field type name, the second<br>    element of which is the field shape name, and the final element of which is a dictionary of<br>    arguments accepted by the field shape.<br><br>    The following are valid field type names:<br>       'mesh' : the standard mesh potential, which includes an edge potential, an angle<br>        potential, and a perimeter potential. Accepts no arguments, and must be passed as a<br>        single string instead of a list.<br>       'edge': an edge potential field in which the potential is a function of the change in the<br>        edge length, summed over each edge in the mesh.<br>       'angle': an angle potential field in which the potential is a function of the change in<br>        the angle measure, summed over all angles in the mesh.<br>       'perimeter': a potential that depends on the vertices on the perimeter of a 2D mesh<br>        remaining in place; the potential changes as a function of the distance of each perimeter<br>        vertex from its reference position.<br>       'anchor': a potential that depends on the distance of a set of vertices from fixed points<br>        in space. After the shape name second argument, an anchor must be followed by a list of<br>        vertex ids then a list of fixed points to which the vertex ids are anchored:<br>        ['anchor', shape_name, vertex_ids, fixed_points, args...].<br><br>    The following are valid shape names:<br>       'harmonic': a harmonic function with the form (c/q)  abs(x - x0)^q.<br>        Parameters: <br>           'scale', the scale parameter c; default: 1.<br>           'order', the order parameter q; default: 2.<br>       'Lennard-Jones': a Lennard-Jones function with the form c (1 + (r0/r)^q - 2(r0/r)^(q/2));<br>        Parameters:<br>           'scale': the scale parameter c; default: 1. <br>           'order': the order parameter q; default: 2.<br>       'Gaussian': A Gaussian function with the form c (1 - exp(-0.5 abs((x - x0)/s)^q))<br>        Parameters:<br>           'scale': the scale parameter c; default: 1.<br>           'order': the order parameter q; default: 2.<br>           'sigma': the standard deviation parameter s; default: 1.<br>       'infinite-well': an infinite well function with the form <br>        c ( (((x0 - m)/(x - m))^q - 1)^2 + (((M - x0)/(M - x))^q - 1)^2 )<br>        Parameters:<br>           'scale': the scale parameter c; default: 1.<br>           'order': the order parameter q; default: 0.5.<br>           'min': the minimum value m; default: 0.<br>           'max': the maximum value M; default: pi.<br><br>    Options: The following optional arguments are accepted.<br>       max_steps (default: 2000) the maximum number of steps to minimize for.<br>       max_step_size (default: 0.1) the maximum distance to allow a vertex to move in a single<br>        minimization step.<br>       max_pe_change: the maximum fraction of the initial potential value that the minimizer<br>        should minimize away before returning; i.e., 0 indicates that no minimization should be<br>        allowed while 0.9 would indicate that the minimizer should minimize until the potential<br>        is 10% or less of the initial potential.<br>       return_report (default: False) indicates that instead of returning the registered data,<br>        mesh_register should instead return the Java Minimizer.Report object (for debugging).<br>       method (default: 'random') specifies the search algorithm used; available options are <br>        'random', 'nimble', and 'pure'. Generally all options will converge on a similar solution,<br>        but usually 'random' is fastest. The 'pure' option uses the nben library's step function,<br>        which performs straight-forward gradient descent. The 'nimble' option performs a gradient<br>        descent in which subsets of vertices in the mesh that have the highest gradients during the<br>        registration are updated more often than those vertices with small gradients; this can<br>        sometimes but not always increase the speed of the minimization. Note that instead of<br>        'nimble', one may alternately provide ('nimble', k) where k is the number of partitions that<br>        the vertices should be sorted into (by partition). 'nimble' by itself is equivalent to <br>        ('nimble', 4). Note also that a single step of nimble minimization is equivalent to 2k<br>        steps of 'pure' minimization. Finally, the 'random' option uses the nben library's<br>        randomStep function, which is a gradient descent algorithm that moves each vertex in the<br>        direction of its negative gradient during each step but which randomizes the length of the<br>        gradient at each individual vertex by drawing from an exponential distribution centered at<br>        the vertex's actual gradient length. In effect, this can prevent vertices with very large<br>        gradients from dominating the minimization and often results in the best results.<br>       initial_coordinates (default: None) specifies the start coordinates of the registration;<br>        if None, uses those in the given mesh, which is generally desired.<br><br>    Examples:<br>      registered_mesh = mesh_register(<br>         mesh,<br>         [['edge', 'harmonic', 'scale', 0.5], # slightly weak edge potential<br>          ['angle', 'infinite-well'], # default arguments for an infinite-well angle potential<br>          ['anchor', 'Gaussian', [1, 10, 50], [[0.0, 0.0], [1.1, 1.1], [2.2, 2.2]]]],<br>         max_step_size=0.05,<br>         max_steps=10000)<br>    '''<br>    # Sanity checking:<br>    # First, make sure that the arguments are all okay:<br>    if not isinstance(mesh, geo.Mesh):<br>        raise RuntimeError('mesh argument must be an instance of neuropythy.geometry.Mesh')<br>    if not pimms.is_vector(max_steps): max_steps = [max_steps]<br>    for ms in max_steps:<br>        if not pimms.is_int(ms) or ms < 0:<br>            raise RuntimeError('max_steps argument must be a positive integer')<br>    if not pimms.is_vector(max_step_size): max_step_size = [max_step_size]<br>    for mss in max_step_size:<br>        if not pimms.is_number(mss) or mss <= 0:<br>            raise RuntimeError('max_step_size must be a positive number')<br>    if not pimms.is_number(max_pe_change) or max_pe_change <= 0 or max_pe_change  1:<br>        raise RuntimeError('max_pe_change must be a number x such that 0 < x <= 1')<br>    if pimms.is_vector(method):<br>        if method[0].lower() == 'nimble' and len(method)  1 and not pimms.is_str(method[1]):<br>            method = [method]<br>    else: method = [method]<br>    if initial_coordinates is None:<br>        init_coords = mesh.coordinates<br>    else:<br>        init_coords = np.asarray(initial_coordinates)<br>        if init_coords.shape[0] != mesh.coordinates.shape[0]:<br>            init_coords = init_coords.T<br>    # If steps is 0, we can skip most of this...<br>    if np.sum(max_steps) == 0:<br>        if return_report: return None<br>        else: return init_coords<br>    # Otherwise, we run at least some minimization<br>    max_pe_change = float(max_pe_change)<br>    nrounds = len(max_steps)<br>    if nrounds  1:<br>        if len(max_step_size) == 1: max_step_size = [max_step_size[0] for _ in max_steps]<br>        if len(method) == 1:        method        = [method[0]        for _ in max_steps]<br>    # Parse the field argument.<br>    faces  = to_java_ints(mesh.tess.indexed_faces)<br>    edges  = to_java_ints(mesh.tess.indexed_edges)<br>    coords = to_java_doubles(mesh.coordinates)<br>    init_coords = coords if init_coords is mesh.coordinates else to_java_doubles(init_coords)<br>    potential = _parse_field_arguments(field, faces, edges, coords)<br>    # Okay, that's basically all we need to do the minimization...<br>    rep = []<br>    for (method,max_step_size,max_steps) in zip(method, max_step_size, max_steps):<br>        minimizer = java_link().jvm.nben.mesh.registration.Minimizer(potential, init_coords)<br>        max_step_size = float(max_step_size)<br>        max_steps = int(max_steps)<br>        if pimms.is_str(method):<br>            method = method.lower()<br>            if method == 'nimble': k = 4<br>            else:                  k = 0<br>        else:<br>            k = method[1]<br>            method = method[0].lower()<br>        if method == 'pure':<br>            r = minimizer.step(max_pe_change, max_steps, max_step_size)<br>        elif method == 'random':<br>            # if k is -1, we do the inverse version where we draw from the 1/mean distribution<br>            r = minimizer.randomStep(max_pe_change, max_steps, max_step_size, k == -1)<br>        elif method == 'nimble':<br>            r = minimizer.nimbleStep(max_pe_change, max_steps, max_step_size, int(k))<br>        else:<br>            raise ValueError('Unrecognized method: %s' % method)<br>        rep.append(r)<br>        init_coords = minimizer.getX()<br>    # Return the report if requested<br>    if return_report:<br>        return rep<br>    else:<br>        result = init_coords<br>        return np.asarray([[x for x in row] for row in result])

### DOC[4] (IRRELEVANT) leetcode/csn_python_train_144450.txt
> def ner_net(source, destinations, width, height, wrap_around=False, radius=10):<br>    """Produce a shortest path tree for a given net using NER.<br><br>    This is the kernel of the NER algorithm.<br><br>    Parameters<br>    ----------<br>    source : (x, y)<br>        The coordinate of the source vertex.<br>    destinations : iterable([(x, y), ...])<br>        The coordinates of destination vertices.<br>    width : int<br>        Width of the system (nodes)<br>    height : int<br>        Height of the system (nodes)<br>    wrap_around : bool<br>        True if wrap-around links should be used, false if they should be<br>        avoided.<br>    radius : int<br>        Radius of area to search from each node. 20 is arbitrarily selected in<br>        the paper and shown to be acceptable in practice.<br><br>    Returns<br>    -------<br>    (:py:class:`~.rig.place_and_route.routing_tree.RoutingTree`,<br>     {(x,y): :py:class:`~.rig.place_and_route.routing_tree.RoutingTree`, ...})<br>        A RoutingTree is produced rooted at the source and visiting all<br>        destinations but which does not contain any vertices etc. For<br>        convenience, a dictionarry mapping from destination (x, y) coordinates<br>        to the associated RoutingTree is provided to allow the caller to insert<br>        these items.<br>    """<br>    # Map from (x, y) to RoutingTree objects<br>    route = {source: RoutingTree(source)}<br><br>    # Handle each destination, sorted by distance from the source, closest<br>    # first.<br>    for destination in sorted(destinations,<br>                              key=(lambda destination:<br>                                   shortest_mesh_path_length(<br>                                       to_xyz(source), to_xyz(destination))<br>                                   if not wrap_around else<br>                                   shortest_torus_path_length(<br>                                       to_xyz(source), to_xyz(destination),<br>                                       width, height))):<br>        # We shall attempt to find our nearest neighbouring placed node.<br>        neighbour = None<br><br>        # Try to find a nearby (within radius hops) node in the routing tree<br>        # that we can route to (falling back on just routing to the source).<br>        #<br>        # In an implementation according to the algorithm's original<br>        # specification looks for nodes at each point in a growing set of rings<br>        # of concentric hexagons. If it doesn't find any destinations this<br>        # means an awful lot of checks: 1261 for the default radius of 20.<br>        #<br>        # An alternative (but behaviourally identical) implementation scans the<br>        # list of all route nodes created so far and finds the closest node<br>        # which is < radius hops (falling back on the origin if no node is<br>        # closer than radius hops).  This implementation requires one check per<br>        # existing route node. In most routes this is probably a lot less than<br>        # 1261 since most routes will probably have at most a few hundred route<br>        # nodes by the time the last destination is being routed.<br>        #<br>        # Which implementation is best is a difficult question to answer:<br>        #  In principle nets with quite localised connections (e.g.<br>        #   nearest-neighbour or centroids traffic) may route slightly more<br>        #   quickly with the original algorithm since it may very quickly find<br>        #   a neighbour.<br>        #  In nets which connect very spaced-out destinations the second<br>        #   implementation may be quicker since in such a scenario it is<br>        #   unlikely that a neighbour will be found.<br>        #  In extremely high-fan-out nets (e.g. broadcasts), the original<br>        #   method is very likely to perform far better than the alternative<br>        #   method since most iterations will complete immediately while the<br>        #   alternative method must scan all the route vertices.<br>        # As such, it should be clear that neither method alone is 'best' and<br>        # both have degenerate performance in certain completely reasonable<br>        # styles of net. As a result, a simple heuristic is used to decide<br>        # which technique to use.<br>        #<br>        # The following micro-benchmarks are crude estimate of the<br>        # runtime-per-iteration of each approach (at least in the case of a<br>        # torus topology)::<br>        #<br>        #     $ # Original approach<br>        #     $ python -m timeit --setup 'x, y, w, h, r = 1, 2, 5, 10, \<br>        #                                     {x:None for x in range(10)}' \<br>        #                        'x += 1; y += 1; x %= w; y %= h; (x, y) in r'<br>        #     1000000 loops, best of 3: 0.207 usec per loop<br>        #     $ # Alternative approach<br>        #     $ python -m timeit --setup 'from rig.geometry import \<br>        #                                 shortest_torus_path_length' \<br>        #                        'shortest_torus_path_length( \<br>        #                             (0, 1, 2), (3, 2, 1), 10, 10)'<br>        #     1000000 loops, best of 3: 0.666 usec per loop<br>        #<br>        # From this we can approximately suggest that the alternative approach<br>        # is 3x more expensive per iteration. A very crude heuristic is to use<br>        # the original approach when the number of route nodes is more than<br>        # 1/3rd of the number of routes checked by the original method.<br>        concentric_hexagons = memoized_concentric_hexagons(radius)<br>        if len(concentric_hexagons) < len(route) / 3:<br>            # Original approach: Start looking for route nodes in a concentric<br>            # spiral pattern out from the destination node.<br>            for x, y in concentric_hexagons:<br>                x += destination[0]<br>                y += destination[1]<br>                if wrap_around:<br>                    x %= width<br>                    y %= height<br>                if (x, y) in route:<br>                    neighbour = (x, y)<br>                    break<br>        else:<br>            # Alternative approach: Scan over every route node and check to see<br>            # if any are < radius, picking the closest one if so.<br>            neighbour = None<br>            neighbour_distance = None<br>            for candidate_neighbour in route:<br>                if wrap_around:<br>                    distance = shortest_torus_path_length(<br>                        to_xyz(candidate_neighbour), to_xyz(destination),<br>                        width, height)<br>                else:<br>                    distance = shortest_mesh_path_length(<br>                        to_xyz(candidate_neighbour), to_xyz(destination))<br><br>                if distance <= radius and (neighbour is None or<br>                                           distance < neighbour_distance):<br>                    neighbour = candidate_neighbour<br>                    neighbour_distance = distance<br><br>        # Fall back on routing directly to the source if no nodes within radius<br>        # hops of the destination was found.<br>        if neighbour is None:<br>            neighbour = source<br><br>        # Find the shortest vector from the neighbour to this destination<br>        if wrap_around:<br>            vector = shortest_torus_path(to_xyz(neighbour),<br>                                         to_xyz(destination),<br>                                         width, height)<br>        else:<br>            vector = shortest_mesh_path(to_xyz(neighbour), to_xyz(destination))<br><br>        # The longest-dimension-first route may inadvertently pass through an<br>        # already connected node. If the route is allowed to pass through that<br>        # node it would create a cycle in the route which would be VeryBad(TM).<br>        # As a result, we work backward through the route and truncate it at<br>        # the first point where the route intersects with a connected node.<br>        ldf = longest_dimension_first(vector, neighbour, width, height)<br>        i = len(ldf)<br>        for direction, (x, y) in reversed(ldf):<br>            i -= 1<br>            if (x, y) in route:<br>                # We've just bumped into a node which is already part of the<br>                # route, this becomes our new neighbour and we truncate the LDF<br>                # route. (Note ldf list is truncated just after the current<br>                # position since it gives (direction, destination) pairs).<br>                neighbour = (x, y)<br>                ldf = ldf[i + 1:]<br>                break<br><br>        # Take the longest dimension first route.<br>        last_node = route[neighbour]<br>        for direction, (x, y) in ldf:<br>            this_node = RoutingTree((x, y))<br>            route[(x, y)] = this_node<br><br>            last_node.children.append((Routes(direction), this_node))<br>            last_node = this_node<br><br>    return (route[source], route)

### DOC[5] (IRRELEVANT) leetcode/csn_python_train_144452.txt
> def a_star(sink, heuristic_source, sources, machine, wrap_around):<br>    """Use A to find a path from any of the sources to the sink.<br><br>    Note that the heuristic means that the search will proceed towards<br>    heuristic_source without any concern for any other sources. This means that<br>    the algorithm may miss a very close neighbour in order to pursue its goal<br>    of reaching heuristic_source. This is not considered a problem since 1) the<br>    heuristic source will typically be in the direction of the rest of the tree<br>    and near by and often the closest entity 2) it prevents us accidentally<br>    forming loops in the rest of the tree since we'll stop as soon as we touch<br>    any part of it.<br><br>    Parameters<br>    ----------<br>    sink : (x, y)<br>    heuristic_source : (x, y)<br>        An element from `sources` which is used as a guiding heuristic for the<br>        A algorithm.<br>    sources : set([(x, y), ...])<br>    machine : :py:class:`~rig.place_and_route.Machine`<br>    wrap_around : bool<br>        Consider wrap-around links in heuristic distance calculations.<br><br>    Returns<br>    -------<br>    [(:py:class:`~rig.routing_table.Routes`, (x, y)), ...]<br>        A path starting with a coordinate in `sources` and terminating at<br>        connected neighbour of `sink` (i.e. the path does not include `sink`).<br>        The direction given is the link down which to proceed from the given<br>        (x, y) to arrive at the next point in the path.<br><br>    Raises<br>    ------<br>    :py:class:~rig.place_and_route.exceptions.MachineHasDisconnectedSubregion`<br>        If a path cannot be found.<br>    """<br>    # Select the heuristic function to use for distances<br>    if wrap_around:<br>        heuristic = (lambda node:<br>                     shortest_torus_path_length(to_xyz(node),<br>                                                to_xyz(heuristic_source),<br>                                                machine.width, machine.height))<br>    else:<br>        heuristic = (lambda node:<br>                     shortest_mesh_path_length(to_xyz(node),<br>                                               to_xyz(heuristic_source)))<br><br>    # A dictionary {node: (direction, previous_node}. An entry indicates that<br>    # 1) the node has been visited and 2) which node we hopped from (and the<br>    # direction used) to reach previous_node.  This may be None if the node is<br>    # the sink.<br>    visited = {sink: None}<br><br>    # The node which the tree will be reconnected to<br>    selected_source = None<br><br>    # A heap (accessed via heapq) of (distance, (x, y)) where distance is the<br>    # distance between (x, y) and heuristic_source and (x, y) is a node to<br>    # explore.<br>    to_visit = [(heuristic(sink), sink)]<br>    while to_visit:<br>        _, node = heapq.heappop(to_visit)<br><br>        # Terminate if we've found the destination<br>        if node in sources:<br>            selected_source = node<br>            break<br><br>        # Try all neighbouring locations. Note: link identifiers are from the<br>        # perspective of the neighbour, not the current node!<br>        for neighbour_link in Links:<br>            vector = neighbour_link.opposite.to_vector()<br>            neighbour = ((node[0] + vector[0]) % machine.width,<br>                         (node[1] + vector[1]) % machine.height)<br><br>            # Skip links which are broken<br>            if (neighbour[0], neighbour[1], neighbour_link) not in machine:<br>                continue<br><br>            # Skip neighbours who have already been visited<br>            if neighbour in visited:<br>                continue<br><br>            # Explore all other neighbours<br>            visited[neighbour] = (neighbour_link, node)<br>            heapq.heappush(to_visit, (heuristic(neighbour), neighbour))<br><br>    # Fail of no paths exist<br>    if selected_source is None:<br>        raise MachineHasDisconnectedSubregion(<br>            "Could not find path from {} to {}".format(<br>                sink, heuristic_source))<br><br>    # Reconstruct the discovered path, starting from the source we found and<br>    # working back until the sink.<br>    path = [(Routes(visited[selected_source][0]), selected_source)]<br>    while visited[path[-1][1]][1] != sink:<br>        node = visited[path[-1][1]][1]<br>        direction = Routes(visited[node][0])<br>        path.append((direction, node))<br><br>    return path


## Ground Truth

### GROUND TRUTH 0, ranked 15, leetcode/leetcode_310.txt
> from collections import deque<br>    """A tree is an undirected graph in which any two vertices are connected by _exactly_ one path. In other words, any connected graph without simple cycles is a tree.<br><br>Given a tree of `n` nodes labelled from `0` to `n - 1`, and an array of `n - 1` `edges` where `edges[i] = [ai, bi]` indicates that there is an undirected edge between the two nodes `ai` and `bi` in the tree, you can choose any node of the tree as the root. When you select a node `x` as the root, the result tree has height `h`. Among all possible rooted trees, those with minimum height (i.e. `min(h)`) are called minimum height trees (MHTs).<br><br>Return _a list of all MHTs' root labels_. You can return the answer in any order.<br><br>The height of a rooted tree is the number of edges on the longest downward path between the root and a leaf.<br><br>Example 1:<br><br>Input: n = 4, edges = \[\[1,0\],\[1,2\],\[1,3\]\]<br>Output: \[1\]<br>Explanation: As shown, the height of the tree is 1 when the root is the node with label 1 which is the only MHT.<br><br>Example 2:<br><br>Input: n = 6, edges = \[\[3,0\],\[3,1\],\[3,2\],\[3,4\],\[5,4\]\]<br>Output: \[3,4\]<br><br>Constraints:<br><br>   `1 <= n <= 2  104`<br>   `edges.length == n - 1`<br>   `0 <= ai, bi < n`<br>   `ai != bi`<br>   All the pairs `(ai, bi)` are distinct.<br>   The given input is guaranteed to be a tree and there will be no repeated edges."""<br><br>from typing import List<br><br>def find_min_height_trees(n: int, edges: List[List[int]]) - List[int]:<br>    if n == 1:<br>        return [0]<br><br>    adj_list = [set() for _ in range(n)]<br>    for a, b in edges:<br>        adj_list[a].add(b)<br>        adj_list[b].add(a)<br><br>    leaves = deque(i for i in range(n) if len(adj_list[i]) == 1)<br><br>    while n  2:<br>        leaves_size = len(leaves)<br>        n -= leaves_size<br>        for _ in range(leaves_size):<br>            leaf = leaves.popleft()<br>            for neighbor in adj_list[leaf]:<br>                adj_list[neighbor].remove(leaf)<br>                if len(adj_list[neighbor]) == 1:<br>                    leaves.append(neighbor)<br><br>    return list(leaves)

### GROUND TRUTH 1, ranked not in top 100, leetcode/leetcode_834.txt
> def ambiguousCoordinates(s):<br>    """There is an undirected connected tree with `n` nodes labeled from `0` to `n - 1` and `n - 1` edges.<br><br>You are given the integer `n` and the array `edges` where `edges[i] = [ai, bi]` indicates that there is an edge between nodes `ai` and `bi` in the tree.<br><br>Return an array `answer` of length `n` where `answer[i]` is the sum of the distances between the `ith` node in the tree and all other nodes.<br><br>Example 1:<br><br>Input: n = 6, edges = \[\[0,1\],\[0,2\],\[2,3\],\[2,4\],\[2,5\]\]<br>Output: \[8,12,6,10,10,10\]<br>Explanation: The tree is shown above.<br>We can see that dist(0,1) + dist(0,2) + dist(0,3) + dist(0,4) + dist(0,5)<br>equals 1 + 1 + 2 + 2 + 2 = 8.<br>Hence, answer\[0\] = 8, and so on.<br><br>Example 2:<br><br>Input: n = 1, edges = \[\]<br>Output: \[0\]<br><br>Example 3:<br><br>Input: n = 2, edges = \[\[1,0\]\]<br>Output: \[1,1\]<br><br>Constraints:<br><br>   `1 <= n <= 3  104`<br>   `edges.length == n - 1`<br>   `edges[i].length == 2`<br>   `0 <= ai, bi < n`<br>   `ai != bi`<br>   The given input represents a valid tree."""<br><br>    def generateNumber(s):<br>        if not s or (len(s)  1 and s[0] == '0' and s[-1] == '0'):<br>            return []<br>        if len(s)  1 and s[0] == '0':<br>            return ["0." + s[1:]]<br>        res = [s]<br>        if len(s) == 1 or s[-1] == '0':<br>            return res<br>        for i in range(1, len(s)):<br>            res.append(s[:i] + "." + s[i:])<br>        return res<br><br>    n = len(s)<br>    res = []<br>    <br>    for i in range(2, n - 1):<br>        first = generateNumber(s[1:i])<br>        second = generateNumber(s[i:n - 1])<br>        <br>        for f in first:<br>            for sec in second:<br>                res.append("(" + f + ", " + sec + ")")<br>    <br>    return res
