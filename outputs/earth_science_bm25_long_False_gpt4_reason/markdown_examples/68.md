# Query `68`

## Original Question

*How is/was continental drift monitored?
I am curious about current technology but I am particularly interested in what techniques were employed prior to the advent of satellite technology.*

## gpt4 Reasoning

```markdown
The essential problem here is understanding how continental drift has been monitored over time, focusing on the evolution from pre-satellite technologies to current methods. To address this, we'll explore the techniques and tools used historically and then contrast these with modern technologies.

### Historical Techniques for Monitoring Continental Drift

Before the advent of satellite technology, scientists relied on several methods to understand and monitor the movement of continents. These included:

1. **Geological Evidence**: Early evidence of continental drift was largely geological. Scientists compared rock formations, fossil records, and the fit of continental coastlines across oceans. For example, the similarity between fossil plants and animals found on continents now widely separated by oceans (such as South America and Africa) supported the idea that these continents were once joined.

2. **Paleomagnetism**: This involves the study of the record of the Earth's magnetic field in rocks, sediment, or archeological materials. Scientists discovered that the magnetic minerals in rocks align with the Earth's magnetic field at the time the rocks were formed. By examining the orientation of these minerals in rocks of different ages and locations, scientists could infer the movement of continents over geological time scales. This method provided more direct evidence of continental drift.

3. **Surveying Techniques**: Before satellites, land-based surveying techniques, including triangulation and later trilateration, were used to measure the positions and distances between points on the Earth's surface with high precision. Repeated measurements over years or decades could detect the gradual movement of land masses. These methods required extensive time and labor and were limited by the need for physical access to the locations being measured.

### Transition to Modern Technologies

With the advent of satellite technology, the ability to monitor continental drift has improved dramatically due to enhanced precision, global coverage, and the ability to collect data continuously.

1. **Global Positioning System (GPS)**: GPS technology has revolutionized the monitoring of continental drift. By using networks of satellites to provide precise positioning data, scientists can measure the movement of the Earth's tectonic plates in real-time with millimeter to centimeter accuracy. This allows for a much more detailed and dynamic understanding of plate tectonics.

2. **Interferometric Synthetic Aperture Radar (InSAR)**: InSAR is another satellite-based technique that uses radar signals to create maps of deformation over time, including the movement of tectonic plates, volcanic activity, and land subsidence. This method can detect minute changes in the Earth's surface, providing valuable data on the processes driving continental drift.

3. **Satellite Laser Ranging (SLR)** and **Very Long Baseline Interferometry (VLBI)**: These highly precise techniques are used to measure the Earth's rotation and crustal deformation at specific points, contributing to our understanding of tectonic movements.

### Conclusion

Monitoring continental drift has evolved from relying on indirect geological and paleomagnetic evidence to utilizing direct, high-precision measurements from satellite technologies. Historical methods laid the foundational understanding of continental drift, which has been significantly expanded and refined with GPS, InSAR, SLR, and VLBI. This technological evolution has transformed our ability to monitor the Earth's surface, providing insights into not only continental drift but also earthquake prediction, volcanic activity monitoring, and the impacts of climate change on the Earth's crust.
```

### Metrics

```
recip_rank: 1.0000
P_1: 1.0000
P_5: 0.4000
P_10: 0.3000
P_25: 0.1600
P_50: 0.1000
P_100: 0.0500
recall_1: 0.2000
recall_5: 0.4000
recall_10: 0.6000
recall_25: 0.8000
recall_50: 1.0000
recall_100: 1.0000
ndcg_cut_1: 1.0000
ndcg_cut_5: 0.4852
ndcg_cut_10: 0.6060
ndcg_cut_25: 0.6977
ndcg_cut_50: 0.7675
ndcg_cut_100: 0.7675
map_cut_1: 0.2000
map_cut_5: 0.3000
map_cut_10: 0.4000
map_cut_25: 0.4667
map_cut_50: 0.5024
map_cut_100: 0.5024
```

## Retrieval Results

### DOC[1] (GROUND TRUTH) continental_drift/Satellite_laser_ranging4.txt
> ReadEditView history<br><br><br><br><br><br>		General<br>	<br><br><br>What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR codeWikidata item<br><br><br><br><br><br>		Print/export<br>	<br><br><br>Download as PDFPrintable version<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>From Wikipedia, the free encyclopedia<br><br><br>This article is about the up-looking type of satellite laser. For the down-looking type, see Satellite laser altimetry.<br>This article includes a list of general references, but it lacks sufficient corresponding inline citations. Please help to improve this article by introducing more precise citations. (November 2020) (Learn how and when to remove this template message)<br>Laser Ranging System of the geodetic observatory Wettzell, Bavaria<br>In  satellite laser ranging  (SLR) a global network of observation stations measures the round trip time of flight of ultrashort pulses of light to satellites equipped with retroreflectors. This provides instantaneous range measurements of millimeter level precision which can be accumulated to provide accurate measurement of orbits and a host of important scientific data. The laser pulse can also be reflected by the surface of a satellite without a retroreflector, which is used for tracking space debris.[1]<br>Satellite laser ranging is a proven geodetic technique with significant potential for important contributions to scientific studies of the earth/atmosphere/ocean system. It is the most accurate technique currently available to determine the geocentric position of an Earth satellite, allowing for the precise calibration of radar altimeters and separation of long-term instrumentation drift from secular changes in ocean topography.<br>Its ability to measure the variations over time in Earth's gravity field and to monitor motion of the station network with respect to the geocenter, together with the capability to monitor vertical motion in an absolute system, makes it unique for modeling and evaluating long-term climate change by:[2]<br><br>providing a reference system for post-glacial rebound, plate tectonics, sea level and ice volume change[3]<br>determining the temporal mass redistribution of the solid earth, ocean, and atmosphere system[4]<br>determining Earth orientation parameters, such as Earth pole coordinates and length-of-day variations[5]<br>determining of precise satellite orbits for artificial satellites with and without active devices onboard[6][7]<br>monitoring the response of the atmosphere to seasonal variations in solar heating.[8]<br>SLR provides a unique capability for verification of the predictions of the theory of general relativity, such as the frame-dragging effect.<br>SLR stations form an important part of the international network of space geodetic observatories, which include VLBI, GPS, DORIS and PRARE systems. On several critical missions, SLR has provided failsafe redundancy when other radiometric tracking systems have failed.<br><br><br>History[edit]<br>Satellite Laser Ranging<br>Laser ranging to a near-Earth satellite was first carried out by NASA in 1964 with the launch of the Beacon-B satellite. Since that time, ranging precision, spurred by scientific requirements, has improved by a factor of a thousand from a few metres to a few millimetres, and more satellites equipped with retroreflectors have been launched.<br>Several sets of retroreflectors were installed on Earth's Moon as part of the American Apollo and Soviet Lunokhod space programs. These retroreflectors are also ranged on a regular basis (lunar laser ranging), providing a highly accurate measurement of the dynamics of the Earth/Moon system.<br>During the subsequent decades, the global satellite laser ranging network has evolved into a powerful source of data for studies of the solid Earth and its ocean and atmospheric systems. In addition, SLR provides precise orbit determination for spaceborne radar altimeter missions mapping the ocean surface (which are used to model global ocean circulation), for<br>mapping volumetric changes in continental ice masses, and for land topography. It provides a means for subnanosecond global time transfer, and a basis for special tests of the Theory of General Relativity.<br>The International Laser Ranging Service was formed in 1998[9] by the global SLR community to enhance  geophysical and geodetic research activities, replacing the previous CSTG Satellite and Laser Ranging Subcommission.<br><br>Applications[edit]<br>SLR data has provided the standard, highly accurate, long wavelength gravity field reference model which supports all precision orbit determination and provides the basis for studying temporal gravitational variations due to mass redistribution. The height of the geoid has been determined to less than ten centimeters at long wavelengths less than 1,500 km.<br>SLR provides mm/year accurate determinations of tectonic drift station motion on a global scale in a geocentric reference frame. Combined with gravity models and decadal changes in Earth rotation, these results contribute to modeling of convection in the Earth's mantle by providing constraints on related Earth interior processes. The velocity of the fiducial station in Hawaii is 70 mm/year and closely matches the rate of the background geophysical model.<br><br>List of satellites[edit]<br>List of passive satellites[edit]<br>For broader coverage of this topic, see List of passive satellites.<br>Several dedicated laser ranging satellites were put in orbit:[10]<br><br>Ajisai (Experimental Geodetic Payload)[11]<br>BLITS[4]<br>Calsphere satellites[12]<br>Etalon[13]<br>Kosmos 1989<br>Kosmos 2024<br>LAGEOS[14]<br>LAGEOS 1<br>LAGEOS 2, see STS-52<br>LARES[15]<br>LARES 1<br>LARES 2<br>Larets[16][17]<br>STARSHINE<br>Starshine 1,[18] see STS-96<br>Starshine 2, see STS-108<br>Starlette and Stella[19]<br>List of shared satellites[edit]<br>Several satellites carried laser retroreflectors, sharing the bus with other instruments:<br><br>Beacon Explorers (Beacon Explorer-B and Beacon Explorer-C)[20]<br>GEOS (GEOS-1, GEOS-2, GEOS-3)[20]<br>Diadème (satellites) [fr][20]<br>PEOLE [fr][20]<br>CHAMP<br>GRACE<br>GOCE[21]<br>Navigation satellites<br>GLONASS[22]<br>GPS (two experimental satellites[23])<br>Galileo[24]<br>BeiDou[25]<br>NavIC[26]<br>QZSS[27]<br>Altimeter satellites<br>GEOS-3<br>TOPEX/Poseidon<br>Sentinel-3[28]<br>SARAL[29]<br>See also[edit]

### DOC[2] (IRRELEVANT) ocean_continent_divergent_boundary/Plate_tectonics5.txt
> part5 -------------------<br>History of the theory<br>Summary<br>Detailed map showing the tectonic plates with their movement vectors.<br>The development of the theory of plate tectonics was the scientific and cultural change which occurred during a period of 50 years of scientific debate. The event of the acceptance itself was a paradigm shift and can therefore be classified as a scientific revolution.<br>Around the start of the twentieth century, various theorists unsuccessfully attempted to explain the many geographical, geological, and biological continuities between continents. In 1912, the meteorologist Alfred Wegener described what he called continental drift, an idea that culminated fifty years later in the modern theory of plate tectonics.<br>Wegener expanded his theory in his 1915 book The Origin of Continents and Oceans. Starting from the idea (also expressed by his forerunners) that the present continents once formed a single land mass (later called Pangaea), Wegener suggested that these separated and drifted apart, likening them to "icebergs" of low density sial floating on a sea of denser sima. Supporting evidence for the idea came from the dove-tailing outlines of South America's east coast and Africa's west coast Antonio Snider-Pellegrini had drawn on his maps, and from the matching of the rock formations along these edges. Confirmation of their previous contiguous nature also came from the fossil plants Glossopteris and Gangamopteris, and the therapsid or mammal-like reptile Lystrosaurus, all widely distributed over South America, Africa, Antarctica, India, and Australia. The evidence for such an erstwhile joining of these continents was patent to field geologists working in the southern hemisphere. The South African Alex du Toit put together a mass of such information in his 1937 publication Our Wandering Continents, and went further than Wegener in recognising the strong links between the Gondwana fragments.<br>Wegener's work was initially not widely accepted, in part due to a lack of detailed evidence but mostly because of the lack of a reasonable physically supported mechanism. Earth might have a solid crust and mantle and a liquid core, but there seemed to be no way that portions of the crust could move around. Many distinguished scientists of the time, such as Harold Jeffreys and Charles Schuchert, were outspoken critics of continental drift.<br>Despite much opposition, the view of continental drift gained support and a lively debate started between "drifters" or "mobilists" (proponents of the theory) and "fixists" (opponents). During the 1920s, 1930s and 1940s, the former reached important milestones proposing that convection currents might have driven the plate movements, and that spreading may have occurred below the sea within the oceanic crust. Concepts close to the elements now incorporated in plate tectonics were proposed by geophysicists and geologists (both fixists and mobilists) like Vening-Meinesz, Holmes, and Umbgrove. In 1941, Otto Ampferer described, in his publication "Thoughts on the motion picture of the Atlantic region", processes that anticipate what is now called seafloor spreading and subduction. One of the first pieces of geophysical evidence that was used to support the movement of lithospheric plates came from paleomagnetism. This is based on the fact that rocks of different ages show a variable magnetic field direction, evidenced by studies since the mid–nineteenth century. The magnetic north and south poles reverse through time, and, especially important in paleotectonic studies, the relative position of the magnetic north pole varies through time. Initially, during the first half of the twentieth century, the latter phenomenon was explained by introducing what was called "polar wander" (see apparent polar wander) (i.e., it was assumed that the north pole location had been shifting through time). An alternative explanation, though, was that the continents had moved (shifted and rotated) relative to the north pole, and each continent, in fact, shows its own "polar wander path". During the late 1950s, it was successfully shown on two occasions that these data could show the validity of continental drift: by Keith Runcorn in a paper in 1956, and by Warren Carey in a symposium held in March 1956.<br>The second piece of evidence in support of continental drift came during the late 1950s and early 60s from data on the bathymetry of the deep ocean floors and the nature of the oceanic crust such as magnetic properties and, more generally, with the development of marine geology which gave evidence for the association of seafloor spreading along the mid-oceanic ridges and magnetic field reversals, published between 1959 and 1963 by Heezen, Dietz, Hess, Mason, Vine & Matthews, and Morley.<br>Simultaneous advances in early seismic imaging techniques in and around Wadati–Benioff zones along the trenches bounding many continental margins, together with many other geophysical (e.g. gravimetric) and geological observations, showed how the oceanic crust could disappear into the mantle, providing the mechanism to balance the extension of the ocean basins with shortening along its margins.<br>All this evidence, both from the ocean floor and from the continental margins, made it clear around 1965 that continental drift was feasible. The theory of plate tectonics was defined in a series of papers between 1965 and 1967. The theory revolutionized the Earth sciences, explaining a diverse range of geological phenomena and their implications in other studies such as paleogeography and paleobiology.<br>Continental drift<br><br>Further information: Continental drift<br>In the late 19th and early 20th centuries, geologists assumed that Earth's major features were fixed, and that most geologic features such as basin development and mountain ranges could be explained by vertical crustal movement, described in what is called the geosynclinal theory. Generally, this was placed in the context of a contracting planet Earth due to heat loss in the course of a relatively short geological time.<br>Alfred Wegener in Greenland in the winter of 1912–13.<br>It was observed as early as 1596 that the opposite coasts of the Atlantic Ocean—or, more precisely, the edges of the continental shelves—have similar shapes and seem to have once fitted together.<br>Since that time many theories were proposed to explain this apparent complementarity, but the assumption of a solid Earth made these various proposals difficult to accept.<br>The discovery of radioactivity and its associated heating properties in 1895 prompted a re-examination of the apparent age of Earth. This had previously been estimated by its cooling rate under the assumption that Earth's surface radiated like a black body. Those calculations had implied that, even if it started at red heat, Earth would have dropped to its present temperature in a few tens of millions of years. Armed with the knowledge of a new heat source, scientists realized that Earth would be much older, and that its core was still sufficiently hot to be liquid.<br>By 1915, after having published a first article in 1912, Alfred Wegener was making serious arguments for the idea of continental drift in the first edition of The Origin of Continents and Oceans. In that book (re-issued in four successive editions up to the final one in 1936), he noted how the east coast of South America and the west coast of Africa looked as if they were once attached. Wegener was not the first to note this (Abraham Ortelius, Antonio Snider-Pellegrini, Eduard Suess, Roberto Mantovani and Frank Bursley Taylor preceded him just to mention a few), but he was the first to marshal significant fossil and paleo-topographical and climatological evidence to support this simple observation (and was supported in this by researchers such as Alex du Toit). Furthermore, when the rock strata of the margins of separate continents are very similar it suggests that these rocks were formed in the same way, implying that they were joined initially. For instance, parts of Scotland and Ireland contain rocks very similar to those found in Newfoundland and New Brunswick. Furthermore, the Caledonian Mountains of Europe and parts of the Appalachian Mountains of North America are very similar in structure and lithology.<br>However, his ideas were not taken seriously by many geologists, who pointed out that there was no apparent mechanism for continental drift. Specifically, they did not see how continental rock could plow through the much denser rock that makes up oceanic crust. Wegener could not explain the force that drove continental drift, and his vindication did not come until after his death in 1930.<br>Floating continents, paleomagnetism, and seismicity zones<br>Global earthquake epicenters, 1963–1998. Most earthquakes occur in narrow belts that correspond to the locations of lithospheric plate boundaries.<br>Map of earthquakes in 2016<br>As it was observed early that although granite existed on continents, seafloor seemed to be composed of denser basalt, the prevailing concept during the first half of the twentieth century was that there were two types of crust, named "sial" (continental type crust) and "sima" (oceanic type crust). Furthermore, it was supposed that a static shell of strata was present under the continents. It therefore looked apparent that a layer of basalt (sial) underlies the continental rocks.<br>However, based on abnormalities in plumb line deflection by the Andes in Peru, Pierre Bouguer had deduced that less-dense mountains must have a downward projection into the denser layer underneath. The concept that mountains had "roots" was confirmed by George B. Airy a hundred years later, during study of Himalayan gravitation, and seismic studies detected corresponding density variations. Therefore, by the mid-1950s, the question remained unresolved as to whether mountain roots were clenched in surrounding basalt or were floating on it like an iceberg.<br>During the 20th century, improvements in and greater use of seismic instruments such as seismographs enabled scientists to learn that earthquakes tend to be concentrated in specific areas, most notably along the oceanic trenches and spreading ridges. By the late 1920s, seismologists were beginning to identify several prominent earthquake zones parallel to the trenches that typically were inclined 40–60° from the horizontal and extended several hundred kilometers into Earth. These zones later became known as Wadati–Benioff zones, or simply Benioff zones, in honor of the seismologists who first recognized them, Kiyoo Wadati of Japan and Hugo Benioff of the United States. The study of global seismicity greatly advanced in the 1960s with the establishment of the Worldwide Standardized Seismograph Network (WWSSN) to monitor the compliance of the 1963 treaty banning above-ground testing of nuclear weapons. The much improved data from the WWSSN instruments allowed seismologists to map precisely the zones of earthquake concentration worldwide.<br>Meanwhile, debates developed around the phenomenon of polar wander. Since the early debates of continental drift, scientists had discussed and used evidence that polar drift had occurred because continents seemed to have moved through different climatic zones during the past. Furthermore, paleomagnetic data had shown that the magnetic pole had also shifted during time. Reasoning in an opposite way, the continents might have shifted and rotated, while the pole remained relatively fixed. The first time the evidence of magnetic polar wander was used to support the movements of continents was in a paper by Keith Runcorn in 1956, and successive papers by him and his students Ted Irving (who was actually the first to be convinced of the fact that paleomagnetism supported continental drift) and Ken Creer.<br>This was immediately followed by a symposium on continental drift in Tasmania in March 1956 organised by S. Warren Carey who had been one of the supporters and promotors of Continental Drift since the thirties  During this symposium, some of the participants used the evidence in the theory of an expansion of the global crust, a theory which had been proposed by other workers decades earlier. In this hypothesis, the shifting of the continents is explained by a large increase in the size of Earth since its formation. However, although the theory still has supporters in science, this is generally regarded as unsatisfactory because there is no convincing mechanism to produce a significant expansion of Earth. Other work during the following years would soon show that the evidence was equally in support of continental drift on a globe with a stable radius.<br>During the 1930s up to the late 1950s, works by Vening-Meinesz, Holmes, Umbgrove, and numerous others outlined concepts that were close or nearly identical to modern plate tectonics theory. In particular, the English geologist Arthur Holmes proposed in 1920 that plate junctions might lie beneath the sea, and in 1928 that convection currents within the mantle might be the driving force. Often, these contributions are forgotten because:<br>At the time, continental drift was not accepted.<br>Some of these ideas were discussed in the context of abandoned fixist ideas of a deforming globe without continental drift or an expanding Earth.<br>They were published during an episode of extreme political and economic instability that hampered scientific communication.<br>Many were published by European scientists and at first not mentioned or given little credit in the papers on sea floor spreading published by the American researchers in the 1960s.<br>Mid-oceanic ridge spreading and convection<br><br>Further information on Mid-ocean ridge: Seafloor spreading<br>In 1947, a team of scientists led by Maurice Ewing utilizing the Woods Hole Oceanographic Institution's research vessel Atlantis and an array of instruments, confirmed the existence of a rise in the central Atlantic Ocean, and found that the floor of the seabed beneath the layer of sediments consisted of basalt, not the granite which is the main constituent of continents. They also found that the oceanic crust was much thinner than continental crust. All these new findings raised important and intriguing questions.<br>The new data that had been collected on the ocean basins also showed particular characteristics regarding the bathymetry. One of the major outcomes of these datasets was that all along the globe, a system of mid-oceanic ridges was detected. An important conclusion was that along this system, new ocean floor was being created, which led to the concept of the "Great Global Rift". This was described in the crucial paper of Bruce Heezen (1960) based on his work with Marie Tharp, which would trigger a real revolution in thinking. A profound consequence of seafloor spreading is that new crust was, and still is, being continually created along the oceanic ridges. For this reason, Heezen initially advocated the so-called "expanding Earth" hypothesis of S. Warren Carey (see above). Therefore, the question remained as to how new crust could continuously be added along the oceanic ridges without increasing the size of Earth. In reality, this question had been solved already by numerous scientists during the 1940s and the 1950s, like Arthur Holmes, Vening-Meinesz, Coates and many others: The crust in excess disappeared along what were called the oceanic trenches, where so-called "subduction" occurred. Therefore, when various scientists during the early 1960s started to reason on the data at their disposal regarding the ocean floor, the pieces of the theory quickly fell into place.<br>The question particularly intrigued Harry Hammond Hess, a Princeton University geologist and a Naval Reserve Rear Admiral, and Robert S. Dietz, a scientist with the United States Coast and Geodetic Survey who first coined the term seafloor spreading. Dietz and Hess (the former published the same idea one year earlier in Nature, but priority belongs to Hess who had already distributed an unpublished manuscript of his 1962 article by 1960) were among the small number who really understood the broad implications of sea floor spreading and how it would eventually agree with the, at that time, unconventional and unaccepted ideas of continental drift and the elegant and mobilistic models proposed by previous workers like Holmes.<br>In the same year, Robert R. Coats of the U.S. Geological Survey described the main features of island arc subduction in the Aleutian Islands. His paper, though little noted (and sometimes even ridiculed) at the time, has since been called "seminal" and "prescient". In reality, it actually shows that the work by the European scientists on island arcs and mountain belts performed and published during the 1930s up until the 1950s was applied and appreciated also in the United States.<br>If Earth's crust was expanding along the oceanic ridges, Hess and Dietz reasoned like Holmes and others before them, it must be shrinking elsewhere. Hess followed Heezen, suggesting that new oceanic crust continuously spreads away from the ridges in a conveyor belt–like motion. And, using the mobilistic concepts developed before, he correctly concluded that many millions of years later, the oceanic crust eventually descends along the continental margins where oceanic trenches—very deep, narrow canyons—are formed, e.g. along the rim of the Pacific Ocean basin. The important step Hess made was that convection currents would be the driving force in this process, arriving at the same conclusions as Holmes had decades before with the only difference that the thinning of the ocean crust was performed using Heezen's mechanism of spreading along the ridges. Hess therefore concluded that the Atlantic Ocean was expanding while the Pacific Ocean was shrinking. As old oceanic crust is "consumed" in the trenches (like Holmes and others, he thought this was done by thickening of the continental lithosphere, not, as now understood, by underthrusting at a larger scale of the oceanic crust itself into the mantle), new magma rises and erupts along the spreading ridges to form new crust. In effect, the ocean basins are perpetually being "recycled", with the forming of new crust and the destruction of old oceanic lithosphere occurring simultaneously. Thus, the new mobilistic concepts neatly explained why Earth does not get bigger with sea floor spreading, why there is so little sediment accumulation on the ocean floor, and why oceanic rocks are much younger than continental rocks.<br>Magnetic striping<br>Seafloor magnetic striping.<br>A demonstration of magnetic striping. (The darker the color is, the closer it is to normal polarity)<br><br>Further information: Vine–Matthews–Morley hypothesis<br>Beginning in the 1950s, scientists like Victor Vacquier, using magnetic instruments (magnetometers) adapted from airborne devices developed during World War II to detect submarines, began recognizing odd magnetic variations across the ocean floor. This finding, though unexpected, was not entirely surprising because it was known that basalt—the iron-rich, volcanic rock making up the ocean floor—contains a strongly magnetic mineral (magnetite) and can locally distort compass readings. This distortion was recognized by Icelandic mariners as early as the late 18th century. More importantly, because the presence of magnetite gives the basalt measurable magnetic properties, these newly discovered magnetic variations provided another means to study the deep ocean floor. When newly formed rock cools, such magnetic materials recorded Earth's magnetic field at the time.<br>As more and more of the seafloor was mapped during the 1950s, the magnetic variations turned out not to be random or isolated occurrences, but instead revealed recognizable patterns. When these magnetic patterns were mapped over a wide region, the ocean floor showed a zebra-like pattern: one stripe with normal polarity and the adjoining stripe with reversed polarity. The overall pattern, defined by these alternating bands of normally and reversely polarized rock, became known as magnetic striping, and was published by Ron G. Mason and co-workers in 1961, who did not find, though, an explanation for these data in terms of sea floor spreading, like Vine, Matthews and Morley a few years later.<br>The discovery of magnetic striping called for an explanation. In the early 1960s scientists such as Heezen, Hess and Dietz had begun to theorise that mid-ocean ridges mark structurally weak zones where the ocean floor was being ripped in two lengthwise along the ridge crest (see the previous paragraph). New magma from deep within Earth rises easily through these weak zones and eventually erupts along the crest of the ridges to create new oceanic crust. This process, at first denominated the "conveyer belt hypothesis" and later called seafloor spreading, operating over many millions of years continues to form new ocean floor all across the 50,000 km-long system of mid-ocean ridges.<br>Only four years after the maps with the "zebra pattern" of magnetic stripes were published, the link between sea floor spreading and these patterns was correctly placed, independently by Lawrence Morley, and by Fred Vine and Drummond Matthews, in 1963, now called the Vine–Matthews–Morley hypothesis. This hypothesis linked these patterns to geomagnetic reversals and was supported by several lines of evidence:<br>the stripes are symmetrical around the crests of the mid-ocean ridges; at or near the crest of the ridge, the rocks are very young, and they become progressively older away from the ridge crest;<br>the youngest rocks at the ridge crest always have present-day (normal) polarity;<br>stripes of rock parallel to the ridge crest alternate in magnetic polarity (normal-reversed-normal, etc.), suggesting that they were formed during different epochs documenting the (already known from independent studies) normal and reversal episodes of Earth's magnetic field.<br>By explaining both the zebra-like magnetic striping and the construction of the mid-ocean ridge system, the seafloor spreading hypothesis (SFS) quickly gained converts and represented another major advance in the development of the plate-tectonics theory. Furthermore, the oceanic crust now came to be appreciated as a natural "tape recording" of the history of the geomagnetic field reversals (GMFR) of Earth's magnetic field. Today, extensive studies are dedicated to the calibration of the normal-reversal patterns in the oceanic crust on one hand and known timescales derived from the dating of basalt layers in sedimentary sequences (magnetostratigraphy) on the other, to arrive at estimates of past spreading rates and plate reconstructions.<br>Definition and refining of the theory<br>After all these considerations, plate tectonics (or, as it was initially called "New Global Tectonics") became quickly accepted in the scientific world, and numerous papers followed that defined the concepts:<br>In 1965, Tuzo Wilson who had been a promoter of the sea floor spreading hypothesis and continental drift from the very beginning added the concept of transform faults to the model, completing the classes of fault types necessary to make the mobility of the plates on the globe work out.<br>A symposium on continental drift was held at the Royal Society of London in 1965 which must be regarded as the official start of the acceptance of plate tectonics by the scientific community, and which abstracts are issued as Blackett, Bullard & Runcorn (1965). In this symposium, Edward Bullard and co-workers showed with a computer calculation how the continents along both sides of the Atlantic would best fit to close the ocean, which became known as the famous "Bullard's Fit".<br>In 1966 Wilson published the paper that referred to previous plate tectonic reconstructions, introducing the concept of what is now known as the "Wilson Cycle".<br>In 1967, at the American Geophysical Union's meeting, W. Jason Morgan proposed that Earth's surface consists of 12 rigid plates that move relative to each other.<br>Two months later, Xavier Le Pichon published a complete model based on six major plates with their relative motions, which marked the final acceptance by the scientific community of plate tectonics.<br>In the same year, McKenzie and Parker independently presented a model similar to Morgan's using translations and rotations on a sphere to define the plate motions.<br>From that moment onwards, discussions have been focussing on the relative role of the forces driving plate tectonics, in order to evolve from a kinematic concept into a dynamic theory. Initially these concepts were focussed on mantle convection, in the footsteps of A. Holmes, and also introduced the importance of the gravitational pull of subducted slabs through the works of Elsasser, Solomon, Sleep, Uyeda and Turcotte. Other authors evoked external driving forces due to the tidal drag of the Moon and other celestial bodies, and, especially since 2000, with the emergence of computational models reproducing Earth's mantle behaviour to first order, following upon the older unifying concepts of van Bemmelen, authors re-evaluated the important role of mantle dynamics.

### DOC[3] (IRRELEVANT) ocean_continent_divergent_boundary/Plate_tectonics1.txt
> part1 -------------------<br><br>Plate tectonics (from Latin  tectonicus, from Ancient Greek  τεκτονικός (tektonikós) 'pertaining to building') is the scientific theory that Earth's lithosphere comprises a number of large tectonic plates, which have been slowly moving since about 3.4 billion years ago. The model builds on the concept of continental drift, an idea developed during the first decades of the 20th century. Plate tectonics came to be accepted by geoscientists after seafloor spreading was validated in the mid-to-late 1960s.<br>Earth's lithosphere, the rigid outer shell of the planet including the crust and upper mantle, is fractured into seven or eight major plates (depending on how they are defined) and many minor plates or "platelets". Where the plates meet, their relative motion determines the type of plate boundary (or fault): convergent, divergent, or transform. The relative movement of the plates typically ranges from zero to 10 cm annually. Faults tend to be geologically active, experiencing earthquakes, volcanic activity, mountain-building, and oceanic trench formation.<br>Tectonic plates are composed of the oceanic lithosphere and the thicker continental lithosphere, each topped by its own kind of crust. Along convergent plate boundaries, the process of subduction carries the edge of one plate down under the other plate and into the mantle. This process reduces the total surface area (crust) of the Earth. The lost surface is balanced by the formation of new oceanic crust along divergent margins by seafloor spreading, keeping the total surface area constant in a tectonic "conveyor belt".<br>Tectonic plates are relatively rigid and float across the ductile asthenosphere beneath. Lateral density variations in the mantle result in convection currents, the slow creeping motion of Earth's solid mantle. At a seafloor spreading ridge, plates move away from the ridge, which is a topographic high, and the newly formed crust cools as it moves away, increasing its density and contributing to the motion. At a subduction zone the relatively cold, dense oceanic crust sinks down into the mantle, forming the downward convecting limb of a mantle cell, which is the strongest driver of plate motion. The relative importance and interaction of other proposed factors such as active convection, upwelling inside the mantle, and tidal drag of the Moon is still the subject of debate.<br>The outer layers of Earth are divided into the lithosphere and asthenosphere. The division is based on differences in mechanical properties and in the method for the transfer of heat. The lithosphere is cooler and more rigid, while the asthenosphere is hotter and flows more easily. In terms of heat transfer, the lithosphere loses heat by conduction, whereas the asthenosphere also transfers heat by convection and has a nearly adiabatic temperature gradient. This division should not be confused with the chemical subdivision of these same layers into the mantle (comprising both the asthenosphere and the mantle portion of the lithosphere) and the crust: a given piece of mantle may be part of the lithosphere or the asthenosphere at different times depending on its temperature and pressure.<br>The key principle of plate tectonics is that the lithosphere exists as separate and distinct tectonic plates, which ride on the fluid-like solid the asthenosphere. Plate motions range from 10 to 40 mm/year at the Mid-Atlantic Ridge (about as fast as fingernails grow), to about 160 mm/year for the Nazca Plate (about as fast as hair grows).<br>Tectonic lithosphere plates consist of lithospheric mantle overlain by one or two types of crustal material: oceanic crust (in older texts called sima from silicon and magnesium) and continental crust (sial from silicon and aluminium). The distinction between oceanic crust and continental crust is based on their modes of formation. Oceanic crust is formed at sea-floor spreading centers. Continental crust is formed through arc volcanism and accretion of terranes through plate tectonic processes. Oceanic crust is denser than continental crust because it has less silicon and more of the heavier elements than continental crust. As a result of this density difference, oceanic crust generally lies below sea level, while continental crust buoyantly projects above sea level.<br>Average oceanic lithosphere is typically 100 km (62 mi) thick. Its thickness is a function of its age. As time passes, it cools by conducting heat from below, and releasing it raditively into space. The adjacent mantle below is cooled by this process and added to its base. Because it is formed at mid-ocean ridges and spreads outwards, its thickness is therefore a function of its distance from the mid-ocean ridge where it was formed. For a typical distance that oceanic lithosphere must travel before being subducted, the thickness varies from about 6 km (4 mi) thick at mid-ocean ridges to greater than 100 km (62 mi) at subduction zones. For shorter or longer distances, the subduction zone, and therefore also the mean, thickness becomes smaller or larger, respectively. Continental lithosphere is typically about 200 km thick, though this varies considerably between basins, mountain ranges, and stable cratonic interiors of continents.<br>The location where two plates meet is called a plate boundary. Plate boundaries are where geological events occur, such as earthquakes and the creation of topographic features such as mountains, volcanoes, mid-ocean ridges, and oceanic trenches. The vast majority of the world's active volcanoes occur along plate boundaries, with the Pacific Plate's Ring of Fire being the most active and widely known. Some volcanoes occur in the interiors of plates, and these have been variously attributed to internal plate deformation and to mantle plumes.<br>Tectonic plates may include continental crust or oceanic crust, or both. For example, the African Plate includes the continent and parts of the floor of the Atlantic and Indian Oceans.<br>Some pieces of oceanic crust, known as ophiolites, failed to be subducted under continental crust at destructive plate boundaries; instead these oceanic crustal fragments were pushed upward and they are now preserved within continental crust.<br>Three types of plate boundaries exist, characterized by the way the plates move relative to each other. They are associated with different types of surface phenomena. The different types of plate boundaries are:<br>Tectonic plates are able to move because of the relative density of oceanic lithosphere and the relative weakness of the asthenosphere. Dissipation of heat from the mantle is the original source of the energy required to drive plate tectonics through convection or large scale upwelling and doming. As a consequence, a powerful source generating plate motion is the excess density of the oceanic lithosphere sinking in subduction zones. When the new crust forms at mid-ocean ridges, this oceanic lithosphere is initially less dense than the underlying asthenosphere, but it becomes denser with age as it conductively cools and thickens. The greater density of old lithosphere relative to the underlying asthenosphere allows it to sink into the deep mantle at subduction zones, providing most of the driving force for plate movement. The weakness of the asthenosphere allows the tectonic plates to move easily towards a subduction zone.<br>For much of the first quarter of the 20th century, the leading theory of the driving force behind tectonic plate motions envisaged large scale convection currents in the upper mantle, which can be transmitted through the asthenosphere. This theory was launched by Arthur Holmes and some forerunners in the 1930s and was immediately recognized as the solution for the acceptance of the theory as originally discussed in the papers of Alfred Wegener in the early years of the 20th century. However, despite its acceptance, it was long debated in the scientific community because the leading theory still envisaged a static Earth without moving continents up until the major breakthroughs of the early sixties.<br>Two- and three-dimensional imaging of Earth's interior (seismic tomography) shows a varying lateral density distribution throughout the mantle. Such density variations can be material (from rock chemistry), mineral (from variations in mineral structures), or thermal (through thermal expansion and contraction from heat energy). The manifestation of this varying lateral density is mantle convection from buoyancy forces.<br>How mantle convection directly and indirectly relates to plate motion is a matter of ongoing study and discussion in geodynamics. Somehow, this energy must be transferred to the lithosphere for tectonic plates to move. There are essentially two main types of mechanisms that are thought to exist related to the dynamics of the mantle that influence plate motion which are primary (through the large scale convection cells) or secondary. The secondary mechanisms view plate motion driven by friction between the convection currents in the asthenosphere and the more rigid overlying lithosphere. This is due to the inflow of mantle material related to the downward pull on plates in subduction zones at ocean trenches. Slab pull may occur in a geodynamic setting where basal tractions continue to act on the plate as it dives into the mantle (although perhaps to a greater extent acting on both the under and upper side of the slab). Furthermore, slabs that are broken off and sink into the mantle can cause viscous mantle forces driving plates through slab suction.<br>In the theory of plume tectonics followed by numerous researchers during the 1990s, a modified concept of mantle convection currents is used. It asserts that super plumes rise from the deeper mantle and are the drivers or substitutes of the major convection cells. These ideas find their roots in the early 1930s in the works of Beloussov and van Bemmelen, which were initially opposed to plate tectonics and placed the mechanism in a fixed frame of vertical movements. Van Bemmelen later modified the concept in his "Undation Models" and used "Mantle Blisters" as the driving force for horizontal movements, invoking gravitational forces away from the regional crustal doming.<br>The theories find resonance in the modern theories which envisage hot spots or mantle plumes which remain fixed and are overridden by oceanic and continental lithosphere plates over time and leave their traces in the geological record (though these phenomena are not invoked as real driving mechanisms, but rather as modulators).<br>The mechanism is still advocated to explain the break-up of supercontinents during specific geological epochs. It has followers amongst the scientists involved in the theory of Earth expansion.<br>Another theory is that the mantle flows neither in cells nor large plumes but rather as a series of channels just below Earth's crust, which then provide basal friction to the lithosphere. This theory, called "surge tectonics", was popularized during the 1980s and 1990s. Recent research, based on three-dimensional computer modelling, suggests that plate geometry is governed by a feedback between mantle convection patterns and the strength of the lithosphere.<br>Forces related to gravity are invoked as secondary phenomena within the framework of a more general driving mechanism such as the various forms of mantle dynamics described above. In modern views, gravity is invoked as the major driving force, through slab pull along subduction zones.<br>Gravitational sliding away from a spreading ridge is one of the proposed driving forces, it proposes plate motion is driven by the higher elevation of plates at ocean ridges. As oceanic lithosphere is formed at spreading ridges from hot mantle material, it gradually cools and thickens with age (and thus adds distance from the ridge). Cool oceanic lithosphere is significantly denser than the hot mantle material from which it is derived and so with increasing thickness it gradually subsides into the mantle to compensate the greater load. The result is a slight lateral incline with increased distance from the ridge axis.<br>This force is regarded as a secondary force and is often referred to as "ridge push". This is a misnomer as there is no force "pushing" horizontally, indeed tensional features are dominant along ridges. It is more accurate to refer to this mechanism as "gravitational sliding", since the topography across the whole plate can vary considerably and spreading ridges are only the most prominent feature. Other mechanisms generating this gravitational secondary force include flexural bulging of the lithosphere before it dives underneath an adjacent plate, producing a clear topographical feature that can offset, or at least affect, the influence of topographical ocean ridges. Mantle plumes and hot spots are also postulated to impinge on the underside of tectonic plates.<br>Slab pull: Current scientific opinion is that the asthenosphere is insufficiently competent or rigid to directly cause motion by friction along the base of the lithosphere. Slab pull is therefore most widely thought to be the greatest force acting on the plates. In this current understanding, plate motion is mostly driven by the weight of cold, dense plates sinking into the mantle at trenches. Recent models indicate that trench suction plays an important role as well. However, the fact that the North American Plate is nowhere being subducted, although it is in motion, presents a problem. The same holds for the African, Eurasian, and Antarctic plates.<br>Gravitational sliding away from mantle doming: According to older theories, one of the driving mechanisms of the plates is the existence of large scale asthenosphere/mantle domes which cause the gravitational sliding of lithosphere plates away from them (see the paragraph on Mantle Mechanisms). This gravitational sliding represents a secondary phenomenon of this basically vertically oriented mechanism. It finds its roots in the Undation Model of van Bemmelen. This can act on various scales, from the small scale of one island arc up to the larger scale of an entire ocean basin.<br>Alfred Wegener, being a meteorologist, had proposed tidal forces and centrifugal forces as the main driving mechanisms behind continental drift; however, these forces were considered far too small to cause continental motion as the concept was of continents plowing through oceanic crust. Therefore, Wegener later changed his position and asserted that convection currents are the main driving force of plate tectonics in the last edition of his book in 1929.<br>However, in the plate tectonics context (accepted since the seafloor spreading proposals of Heezen, Hess, Dietz, Morley, Vine, and Matthews (see below) during the early 1960s), the oceanic crust is suggested to be in motion with the continents which caused the proposals related to Earth rotation to be reconsidered. In more recent literature, these driving forces are:<br>Forces that are small and generally negligible are:<br>For these mechanisms to be overall valid, systematic relationships should exist all over the globe between the orientation and kinematics of deformation and the geographical latitudinal and longitudinal grid of Earth itself. These systematic relations studies in the second half of the nineteenth century and the first half of the twentieth century underline exactly the opposite: that the plates had not moved in time, that the deformation grid was fixed with respect to Earth's equator and axis, and that gravitational driving forces were generally acting vertically and caused only local horizontal movements (the so-called pre-plate tectonic, "fixist theories"). Later studies (discussed below on this page), therefore, invoked many of the relationships recognized during this pre-plate tectonics period to support their theories (see reviews of these various mechanisms related to Earth rotation the work of van Dijk and collaborators).<br>Of the many forces discussed above, tidal force is still highly debated and defended as a possible principal driving force of plate tectonics. The other forces are only used in global geodynamic models not using plate tectonics concepts (therefore beyond the discussions treated in this section) or proposed as minor modulations within the overall plate tectonics model.<br>In 1973, George W. Moore of the USGS and R. C. Bostrom presented evidence for a general westward drift of Earth's lithosphere with respect to the mantle, based on the steepness of the subduction zones (shallow dipping towards the east, steeply dipping towards the west). They concluded that tidal forces (the tidal lag or "friction") caused by Earth's rotation and the forces acting upon it by the Moon are a driving force for plate tectonics. As Earth spins eastward beneath the Moon, the Moon's gravity ever so slightly pulls Earth's surface layer back westward, just as proposed by Alfred Wegener (see above). Since 1990 this theory is mainly advocated by Doglioni and co-workers (Doglioni 1990), such as in a more recent 2006 study, where scientists reviewed and advocated these ideas. It has been suggested in Lovett (2006) that this observation may also explain why Venus and Mars have no plate tectonics, as Venus has no moon and Mars' moons are too small to have significant tidal effects on the planet. In a paper by  it was suggested that, on the other hand, it can easily be observed that many plates are moving north and eastward, and that the dominantly westward motion of the Pacific Ocean basins derives simply from the eastward bias of the Pacific spreading center (which is not a predicted manifestation of such lunar forces). In the same paper the authors admit, however, that relative to the lower mantle, there is a slight westward component in the motions of all the plates. They demonstrated though that the westward drift, seen only for the past 30 Ma, is attributed to the increased dominance of the steadily growing and accelerating Pacific plate. The debate is still open, and a recent paper by Hofmeister et al. (2022)  revived the idea advocating again the interaction between the Earth's rotation and the Moon as main driving forces for the plates.<br>The vector of a plate's motion is a function of all the forces acting on the plate; however, therein lies the problem regarding the degree to which each process contributes to the overall motion of each tectonic plate.<br>The diversity of geodynamic settings and the properties of each plate result from the impact of the various processes actively driving each individual plate. One method of dealing with this problem is to consider the relative rate at which each plate is moving as well as the evidence related to the significance of each process to the overall driving force on the plate.<br>One of the most significant correlations discovered to date is that lithospheric plates attached to downgoing (subducting) plates move much faster than other types of plates. The Pacific plate, for instance, is essentially surrounded by zones of subduction (the so-called Ring of Fire) and moves much faster than the plates of the Atlantic basin, which are attached (perhaps one could say 'welded') to adjacent continents instead of subducting plates. It is thus thought that forces associated with the downgoing plate (slab pull and slab suction) are the driving forces which determine the motion of plates, except for those plates which are not being subducted. This view however has been contradicted by a recent study which found that the actual motions of the Pacific Plate and other plates associated with the East Pacific Rise do not correlate mainly with either slab pull or slab push, but rather with a mantle convection upwelling whose horizontal spreading along the bases of the various plates drives them along via viscosity-related traction forces. The driving forces of plate motion continue to be active subjects of on-going research within geophysics and tectonophysics.<br>The development of the theory of plate tectonics was the scientific and cultural change which occurred during a period of 50 years of scientific debate. The event of the acceptance itself was a paradigm shift and can therefore be classified as a scientific revolution.<br>Around the start of the twentieth century, various theorists unsuccessfully attempted to explain the many geographical, geological, and biological continuities between continents. In 1912, the meteorologist Alfred Wegener described what he called continental drift, an idea that culminated fifty years later in the modern theory of plate tectonics.<br>Wegener expanded his theory in his 1915 book The Origin of Continents and Oceans. Starting from the idea (also expressed by his forerunners) that the present continents once formed a single land mass (later called Pangaea), Wegener suggested that these separated and drifted apart, likening them to "icebergs" of low density sial floating on a sea of denser sima. Supporting evidence for the idea came from the dove-tailing outlines of South America's east coast and Africa's west coast Antonio Snider-Pellegrini had drawn on his maps, and from the matching of the rock formations along these edges. Confirmation of their previous contiguous nature also came from the fossil plants Glossopteris and Gangamopteris, and the therapsid or mammal-like reptile Lystrosaurus, all widely distributed over South America, Africa, Antarctica, India, and Australia. The evidence for such an erstwhile joining of these continents was patent to field geologists working in the southern hemisphere. The South African Alex du Toit put together a mass of such information in his 1937 publication Our Wandering Continents, and went further than Wegener in recognising the strong links between the Gondwana fragments.<br>Wegener's work was initially not widely accepted, in part due to a lack of detailed evidence but mostly because of the lack of a reasonable physically supported mechanism. Earth might have a solid crust and mantle and a liquid core, but there seemed to be no way that portions of the crust could move around. Many distinguished scientists of the time, such as Harold Jeffreys and Charles Schuchert, were outspoken critics of continental drift.<br>Despite much opposition, the view of continental drift gained support and a lively debate started between "drifters" or "mobilists" (proponents of the theory) and "fixists" (opponents). During the 1920s, 1930s and 1940s, the former reached important milestones proposing that convection currents might have driven the plate movements, and that spreading may have occurred below the sea within the oceanic crust. Concepts close to the elements now incorporated in plate tectonics were proposed by geophysicists and geologists (both fixists and mobilists) like Vening-Meinesz, Holmes, and Umbgrove. In 1941, Otto Ampferer described, in his publication "Thoughts on the motion picture of the Atlantic region", processes that anticipate what is now called seafloor spreading and subduction. One of the first pieces of geophysical evidence that was used to support the movement of lithospheric plates came from paleomagnetism. This is based on the fact that rocks of different ages show a variable magnetic field direction, evidenced by studies since the mid–nineteenth century. The magnetic north and south poles reverse through time, and, especially important in paleotectonic studies, the relative position of the magnetic north pole varies through time. Initially, during the first half of the twentieth century, the latter phenomenon was explained by introducing what was called "polar wander" (see apparent polar wander) (i.e., it was assumed that the north pole location had been shifting through time). An alternative explanation, though, was that the continents had moved (shifted and rotated) relative to the north pole, and each continent, in fact, shows its own "polar wander path". During the late 1950s, it was successfully shown on two occasions that these data could show the validity of continental drift: by Keith Runcorn in a paper in 1956, and by Warren Carey in a symposium held in March 1956.<br>The second piece of evidence in support of continental drift came during the late 1950s and early 60s from data on the bathymetry of the deep ocean floors and the nature of the oceanic crust such as magnetic properties and, more generally, with the development of marine geology which gave evidence for the association of seafloor spreading along the mid-oceanic ridges and magnetic field reversals, published between 1959 and 1963 by Heezen, Dietz, Hess, Mason, Vine & Matthews, and Morley.<br>Simultaneous advances in early seismic imaging techniques in and around Wadati–Benioff zones along the trenches bounding many continental margins, together with many other geophysical (e.g. gravimetric) and geological observations, showed how the oceanic crust could disappear into the mantle, providing the mechanism to balance the extension of the ocean basins with shortening along its margins.<br>All this evidence, both from the ocean floor and from the continental margins, made it clear around 1965 that continental drift was feasible. The theory of plate tectonics was defined in a series of papers between 1965 and 1967. The theory revolutionized the Earth sciences, explaining a diverse range of geological phenomena and their implications in other studies such as paleogeography and paleobiology.<br>In the late 19th and early 20th centuries, geologists assumed that Earth's major features were fixed, and that most geologic features such as basin development and mountain ranges could be explained by vertical crustal movement, described in what is called the geosynclinal theory. Generally, this was placed in the context of a contracting planet Earth due to heat loss in the course of a relatively short geological time.<br>It was observed as early as 1596 that the opposite coasts of the Atlantic Ocean—or, more precisely, the edges of the continental shelves—have similar shapes and seem to have once fitted together.<br>Since that time many theories were proposed to explain this apparent complementarity, but the assumption of a solid Earth made these various proposals difficult to accept.<br>The discovery of radioactivity and its associated heating properties in 1895 prompted a re-examination of the apparent age of Earth. This had previously been estimated by its cooling rate under the assumption that Earth's surface radiated like a black body. Those calculations had implied that, even if it started at red heat, Earth would have dropped to its present temperature in a few tens of millions of years. Armed with the knowledge of a new heat source, scientists realized that Earth would be much older, and that its core was still sufficiently hot to be liquid.<br>By 1915, after having published a first article in 1912, Alfred Wegener was making serious arguments for the idea of continental drift in the first edition of The Origin of Continents and Oceans. In that book (re-issued in four successive editions up to the final one in 1936), he noted how the east coast of South America and the west coast of Africa looked as if they were once attached. Wegener was not the first to note this (Abraham Ortelius, Antonio Snider-Pellegrini, Eduard Suess, Roberto Mantovani and Frank Bursley Taylor preceded him just to mention a few), but he was the first to marshal significant fossil and paleo-topographical and climatological evidence to support this simple observation (and was supported in this by researchers such as Alex du Toit). Furthermore, when the rock strata of the margins of separate continents are very similar it suggests that these rocks were formed in the same way, implying that they were joined initially. For instance, parts of Scotland and Ireland contain rocks very similar to those found in Newfoundland and New Brunswick. Furthermore, the Caledonian Mountains of Europe and parts of the Appalachian Mountains of North America are very similar in structure and lithology.<br>However, his ideas were not taken seriously by many geologists, who pointed out that there was no apparent mechanism for continental drift. Specifically, they did not see how continental rock could plow through the much denser rock that makes up oceanic crust. Wegener could not explain the force that drove continental drift, and his vindication did not come until after his death in 1930.<br>As it was observed early that although granite existed on continents, seafloor seemed to be composed of denser basalt, the prevailing concept during the first half of the twentieth century was that there were two types of crust, named "sial" (continental type crust) and "sima" (oceanic type crust). Furthermore, it was supposed that a static shell of strata was present under the continents. It therefore looked apparent that a layer of basalt (sial) underlies the continental rocks.<br>However, based on abnormalities in plumb line deflection by the Andes in Peru, Pierre Bouguer had deduced that less-dense mountains must have a downward projection into the denser layer underneath. The concept that mountains had "roots" was confirmed by George B. Airy a hundred years later, during study of Himalayan gravitation, and seismic studies detected corresponding density variations. Therefore, by the mid-1950s, the question remained unresolved as to whether mountain roots were clenched in surrounding basalt or were floating on it like an iceberg.<br>During the 20th century, improvements in and greater use of seismic instruments such as seismographs enabled scientists to learn that earthquakes tend to be concentrated in specific areas, most notably along the oceanic trenches and spreading ridges. By the late 1920s, seismologists were beginning to identify several prominent earthquake zones parallel to the trenches that typically were inclined 40–60° from the horizontal and extended several hundred kilometers into Earth. These zones later became known as Wadati–Benioff zones, or simply Benioff zones, in honor of the seismologists who first recognized them, Kiyoo Wadati of Japan and Hugo Benioff of the United States. The study of global seismicity greatly advanced in the 1960s with the establishment of the Worldwide Standardized Seismograph Network (WWSSN) to monitor the compliance of the 1963 treaty banning above-ground testing of nuclear weapons. The much improved data from the WWSSN instruments allowed seismologists to map precisely the zones of earthquake concentration worldwide.<br>Meanwhile, debates developed around the phenomenon of polar wander. Since the early debates of continental drift, scientists had discussed and used evidence that polar drift had occurred because continents seemed to have moved through different climatic zones during the past. Furthermore, paleomagnetic data had shown that the magnetic pole had also shifted during time. Reasoning in an opposite way, the continents might have shifted and rotated, while the pole remained relatively fixed. The first time the evidence of magnetic polar wander was used to support the movements of continents was in a paper by Keith Runcorn in 1956, and successive papers by him and his students Ted Irving (who was actually the first to be convinced of the fact that paleomagnetism supported continental drift) and Ken Creer.<br>This was immediately followed by a symposium on continental drift in Tasmania in March 1956 organised by S. Warren Carey who had been one of the supporters and promotors of Continental Drift since the thirties  During this symposium, some of the participants used the evidence in the theory of an expansion of the global crust, a theory which had been proposed by other workers decades earlier. In this hypothesis, the shifting of the continents is explained by a large increase in the size of Earth since its formation. However, although the theory still has supporters in science, this is generally regarded as unsatisfactory because there is no convincing mechanism to produce a significant expansion of Earth. Other work during the following years would soon show that the evidence was equally in support of continental drift on a globe with a stable radius.<br>During the 1930s up to the late 1950s, works by Vening-Meinesz, Holmes, Umbgrove, and numerous others outlined concepts that were close or nearly identical to modern plate tectonics theory. In particular, the English geologist Arthur Holmes proposed in 1920 that plate junctions might lie beneath the sea, and in 1928 that convection currents within the mantle might be the driving force. Often, these contributions are forgotten because:<br>In 1947, a team of scientists led by Maurice Ewing utilizing the Woods Hole Oceanographic Institution's research vessel Atlantis and an array of instruments, confirmed the existence of a rise in the central Atlantic Ocean, and found that the floor of the seabed beneath the layer of sediments consisted of basalt, not the granite which is the main constituent of continents. They also found that the oceanic crust was much thinner than continental crust. All these new findings raised important and intriguing questions.<br>The new data that had been collected on the ocean basins also showed particular characteristics regarding the bathymetry. One of the major outcomes of these datasets was that all along the globe, a system of mid-oceanic ridges was detected. An important conclusion was that along this system, new ocean floor was being created, which led to the concept of the "Great Global Rift". This was described in the crucial paper of Bruce Heezen (1960) based on his work with Marie Tharp, which would trigger a real revolution in thinking. A profound consequence of seafloor spreading is that new crust was, and still is, being continually created along the oceanic ridges. For this reason, Heezen initially advocated the so-called "expanding Earth" hypothesis of S. Warren Carey (see above). Therefore, the question remained as to how new crust could continuously be added along the oceanic ridges without increasing the size of Earth. In reality, this question had been solved already by numerous scientists during the 1940s and the 1950s, like Arthur Holmes, Vening-Meinesz, Coates and many others: The crust in excess disappeared along what were called the oceanic trenches, where so-called "subduction" occurred. Therefore, when various scientists during the early 1960s started to reason on the data at their disposal regarding the ocean floor, the pieces of the theory quickly fell into place.<br>The question particularly intrigued Harry Hammond Hess, a Princeton University geologist and a Naval Reserve Rear Admiral, and Robert S. Dietz, a scientist with the United States Coast and Geodetic Survey who first coined the term seafloor spreading. Dietz and Hess (the former published the same idea one year earlier in Nature, but priority belongs to Hess who had already distributed an unpublished manuscript of his 1962 article by 1960) were among the small number who really understood the broad implications of sea floor spreading and how it would eventually agree with the, at that time, unconventional and unaccepted ideas of continental drift and the elegant and mobilistic models proposed by previous workers like Holmes.<br>In the same year, Robert R. Coats of the U.S. Geological Survey described the main features of island arc subduction in the Aleutian Islands. His paper, though little noted (and sometimes even ridiculed) at the time, has since been called "seminal" and "prescient". In reality, it actually shows that the work by the European scientists on island arcs and mountain belts performed and published during the 1930s up until the 1950s was applied and appreciated also in the United States.<br>If Earth's crust was expanding along the oceanic ridges, Hess and Dietz reasoned like Holmes and others before them, it must be shrinking elsewhere. Hess followed Heezen, suggesting that new oceanic crust continuously spreads away from the ridges in a conveyor belt–like motion. And, using the mobilistic concepts developed before, he correctly concluded that many millions of years later, the oceanic crust eventually descends along the continental margins where oceanic trenches—very deep, narrow canyons—are formed, e.g. along the rim of the Pacific Ocean basin. The important step Hess made was that convection currents would be the driving force in this process, arriving at the same conclusions as Holmes had decades before with the only difference that the thinning of the ocean crust was performed using Heezen's mechanism of spreading along the ridges. Hess therefore concluded that the Atlantic Ocean was expanding while the Pacific Ocean was shrinking. As old oceanic crust is "consumed" in the trenches (like Holmes and others, he thought this was done by thickening of the continental lithosphere, not, as now understood, by underthrusting at a larger scale of the oceanic crust itself into the mantle), new magma rises and erupts along the spreading ridges to form new crust. In effect, the ocean basins are perpetually being "recycled", with the forming of new crust and the destruction of old oceanic lithosphere occurring simultaneously. Thus, the new mobilistic concepts neatly explained why Earth does not get bigger with sea floor spreading, why there is so little sediment accumulation on the ocean floor, and why oceanic rocks are much younger than continental rocks.<br>Beginning in the 1950s, scientists like Victor Vacquier, using magnetic instruments (magnetometers) adapted from airborne devices developed during World War II to detect submarines, began recognizing odd magnetic variations across the ocean floor. This finding, though unexpected, was not entirely surprising because it was known that basalt—the iron-rich, volcanic rock making up the ocean floor—contains a strongly magnetic mineral (magnetite) and can locally distort compass readings. This distortion was recognized by Icelandic mariners as early as the late 18th century. More importantly, because the presence of magnetite gives the basalt measurable magnetic properties, these newly discovered magnetic variations provided another means to study the deep ocean floor. When newly formed rock cools, such magnetic materials recorded Earth's magnetic field at the time.<br>As more and more of the seafloor was mapped during the 1950s, the magnetic variations turned out not to be random or isolated occurrences, but instead revealed recognizable patterns. When these magnetic patterns were mapped over a wide region, the ocean floor showed a zebra-like pattern: one stripe with normal polarity and the adjoining stripe with reversed polarity. The overall pattern, defined by these alternating bands of normally and reversely polarized rock, became known as magnetic striping, and was published by Ron G. Mason and co-workers in 1961, who did not find, though, an explanation for these data in terms of sea floor spreading, like Vine, Matthews and Morley a few years later.<br>The discovery of magnetic striping called for an explanation. In the early 1960s scientists such as Heezen, Hess and Dietz had begun to theorise that mid-ocean ridges mark structurally weak zones where the ocean floor was being ripped in two lengthwise along the ridge crest (see the previous paragraph). New magma from deep within Earth rises easily through these weak zones and eventually erupts along the crest of the ridges to create new oceanic crust. This process, at first denominated the "conveyer belt hypothesis" and later called seafloor spreading, operating over many millions of years continues to form new ocean floor all across the 50,000 km-long system of mid-ocean ridges.<br>Only four years after the maps with the "zebra pattern" of magnetic stripes were published, the link between sea floor spreading and these patterns was correctly placed, independently by Lawrence Morley, and by Fred Vine and Drummond Matthews, in 1963, now called the Vine–Matthews–Morley hypothesis. This hypothesis linked these patterns to geomagnetic reversals and was supported by several lines of evidence:<br>By explaining both the zebra-like magnetic striping and the construction of the mid-ocean ridge system, the seafloor spreading hypothesis (SFS) quickly gained converts and represented another major advance in the development of the plate-tectonics theory. Furthermore, the oceanic crust now came to be appreciated as a natural "tape recording" of the history of the geomagnetic field reversals (GMFR) of Earth's magnetic field. Today, extensive studies are dedicated to the calibration of the normal-reversal patterns in the oceanic crust on one hand and known timescales derived from the dating of basalt layers in sedimentary sequences (magnetostratigraphy) on the other, to arrive at estimates of past spreading rates and plate reconstructions.<br>After all these considerations, plate tectonics (or, as it was initially called "New Global Tectonics") became quickly accepted in the scientific world, and numerous papers followed that defined the concepts:<br>Continental drift theory helps biogeographers to explain the disjunct biogeographic distribution of present-day life found on different continents but having similar ancestors. In particular, it explains the Gondwanan distribution of ratites and the Antarctic flora.<br>Reconstruction is used to establish past (and future) plate configurations, helping determine the shape and make-up of ancient supercontinents and providing a basis for paleogeography.<br>Current plate boundaries are defined by their seismicity. Past plate boundaries within existing plates are identified from a variety of evidence, such as the presence of ophiolites that are indicative of vanished oceans.<br>Tectonic motion is believed to have begun around 3 to 3.8 billion years ago.<br>Various types of quantitative and semi-quantitative information are available to constrain past plate motions. The geometric fit between continents, such as between west Africa and South America is still an important part of plate reconstruction. Magnetic stripe patterns provide a reliable guide to relative plate motions going back into the Jurassic period. The tracks of hotspots give absolute reconstructions, but these are only available back to the Cretaceous. Older reconstructions rely mainly on paleomagnetic pole data, although these only constrain the latitude and rotation, but not the longitude. Combining poles of different ages in a particular plate to produce apparent polar wander paths provides a method for comparing the motions of different plates through time. Additional evidence comes from the distribution of certain sedimentary rock types, faunal provinces shown by particular fossil groups, and the position of orogenic belts.<br>The movement of plates has caused the formation and break-up of continents over time, including occasional formation of a supercontinent that contains most or all of the continents. The supercontinent Columbia or Nuna formed during a period of 2,000 to 1,800 million years ago and broke up about 1,500 to 1,300 million years ago. The supercontinent Rodinia is thought to have formed about 1 billion years ago and to have embodied most or all of Earth's continents, and broken up into eight continents around 600 million years ago. The eight continents later re-assembled into another supercontinent called Pangaea; Pangaea broke up into Laurasia (which became North America and Eurasia) and Gondwana (which became the remaining continents).<br>The Himalayas, the world's tallest mountain range, are assumed to have been formed by the collision of two major plates. Before uplift, the area where they currently stand was covered by the Tethys Ocean.<br>Depending on how they are defined, there are usually seven or eight "major" plates: African, Antarctic, Eurasian, North American, South American, Pacific, and Indo-Australian. The latter is sometimes subdivided into the Indian and Australian plates.<br>There are dozens of smaller plates, the seven largest of which are the Arabian, Caribbean, Juan de Fuca, Cocos, Nazca, Philippine Sea, and Scotia.<br>During the twenties of the 21st Century new proposals have come forward that divide the Earth's crust into many smaller plates, called terranes, which reflects the fact that Plate reconstructions show that the larger plates have been internally deformed and oceanic and continental plates have been fragmented over time. This has resulted in the definition of ca. 1200 terranes inside the oceanic plates, continental blocks and the mobile zones (mountainous belts) that separate them.<br>The current motion of the tectonic plates is today determined by remote sensing satellite data sets, calibrated with ground station measurements.<br>The appearance of plate tectonics on terrestrial planets is related to planetary mass, with more massive planets than Earth expected to exhibit plate tectonics. Earth may be a borderline case, owing its tectonic activity to abundant water (silica and water form a deep eutectic).<br>Venus shows no evidence of active plate tectonics. There is debatable evidence of active tectonics in the planet's distant past; however, events taking place since then (such as the plausible and generally accepted hypothesis that the Venusian lithosphere has thickened greatly over the course of several hundred million years) has made constraining the course of its geologic record difficult. However, the numerous well-preserved impact craters have been used as a dating method to approximately date the Venusian surface (since there are thus far no known samples of Venusian rock to be dated by more reliable methods). Dates derived are dominantly in the range 500 to 750 million years ago, although ages of up to 1,200 million years ago have been calculated. This research has led to the fairly well accepted hypothesis that Venus has undergone an essentially complete volcanic resurfacing at least once in its distant past, with the last event taking place approximately within the range of estimated surface ages. While the mechanism of such an impressive thermal event remains a debated issue in Venusian geosciences, some scientists are advocates of processes involving plate motion to some extent.<br>One explanation for Venus's lack of plate tectonics is that on Venus temperatures are too high for significant water to be present. Earth's crust is soaked with water, and water plays an important role in the development of shear zones. Plate tectonics requires weak surfaces in the crust along which crustal slices can move, and it may well be that such weakening never took place on Venus because of the absence of water. However, some researchers remain convinced that plate tectonics is or was once active on this planet.<br>Mars is considerably smaller than Earth and Venus, and there is evidence for ice on its surface and in its crust.<br>In the 1990s, it was proposed that Martian Crustal Dichotomy was created by plate tectonic processes. Scientists today disagree, and think that it was created either by upwelling within the Martian mantle that thickened the crust of the Southern Highlands and formed Tharsis or by a giant impact that excavated the Northern Lowlands.<br>Valles Marineris may be a tectonic boundary.<br>Observations made of the magnetic field of Mars by the Mars Global Surveyor spacecraft in 1999 showed patterns of magnetic striping discovered on this planet. Some scientists interpreted these as requiring plate tectonic processes, such as seafloor spreading. However, their data failed a "magnetic reversal test", which is used to see if they were formed by flipping polarities of a global magnetic field.<br>Some of the satellites of Jupiter have features that may be related to plate-tectonic style deformation, although the materials and specific mechanisms may be different from plate-tectonic activity on Earth. On 8 September 2014, NASA reported finding evidence of plate tectonics on Europa, a satellite of Jupiter—the first sign of subduction activity on another world other than Earth.<br>Titan, the largest moon of Saturn, was reported to show tectonic activity in images taken by the Huygens probe, which landed on Titan on January 14, 2005.<br>On Earth-sized planets, plate tectonics is more likely if there are oceans of water. However, in 2007, two independent teams of researchers came to opposing conclusions about the likelihood of plate tectonics on larger super-Earths with one team saying that plate tectonics would be episodic or stagnant and the other team saying that plate tectonics is very likely on super-earths even if the planet is dry.<br>Consideration of plate tectonics is a part of the search for extraterrestrial intelligence and extraterrestrial life.<br>Videos

### DOC[4] (GROUND TRUTH) continental_drift/Paleomagnetism3.txt
> Toggle the table of contents<br><br><br><br><br><br><br><br>Paleomagnetism<br><br><br><br>42 languages<br><br><br><br><br>AfrikaansالعربيةAzərbaycancaBosanskiCatalàČeštinaDeutschEspañolEuskaraفارسیFrançaisGaeilgeGalego한국어Հայերենहिन्दीHrvatskiBahasa IndonesiaItalianoעבריתҚазақшаMagyarमराठीBahasa MelayuNederlands日本語Norsk bokmålNorsk nynorskپښتوPolskiPortuguêsРусскийSlovenčinaSlovenščinaСрпски / srpskiSrpskohrvatski / српскохрватскиSuomiSvenskaTürkçeУкраїнськаTiếng Việt中文<br><br>Edit links<br><br><br><br><br><br><br><br><br><br><br><br>ArticleTalk<br><br><br><br><br><br>English<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>ReadEditView history<br><br><br><br><br><br><br><br>Tools<br><br><br><br><br><br>Tools<br>move to sidebar<br>hide<br><br><br><br>		Actions<br>	<br><br><br>ReadEditView history<br><br><br><br><br><br>		General<br>	<br><br><br>What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR codeWikidata item<br><br><br><br><br><br>		Print/export<br>	<br><br><br>Download as PDFPrintable version<br><br><br><br><br><br>		In other projects<br>	<br><br><br>Wikimedia Commons<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>From Wikipedia, the free encyclopedia<br><br><br>Study of Earth's magnetic field in past<br><br><br><br>Magnetic stripes are the result of reversals of the Earth's field and seafloor spreading. New oceanic crust is magnetized as it forms and then it moves away from the ridge in both directions. The models show a ridge (a) about 5 million years ago (b) about 2 million years ago and (c) in the present.[1]<br>Paleomagnetism (occasionally palaeomagnetism) is the study of prehistoric Earth's magnetic fields recorded in rocks, sediment, or archeological materials. Geophysicists who specialize in paleomagnetism are called paleomagnetists.<br>Certain magnetic minerals in rocks can record the direction and intensity of Earth's magnetic field at the time they formed. This record provides information on the past behavior of the geomagnetic field and the past location of tectonic plates. The record of geomagnetic reversals preserved in volcanic and sedimentary rock sequences (magnetostratigraphy) provides a time-scale that is used as a geochronologic tool.<br>Evidence from paleomagnetism led to the revival of the continental drift hypothesis and its transformation into the modern theory of plate tectonics. Apparent polar wander paths provided the first clear geophysical evidence for continental drift, while marine magnetic anomalies did the same for seafloor spreading. Paleomagnetic data continues to extend the history of plate tectonics back in time, constraining the ancient position and movement of continents and continental fragments (terranes).

### DOC[5] (IRRELEVANT) remote_sensing/Remote_sensing_Acoustic_and_near_acoustic3.txt
> ArticleTalk<br><br><br><br><br><br>English<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>ReadEditView history<br><br><br><br><br><br><br><br>Tools<br><br><br><br><br><br>Tools<br>move to sidebar<br>hide<br><br><br><br>		Actions<br>	<br><br><br>ReadEditView history<br><br><br><br><br><br>		General<br>	<br><br><br>What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR codeWikidata item<br><br><br><br><br><br>		Print/export<br>	<br><br><br>Download as PDFPrintable version<br><br><br><br><br><br>		In other projects<br>	<br><br><br>Wikimedia CommonsWikiversity<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>From Wikipedia, the free encyclopedia<br><br><br>This is the latest accepted revision, reviewed on 11 April 2024.<br><br><br><br>Acquisition of information at a significant distance from the subject<br>Not to be confused with remote viewing.<br>For other uses, see Remote sensing (disambiguation).<br>This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources: "Remote sensing" – news · newspapers · books · scholar · JSTOR (September 2023) (Learn how and when to remove this template message)<br><br><br>Synthetic aperture radar image of Death Valley colored using polarimetry<br>Remote sensing is the acquisition of information about an object or phenomenon without making physical contact with the object, in contrast to in situ or on-site observation. The term is applied especially to acquiring information about Earth and other planets. Remote sensing is used in numerous fields, including geophysics, geography, land surveying and most Earth science disciplines (e.g. exploration geophysics, hydrology, ecology, meteorology, oceanography, glaciology, geology). It also has military, intelligence, commercial, economic, planning, and humanitarian applications, among others.<br>In current usage, the term remote sensing generally refers to the use of satellite- or aircraft-based sensor technologies to detect and classify objects on Earth. It includes the surface and the atmosphere and oceans, based on propagated signals (e.g. electromagnetic radiation). It may be split into "active" remote sensing (when a signal is emitted by a satellite or aircraft to the object and its reflection is detected by the sensor) and "passive" remote sensing (when the reflection of sunlight is detected by the sensor).[1][2][3][4]<br><br><br>Overview[edit]<br>This video is about how Landsat was used to identify areas of conservation in the Democratic Republic of the Congo, and how it was used to help map an area called MLW in the north.<br>Remote sensing can be divided into two types of methods: Passive remote sensing and Active remote sensing. Passive sensors gather radiation that is emitted or reflected by the object or surrounding areas. Reflected sunlight is the most common source of radiation measured by passive sensors. Examples of passive remote sensors include film photography, infrared, charge-coupled devices, and radiometers. Active collection, on the other hand, emits energy in order to scan objects and areas whereupon a sensor then detects and measures the radiation that is reflected or backscattered from the target. RADAR and LiDAR are examples of active remote sensing where the time delay between emission and return is measured, establishing the location, speed and direction of an object.<br><br>Illustration of remote sensing<br>Remote sensing makes it possible to collect data of dangerous or inaccessible areas. Remote sensing applications include monitoring deforestation in areas such as the Amazon Basin, glacial features in Arctic and Antarctic regions, and depth sounding of coastal and ocean depths. Military collection during the Cold War made use of stand-off collection of data about dangerous border areas. Remote sensing also replaces costly and slow data collection on the ground, ensuring in the process that areas or objects are not disturbed.<br>Orbital platforms collect and transmit data from different parts of the electromagnetic spectrum, which in conjunction with larger scale aerial or ground-based sensing and analysis, provides researchers with enough information to monitor trends such as El Niño and other natural long and short term phenomena. Other uses include different areas of the earth sciences such as natural resource management, agricultural fields such as land usage and conservation,[5][6] greenhouse gas monitoring,[7] oil spill detection and monitoring,[8] and national security and overhead, ground-based and stand-off collection on border areas.[9]<br><br>Types of data acquisition techniques[edit]<br>The basis for multispectral collection and analysis is that of examined areas or objects that reflect or emit radiation that stand out from surrounding areas. For a summary of major remote sensing satellite systems see the overview table.<br><br>Applications of remote sensing[edit]<br>Further information: Remote sensing (geology) and Remote sensing in archaeology<br>Radar image of Aswan Dam, Egypt taken by Umbra<br>Conventional radar is mostly associated with aerial traffic control, early warning, and certain large-scale meteorological data. Doppler radar is used by local law enforcements' monitoring of speed limits and in enhanced meteorological collection such as wind speed and direction within weather systems in addition to precipitation location and intensity. Other types of active collection includes plasmas in the ionosphere. Interferometric synthetic aperture radar is used to produce precise digital elevation models of large scale terrain (See RADARSAT, TerraSAR-X, Magellan).<br>Laser and radar altimeters on satellites have provided a wide range of data. By measuring the bulges of water caused by gravity, they map features on the seafloor to a resolution of a mile or so. By measuring the height and wavelength of ocean waves, the altimeters measure wind speeds and direction, and surface ocean currents and directions.<br>Ultrasound (acoustic) and radar tide gauges measure sea level, tides and wave direction in coastal and offshore tide gauges.<br>Light detection and ranging (LIDAR) is well known in examples of weapon ranging, laser illuminated homing of projectiles. LIDAR is used to detect and measure the concentration of various chemicals in the atmosphere, while airborne LIDAR can be used to measure the heights of objects and features on the ground more accurately than with radar technology. Vegetation remote sensing is a principal application of LIDAR.[10]<br>Radiometers and photometers are the most common instrument in use, collecting reflected and emitted radiation in a wide range of frequencies. The most common are visible and infrared sensors, followed by microwave, gamma-ray, and rarely, ultraviolet. They may also be used to detect the emission spectra of various chemicals, providing data on chemical concentrations in the atmosphere.<br>Examples of remote sensing equipment deployed byor interfaced with oceanographic research vessels.[11]<br>Radiometers are also used at night, because artificial light emissions are a key signature of human activity.[12] Applications include remote sensing of population, GDP, and damage to infrastructure from war or disasters.<br>Radiometers and radar onboard of satellites can be used to monitor volcanic eruptions [13][14]<br>Spectropolarimetric Imaging has been reported to be useful for target tracking purposes by researchers at the U.S. Army Research Laboratory. They determined that manmade items possess polarimetric signatures that are not found in natural objects. These conclusions were drawn from the imaging of military trucks, like the Humvee, and trailers with their acousto-optic tunable filter dual hyperspectral and spectropolarimetric VNIR Spectropolarimetric Imager.[15][16]<br>Stereographic pairs of aerial photographs have often been used to make topographic maps by imagery and terrain analysts in trafficability and highway departments for potential routes, in addition to modelling terrestrial habitat features.[17][18][19]<br>Simultaneous multi-spectral platforms such as Landsat have been in use since the 1970s. These thematic mappers take images in multiple wavelengths of electromagnetic radiation (multi-spectral) and are usually found on Earth observation satellites, including (for example) the Landsat program or the IKONOS satellite. Maps of land cover and land use from thematic mapping can be used to prospect for minerals, detect or monitor land usage, detect invasive vegetation, deforestation, and examine the health of indigenous plants and crops (satellite crop monitoring), including entire farming regions or forests.[20] Prominent scientists using remote sensing for this purpose include Janet Franklin and Ruth DeFries. Landsat images are used by regulatory agencies such as KYDOW to indicate water quality parameters including Secchi depth, chlorophyll density, and total phosphorus content. Weather satellites are used in meteorology and climatology.<br>Hyperspectral imaging produces an image where each pixel has full spectral information with imaging narrow spectral bands over a contiguous spectral range. Hyperspectral imagers are used in various applications including mineralogy, biology, defence, and environmental measurements.<br>Within the scope of the combat against desertification, remote sensing allows researchers to follow up and monitor risk areas in the long term, to determine desertification factors, to support decision-makers in defining relevant measures of environmental management, and to assess their impacts.[21]<br>Remotely sensed multi- and hyperspectral images can be used for assessing biodiversity at different scales. Since the spectral properties of different plants species are unique, it is possible to get information about properties that relates to biodiversity such as habitat heterogeneity, spectral diversity and plant functional trait.[22][23][24]<br>Remote sensing has been used to detect rare plants to aid in conservation efforts. Prediction, detection, and the ability to record biophysical conditions were possible from medium to very high resolutions.[25]<br>Agricultural and environmental statistics, usually combining classified satellite images with ground truth data collected on a sample selected on an area sampling frame[26]<br>Geodetic[edit]<br>Further information: Satellite geodesy<br>Geodetic remote sensing can be gravimetric or geometric. Overhead gravity data collection was first used in aerial submarine detection. This data revealed minute perturbations in the Earth's gravitational field that may be used to determine changes in the mass distribution of the Earth, which in turn may be used for geophysical studies, as in GRACE. Geometric remote sensing includes position and deformation imaging using InSAR, LIDAR, etc.[27]<br>Acoustic and near-acoustic[edit]<br>Sonar: passive sonar, listening for the sound made by another object (a vessel, a whale etc.); active sonar, emitting pulses of sounds and listening for echoes, used for detecting, ranging and measurements of underwater objects and terrain.<br>Seismograms taken at different locations can locate and measure earthquakes (after they occur) by comparing the relative intensity and precise timings.<br>Ultrasound: Ultrasound sensors, that emit high-frequency pulses and listening for echoes, used for detecting water waves and water level, as in tide gauges or for towing tanks.<br>To coordinate a series of large-scale observations, most sensing systems depend on the following: platform location and the orientation of the sensor. High-end instruments now often use positional information from satellite navigation systems. The rotation and orientation are often provided within a degree or two with electronic compasses. Compasses can measure not just azimuth (i. e. degrees to magnetic north), but also altitude (degrees above the horizon), since the magnetic field curves into the Earth at different angles at different latitudes. More exact orientations require gyroscopic-aided orientation, periodically realigned by different methods including navigation from stars or known benchmarks.<br><br>Data characteristics[edit]<br>The quality of remote sensing data consists of its spatial, spectral, radiometric and temporal resolutions.<br><br>Spatial resolution<br>The size of a pixel that is recorded in a raster image – typically pixels may correspond to square areas ranging in side length from 1 to 1,000 metres (3.3 to 3,280.8 ft).<br>Spectral resolution<br>The wavelength of the different frequency bands recorded – usually, this is related to the number of frequency bands recorded by the platform. Current Landsat collection is that of seven bands, including several in the infrared spectrum, ranging from a spectral resolution of 0.7 to 2.1 μm. The Hyperion sensor on Earth Observing-1 resolves 220 bands from 0.4 to 2.5 μm, with a spectral resolution of 0.10 to 0.11 μm per band.<br>Radiometric resolution<br>The number of different intensities of radiation the sensor is able to distinguish. Typically, this ranges from 8 to 14 bits, corresponding to 256 levels of the gray scale and up to 16,384 intensities or "shades" of colour, in each band. It also depends on the instrument noise.<br>Temporal resolution<br>The frequency of flyovers by the satellite or plane, and is only relevant in time-series studies or those requiring an averaged or mosaic image as in deforesting monitoring. This was first used by the intelligence community where repeated coverage revealed changes in infrastructure, the deployment of units or the modification/introduction of equipment. Cloud cover over a given area or object makes it necessary to repeat the collection of said location.<br>Data processing[edit]<br>In order to create sensor-based maps, most remote sensing systems expect to extrapolate sensor data in relation to a reference point including distances between known points on the ground. This depends on the type of sensor used. For example, in conventional photographs, distances are accurate in the center of the image, with the distortion of measurements increasing the farther you get from the center. Another factor is that of the platen against which the film is pressed can cause severe errors when photographs are used to measure ground distances. The step in which this problem is resolved is called georeferencing and involves computer-aided matching of points in the image (typically 30 or more points per image) which is extrapolated with the use of an established benchmark, "warping" the image to produce accurate spatial data. As of the early 1990s, most satellite images are sold fully georeferenced.<br>In addition, images may need to be radiometrically and atmospherically corrected.<br><br>Radiometric correction<br>Allows avoidance of radiometric errors and distortions. The illumination of objects on the Earth's surface is uneven because of different properties of the relief. This factor is taken into account in the method of radiometric distortion correction.[28] Radiometric correction gives a scale to the pixel values, e. g. the monochromatic scale of 0 to 255 will be converted to actual radiance values.<br>Topographic correction (also called terrain correction)<br>In rugged mountains, as a result of terrain, the effective illumination of pixels varies considerably. In a remote sensing image, the pixel on the shady slope receives weak illumination and has a low radiance value, in contrast, the pixel on the sunny slope receives strong illumination and has a high radiance value. For the same object, the pixel radiance value on the shady slope will be different from that on the sunny slope. Additionally, different objects may have similar radiance values. These ambiguities seriously affected remote sensing image information extraction accuracy in mountainous areas. It became the main obstacle to the further application of remote sensing images. The purpose of topographic correction is to eliminate this effect, recovering the true reflectivity or radiance of objects in horizontal conditions. It is the premise of quantitative remote sensing application.<br>Atmospheric correction<br>Elimination of atmospheric haze by rescaling each frequency band so that its minimum value (usually realised in water bodies) corresponds to a pixel value of 0. The digitizing of data also makes it possible to manipulate the data by changing gray-scale values.<br>Interpretation is the critical process of making sense of the data. The first application was that of aerial photographic collection which used the following process; spatial measurement through the use of a light table in both conventional single or stereographic coverage, added skills such as the use of photogrammetry, the use of photomosaics, repeat coverage, Making use of objects' known dimensions in order to detect modifications. Image Analysis is the recently developed automated computer-aided application that is in increasing use.<br>Object-Based Image Analysis (OBIA) is a sub-discipline of GIScience devoted to partitioning remote sensing (RS) imagery into meaningful image-objects, and assessing their characteristics through spatial, spectral and temporal scale.<br>Old data from remote sensing is often valuable because it may provide the only long-term data for a large extent of geography. At the same time, the data is often complex to interpret, and bulky to store. Modern systems tend to store the data digitally, often with lossless compression. The difficulty with this approach is that the data is fragile, the format may be archaic, and the data may be easy to falsify. One of the best systems for archiving data series is as computer-generated machine-readable ultrafiche, usually in typefonts such as OCR-B, or as digitized half-tone images. Ultrafiches survive well in standard libraries, with lifetimes of several centuries. They can be created, copied, filed and retrieved by automated systems. They are about as compact as archival magnetic media, and yet can be read by human beings with minimal, standardized equipment.


## Ground Truth

### GROUND TRUTH 0, ranked 0, continental_drift/Satellite_laser_ranging4.txt
> ReadEditView history<br><br><br><br><br><br>		General<br>	<br><br><br>What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR codeWikidata item<br><br><br><br><br><br>		Print/export<br>	<br><br><br>Download as PDFPrintable version<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>From Wikipedia, the free encyclopedia<br><br><br>This article is about the up-looking type of satellite laser. For the down-looking type, see Satellite laser altimetry.<br>This article includes a list of general references, but it lacks sufficient corresponding inline citations. Please help to improve this article by introducing more precise citations. (November 2020) (Learn how and when to remove this template message)<br>Laser Ranging System of the geodetic observatory Wettzell, Bavaria<br>In  satellite laser ranging  (SLR) a global network of observation stations measures the round trip time of flight of ultrashort pulses of light to satellites equipped with retroreflectors. This provides instantaneous range measurements of millimeter level precision which can be accumulated to provide accurate measurement of orbits and a host of important scientific data. The laser pulse can also be reflected by the surface of a satellite without a retroreflector, which is used for tracking space debris.[1]<br>Satellite laser ranging is a proven geodetic technique with significant potential for important contributions to scientific studies of the earth/atmosphere/ocean system. It is the most accurate technique currently available to determine the geocentric position of an Earth satellite, allowing for the precise calibration of radar altimeters and separation of long-term instrumentation drift from secular changes in ocean topography.<br>Its ability to measure the variations over time in Earth's gravity field and to monitor motion of the station network with respect to the geocenter, together with the capability to monitor vertical motion in an absolute system, makes it unique for modeling and evaluating long-term climate change by:[2]<br><br>providing a reference system for post-glacial rebound, plate tectonics, sea level and ice volume change[3]<br>determining the temporal mass redistribution of the solid earth, ocean, and atmosphere system[4]<br>determining Earth orientation parameters, such as Earth pole coordinates and length-of-day variations[5]<br>determining of precise satellite orbits for artificial satellites with and without active devices onboard[6][7]<br>monitoring the response of the atmosphere to seasonal variations in solar heating.[8]<br>SLR provides a unique capability for verification of the predictions of the theory of general relativity, such as the frame-dragging effect.<br>SLR stations form an important part of the international network of space geodetic observatories, which include VLBI, GPS, DORIS and PRARE systems. On several critical missions, SLR has provided failsafe redundancy when other radiometric tracking systems have failed.<br><br><br>History[edit]<br>Satellite Laser Ranging<br>Laser ranging to a near-Earth satellite was first carried out by NASA in 1964 with the launch of the Beacon-B satellite. Since that time, ranging precision, spurred by scientific requirements, has improved by a factor of a thousand from a few metres to a few millimetres, and more satellites equipped with retroreflectors have been launched.<br>Several sets of retroreflectors were installed on Earth's Moon as part of the American Apollo and Soviet Lunokhod space programs. These retroreflectors are also ranged on a regular basis (lunar laser ranging), providing a highly accurate measurement of the dynamics of the Earth/Moon system.<br>During the subsequent decades, the global satellite laser ranging network has evolved into a powerful source of data for studies of the solid Earth and its ocean and atmospheric systems. In addition, SLR provides precise orbit determination for spaceborne radar altimeter missions mapping the ocean surface (which are used to model global ocean circulation), for<br>mapping volumetric changes in continental ice masses, and for land topography. It provides a means for subnanosecond global time transfer, and a basis for special tests of the Theory of General Relativity.<br>The International Laser Ranging Service was formed in 1998[9] by the global SLR community to enhance  geophysical and geodetic research activities, replacing the previous CSTG Satellite and Laser Ranging Subcommission.<br><br>Applications[edit]<br>SLR data has provided the standard, highly accurate, long wavelength gravity field reference model which supports all precision orbit determination and provides the basis for studying temporal gravitational variations due to mass redistribution. The height of the geoid has been determined to less than ten centimeters at long wavelengths less than 1,500 km.<br>SLR provides mm/year accurate determinations of tectonic drift station motion on a global scale in a geocentric reference frame. Combined with gravity models and decadal changes in Earth rotation, these results contribute to modeling of convection in the Earth's mantle by providing constraints on related Earth interior processes. The velocity of the fiducial station in Hawaii is 70 mm/year and closely matches the rate of the background geophysical model.<br><br>List of satellites[edit]<br>List of passive satellites[edit]<br>For broader coverage of this topic, see List of passive satellites.<br>Several dedicated laser ranging satellites were put in orbit:[10]<br><br>Ajisai (Experimental Geodetic Payload)[11]<br>BLITS[4]<br>Calsphere satellites[12]<br>Etalon[13]<br>Kosmos 1989<br>Kosmos 2024<br>LAGEOS[14]<br>LAGEOS 1<br>LAGEOS 2, see STS-52<br>LARES[15]<br>LARES 1<br>LARES 2<br>Larets[16][17]<br>STARSHINE<br>Starshine 1,[18] see STS-96<br>Starshine 2, see STS-108<br>Starlette and Stella[19]<br>List of shared satellites[edit]<br>Several satellites carried laser retroreflectors, sharing the bus with other instruments:<br><br>Beacon Explorers (Beacon Explorer-B and Beacon Explorer-C)[20]<br>GEOS (GEOS-1, GEOS-2, GEOS-3)[20]<br>Diadème (satellites) [fr][20]<br>PEOLE [fr][20]<br>CHAMP<br>GRACE<br>GOCE[21]<br>Navigation satellites<br>GLONASS[22]<br>GPS (two experimental satellites[23])<br>Galileo[24]<br>BeiDou[25]<br>NavIC[26]<br>QZSS[27]<br>Altimeter satellites<br>GEOS-3<br>TOPEX/Poseidon<br>Sentinel-3[28]<br>SARAL[29]<br>See also[edit]

### GROUND TRUTH 1, ranked 27, continental_drift/Global_Positioning_System3.txt
> {\displaystyle \left({\tilde {t}}_{i}-b-s_{i}\right)c}<br><br>.<br>For n satellites, the equations to satisfy are:<br><br><br><br><br><br><br>d<br><br>i<br><br><br>=<br><br>(<br><br><br><br><br><br>t<br>~<br><br><br><br><br>i<br><br><br>−<br>b<br>−<br><br>s<br><br>i<br><br><br><br>)<br><br>c<br>,<br><br>i<br>=<br>1<br>,<br>2<br>,<br>…<br>,<br>n<br><br><br>{\displaystyle d_{i}=\left({\tilde {t}}_{i}-b-s_{i}\right)c,\;i=1,2,\dots ,n}<br><br><br>where di is the geometric distance or range between receiver and satellite i (the values without subscripts are the x, y, and z components of receiver position):<br><br><br><br><br><br><br>d<br><br>i<br><br><br>=<br><br><br>(<br>x<br>−<br><br>x<br><br>i<br><br><br><br>)<br><br>2<br><br><br>+<br>(<br>y<br>−<br><br>y<br><br>i<br><br><br><br>)<br><br>2<br><br><br>+<br>(<br>z<br>−<br><br>z<br><br>i<br><br><br><br>)<br><br>2<br><br><br><br><br><br><br>{\displaystyle d_{i}={\sqrt {(x-x_{i})^{2}+(y-y_{i})^{2}+(z-z_{i})^{2}}}}<br><br><br>Defining pseudoranges as <br><br><br><br><br>p<br><br>i<br><br><br>=<br><br>(<br><br><br><br><br><br>t<br>~<br><br><br><br><br>i<br><br><br>−<br><br>s<br><br>i<br><br><br><br>)<br><br>c<br><br><br>{\displaystyle p_{i}=\left({\tilde {t}}_{i}-s_{i}\right)c}<br><br>, we see they are biased versions of the true range:<br><br><br><br><br><br><br>p<br><br>i<br><br><br>=<br><br>d<br><br>i<br><br><br>+<br>b<br>c<br>,<br><br>i<br>=<br>1<br>,<br>2<br>,<br>.<br>.<br>.<br>,<br>n<br><br><br>{\displaystyle p_{i}=d_{i}+bc,\;i=1,2,...,n}<br><br> .[169][170]<br>Since the equations have four unknowns [x, y, z, b]—the three components of GPS receiver position and the clock bias—signals from at least four satellites are necessary to attempt solving these equations. They can be solved by algebraic or numerical methods. Existence and uniqueness of GPS solutions are discussed by Abell and Chaffee.[74] When n is greater than four, this system is overdetermined and a fitting method must be used.<br>The amount of error in the results varies with the received satellites' locations in the sky, since certain configurations (when the received satellites are close together in the sky) cause larger errors.  Receivers usually calculate a running estimate of the error in the calculated position. This is done by multiplying the basic resolution of the receiver by quantities called the geometric dilution of position (GDOP) factors, calculated from the relative sky directions of the satellites used.[171] The receiver location is expressed in a specific coordinate system, such as latitude and longitude using the WGS 84 geodetic datum or a country-specific system.[172]<br><br>Geometric interpretation[edit]<br>The GPS equations can be solved by numerical and analytical methods. Geometrical interpretations can enhance the understanding of these solution methods.<br><br>Spheres[edit]<br>2-D Cartesian true-range multilateration (trilateration) scenario<br>The measured ranges, called pseudoranges, contain clock errors. In a simplified idealization in which the ranges are synchronized, these true ranges represent the radii of spheres, each centered on one of the transmitting satellites. The solution for the position of the receiver is then at the intersection of the surfaces of these spheres; see trilateration (more generally, true-range multilateration). Signals from at minimum three satellites are required, and their three spheres would typically intersect at two points.[173] One of the points is the location of the receiver, and the other moves rapidly in successive measurements and would not usually be on Earth's surface.<br>In practice, there are many sources of inaccuracy besides clock bias, including random errors as well as the potential for precision loss from subtracting numbers close to each other if the centers of the spheres are relatively close together. This means that the position calculated from three satellites alone is unlikely to be accurate enough. Data from more satellites can help because of the tendency for random errors to cancel out and also by giving a larger spread between the sphere centers. But at the same time, more spheres will not generally intersect at one point. Therefore, a near intersection gets computed, typically via least squares. The more signals available, the better the approximation is likely to be.<br><br>Hyperboloids[edit]<br>Three satellites (labeled as "stations" A, B, C) have known locations. The true times it takes for a radio signal to travel from each satellite to the receiver are unknown, but the true time differences are known. Then, each time difference locates the receiver on a branch of a hyperbola focused on the satellites. The receiver is then located at one of the two intersections.<br>If the pseudorange between the receiver and satellite i and the pseudorange between the receiver and satellite j are subtracted, pi − pj, the common receiver clock bias (b) cancels out, resulting in a difference of distances di − dj. The locus of points having a constant difference in distance to two points (here, two satellites) is a hyperbola on a plane and a hyperboloid of revolution (more specifically, a two-sheeted hyperboloid) in 3D space (see Multilateration). Thus, from four pseudorange measurements, the receiver can be placed at the intersection of the surfaces of three hyperboloids each with foci at a pair of satellites. With additional satellites, the multiple intersections are not necessarily unique, and a best-fitting solution is sought instead.[74][75][174][175][176][177]<br><br>Inscribed sphere[edit]<br>A smaller circle (red) inscribed and tangent to other circles (black), that need not necessarily be mutually tangent<br>The receiver position can be interpreted as the center of an inscribed sphere (insphere) of radius bc, given by the receiver clock bias b (scaled by the speed of light c). The insphere location is such that it touches other spheres. The circumscribing spheres are centered at the GPS satellites, whose radii equal the measured pseudoranges pi. This configuration is distinct from the one described above, in which the spheres' radii were the unbiased or geometric ranges di.[176]: 36–37 [178]<br><br>Hypercones[edit]<br>The clock in the receiver is usually not of the same quality as the ones in the satellites and will not be accurately synchronized to them. This produces pseudoranges with large differences compared to the true distances to the satellites. Therefore, in practice, the time difference between the receiver clock and the satellite time is defined as an unknown clock bias b. The equations are then solved simultaneously for the receiver position and the clock bias.  The solution space [x, y, z, b] can be seen as a four-dimensional spacetime, and signals from at minimum four satellites are needed. In that case each of the equations describes a hypercone (or spherical cone),[179] with the cusp located at the satellite, and the base a sphere around the satellite. The receiver is at the intersection of four or more of such hypercones.<br><br>Solution methods[edit]<br>Least squares[edit]<br>When more than four satellites are available, the calculation can use the four best, or more than four simultaneously (up to all visible satellites), depending on the number of receiver channels, processing capability, and geometric dilution of precision (GDOP).<br>Using more than four involves an over-determined system of equations with no unique solution; such a system can be solved by a least-squares or weighted least squares method.[169]<br><br><br><br><br><br><br>(<br><br><br><br><br>x<br>^<br><br><br><br>,<br><br><br><br>y<br>^<br><br><br><br>,<br><br><br><br>z<br>^<br><br><br><br>,<br><br><br><br>b<br>^<br><br><br><br><br>)<br><br>=<br><br><br><br>arg<br>⁡<br>min<br><br><br>(<br><br>x<br>,<br>y<br>,<br>z<br>,<br>b<br><br>)<br><br><br><br><br>∑<br><br>i<br><br><br><br><br>(<br><br><br><br>(<br>x<br>−<br><br>x<br><br>i<br><br><br><br>)<br><br>2<br><br><br>+<br>(<br>y<br>−<br><br>y<br><br>i<br><br><br><br>)<br><br>2<br><br><br>+<br>(<br>z<br>−<br><br>z<br><br>i<br><br><br><br>)<br><br>2<br><br><br><br><br>+<br>b<br>c<br>−<br><br>p<br><br>i<br><br><br><br>)<br><br><br>2<br><br><br><br><br>{\displaystyle \left({\hat {x}},{\hat {y}},{\hat {z}},{\hat {b}}\right)={\underset {\left(x,y,z,b\right)}{\arg \min }}\sum _{i}\left({\sqrt {(x-x_{i})^{2}+(y-y_{i})^{2}+(z-z_{i})^{2}}}+bc-p_{i}\right)^{2}}<br><br><br>Iterative[edit]<br>Both the equations for four satellites, or the least squares equations for more than four, are non-linear and need special solution methods. A common approach is by iteration on a linearized form of the equations, such as the Gauss–Newton algorithm.<br>The GPS was initially developed assuming use of a numerical least-squares solution method—i.e., before closed-form solutions were found.<br><br>Closed-form[edit]<br>One closed-form solution to the above set of equations was developed by S. Bancroft.[170][180] Its properties are well known;[74][75][181] in particular, proponents claim it is superior in low-GDOP situations, compared to iterative least squares methods.[180]<br>Bancroft's method is algebraic, as opposed to numerical, and can be used for four or more satellites. When four satellites are used, the key steps are inversion of a 4x4 matrix and solution of a single-variable quadratic equation. Bancroft's method provides one or two solutions for the unknown quantities. When there are two (usually the case), only one is a near-Earth sensible solution.[170]<br>When a receiver uses more than four satellites for a solution, Bancroft uses the generalized inverse (i.e., the pseudoinverse) to find a solution. A case has been made that iterative methods, such as the Gauss–Newton algorithm approach for solving over-determined non-linear least squares problems, generally provide more accurate solutions.[182]<br>Leick et al. (2015) states that "Bancroft's (1985) solution is a very early, if not the first, closed-form solution."[183]<br>Other closed-form solutions were published afterwards,[184][185] although their adoption in practice is unclear.<br><br>Error sources and analysis[edit]<br>Main article: Error analysis for the Global Positioning System<br>GPS error analysis examines error sources in GPS results and the expected size of those errors. GPS makes corrections for receiver clock errors and other effects, but some residual errors remain uncorrected. Error sources include signal arrival time measurements, numerical calculations, atmospheric effects (ionospheric/tropospheric delays), ephemeris and clock data, multipath signals, and natural and artificial interference. Magnitude of residual errors from these sources depends on geometric dilution of precision. Artificial errors may result from jamming devices and threaten ships and aircraft[186] or from intentional signal degradation through selective availability, which limited accuracy to ≈ 6–12 m (20–40 ft), but has been switched off since May 1, 2000.[187][188]<br><br>Accuracy enhancement and surveying[edit]<br>This section is an excerpt from GNSS enhancement.[edit]<br>This article needs attention from an expert in Geography. The specific problem is: possibly duplicate references to the same phase stuff, esp. between RTK and carrier-phase tracking. WikiProject Geography may be able to help recruit an expert. (March 2020)<br>GNSS enhancement refers to techniques used to improve the accuracy of positioning information provided by the Global Positioning System or other global navigation satellite systems in general, a network of satellites used for navigation.<br><br>Enhancement methods of improving accuracy rely on external information being integrated into the calculation process. There are many such systems in place and they are generally named or described based on how the GPS sensor receives the information. Some systems transmit additional information about sources of error (such as clock drift, ephemeris, or ionospheric delay), others provide direct measurements of how much the signal was off in the past, while a third group provides additional navigational or vehicle information to be integrated into the calculation process.<br>Regulatory spectrum issues concerning GPS receivers[edit]<br>In the United States, GPS receivers are regulated under the Federal Communications Commission's (FCC) Part 15 rules. As indicated in the manuals of GPS-enabled devices sold in the United States, as a Part 15 device, it "must accept any interference received, including interference that may cause undesired operation".[189] With respect to GPS devices in particular, the FCC states that GPS receiver manufacturers "must use receivers that reasonably discriminate against reception of signals outside their allocated spectrum".[190] For the last 30 years, GPS receivers have operated next to the Mobile Satellite Service band, and have discriminated against reception of mobile satellite services, such as Inmarsat, without any issue.<br>The spectrum allocated for GPS L1 use by the FCC is 1559 to 1610 MHz, while the spectrum allocated for satellite-to-ground use owned by Lightsquared is the Mobile Satellite Service band.[191] Since 1996, the FCC has authorized licensed use of the spectrum neighboring the GPS band of 1525 to 1559 MHz to the Virginia company LightSquared. On March 1, 2001, the FCC received an application from LightSquared's predecessor, Motient Services, to use their allocated frequencies for an integrated satellite-terrestrial service.[192] In 2002, the U.S. GPS Industry Council came to an out-of-band-emissions (OOBE) agreement with LightSquared to prevent transmissions from LightSquared's ground-based stations from emitting transmissions into the neighboring GPS band of 1559 to 1610 MHz.[193] In 2004, the FCC adopted the OOBE agreement in its authorization for LightSquared to deploy a ground-based network ancillary to their satellite system – known as the Ancillary Tower Components (ATCs) – "We will authorize MSS ATC subject to conditions that ensure that the added terrestrial component remains ancillary to the principal MSS offering. We do not intend, nor will we permit, the terrestrial component to become a stand-alone service."[194] This authorization was reviewed and approved by the U.S. Interdepartment Radio Advisory Committee, which includes the U.S. Department of Agriculture, U.S. Space Force, U.S. Army, U.S. Coast Guard, Federal Aviation Administration, National Aeronautics and Space Administration (NASA), U.S. Department of the Interior, and U.S. Department of Transportation.[195]<br>In January 2011, the FCC conditionally authorized LightSquared's wholesale customers—such as Best Buy, Sharp, and C Spire—to only purchase an integrated satellite-ground-based service from LightSquared and re-sell that integrated service on devices that are equipped to only use the ground-based signal using LightSquared's allocated frequencies of 1525 to 1559 MHz.[196] In December 2010, GPS receiver manufacturers expressed concerns to the FCC that LightSquared's signal would interfere with GPS receiver devices[164] although the FCC's policy considerations leading up to the January 2011 order did not pertain to any proposed changes to the maximum number of ground-based LightSquared stations or the maximum power at which these stations could operate. The January 2011 order makes final authorization contingent upon studies of GPS interference issues carried out by a LightSquared led working group along with GPS industry and Federal agency participation. On February 14, 2012, the FCC initiated proceedings to vacate LightSquared's Conditional Waiver Order based on the NTIA's conclusion that there was currently no practical way to mitigate potential GPS interference.<br>GPS receiver manufacturers design GPS receivers to use spectrum beyond the GPS-allocated band. In some cases, GPS receivers are designed to use up to 400 MHz of spectrum in either direction of the L1 frequency of 1575.42 MHz, because mobile satellite services in those regions are broadcasting from space to ground, and at power levels commensurate with mobile satellite services.[197] As regulated under the FCC's Part 15 rules, GPS receivers are not warranted protection from signals outside GPS-allocated spectrum.[190] This is why GPS operates next to the Mobile Satellite Service band, and also why the Mobile Satellite Service band operates next to GPS. The symbiotic relationship of spectrum allocation ensures that users of both bands are able to operate cooperatively and freely.<br>The FCC adopted rules in February 2003 that allowed Mobile Satellite Service (MSS) licensees such as LightSquared to construct a small number of ancillary ground-based towers in their licensed spectrum to "promote more efficient use of terrestrial wireless spectrum".[198] In those 2003 rules, the FCC stated: "As a preliminary matter, terrestrial [Commercial Mobile Radio Service ('CMRS')] and MSS ATC are expected to have different prices, coverage, product acceptance and distribution; therefore, the two services appear, at best, to be imperfect substitutes for one another that would be operating in predominantly different market segments ... MSS ATC is unlikely to compete directly with terrestrial CMRS for the same customer base...". In 2004, the FCC clarified that the ground-based towers would be ancillary, noting: "We will authorize MSS ATC subject to conditions that ensure that the added terrestrial component remains ancillary to the principal MSS offering. We do not intend, nor will we permit, the terrestrial component to become a stand-alone service."[194] In July 2010, the FCC stated that it expected LightSquared to use its authority to offer an integrated satellite-terrestrial service to "provide mobile broadband services similar to those provided by terrestrial mobile providers and enhance competition in the mobile broadband sector".[199] GPS receiver manufacturers have argued that LightSquared's licensed spectrum of 1525 to 1559 MHz was never envisioned as being used for high-speed wireless broadband based on the 2003 and 2004 FCC ATC rulings making clear that the Ancillary Tower Component (ATC) would be, in fact, ancillary to the primary satellite component.[200] To build public support of efforts to continue the 2004 FCC authorization of LightSquared's ancillary terrestrial component vs. a simple ground-based LTE service in the Mobile Satellite Service band, GPS receiver manufacturer Trimble Navigation Ltd. formed the "Coalition To Save Our GPS".[201]<br>The FCC and LightSquared have each made public commitments to solve the GPS interference issue before the network is allowed to operate.[202][203] According to Chris Dancy of the Aircraft Owners and Pilots Association, airline pilots with the type of systems that would be affected "may go off course and not even realize it".[204] The problems could also affect the Federal Aviation Administration upgrade to the air traffic control system, United States Defense Department guidance, and local emergency services including 911.[204]<br>On February 14, 2012, the FCC moved to bar LightSquared's planned national broadband network after being informed by the National Telecommunications and Information Administration (NTIA), the federal agency that coordinates spectrum uses for the military and other federal government entities, that "there is no practical way to mitigate potential interference at this time".[205][206] LightSquared is challenging the FCC's action.[needs update]<br><br>Similar systems[edit]<br>Main article: Satellite navigation<br>Orbit size comparison of GPS, GLONASS, Galileo, BeiDou-2, and Iridium constellations, the International Space Station, the Hubble Space Telescope, and geostationary orbit (and its graveyard orbit), with the Van Allen radiation belts and the Earth to scale.[b]  The Moon's orbit is around 9 times as large as geostationary orbit.[c] (In the SVG file, hover over an orbit or its label to highlight it; click to load its article.)<br>Following the United States' deployment of GPS, other countries have also developed their own satellite navigation systems. These systems include:<br><br>The Russian Global Navigation Satellite System (GLONASS) was developed at the same time as GPS, but suffered from incomplete coverage of the globe until the mid-2000s.[207] GLONASS reception in addition to GPS can be combined in a receiver thereby allowing for additional satellites available to enable faster position fixes and improved accuracy, to within two meters (6.6 ft).[208][209]<br>China's BeiDou Navigation Satellite System began global services in 2018 and finished its full deployment in 2020.[210]<br>The Galileo navigation satellite system, a global system being developed by the European Union and other partner countries, began operation in 2016,[211] and is expected to be fully deployed by 2020.[needs update]<br>Japan's Quasi-Zenith Satellite System (QZSS) is a GPS satellite-based augmentation system to enhance GPS's accuracy in Asia-Oceania, with satellite navigation independent of GPS scheduled for 2023.[212]<br>The Indian Regional Navigation Satellite System, deployed by India.<br>See also[edit]<br><br>List of GPS satellites<br>GPS satellite blocks<br>GPS signals<br>Satellite navigation software<br>GPS/INS<br>GPS spoofing<br>Indoor positioning system<br>Local-area augmentation system<br>Local positioning system<br>Military invention<br>Mobile phone tracking<br>Navigation paradox<br>Notice Advisory to Navstar Users<br>S-GPS<br>Geostationary balloon satellite<br><br>Portals: Spaceflight Geography Maps United States World<br>Notes[edit]<br><br><br>^ In fact, the ship is unlikely to be at precisely 0m, because of tides and other factors which create a discrepancy between mean sea level and actual sea level. In the open ocean, high and low tide typically only differ by about 0.6m, but there are locations closer to land where they can differ by over 15m. See tidal range for more details and references.<br><br>^ Orbital periods and speeds are calculated using the relations 4π2R3 = T2GM and V2R = GM, where R is the radius of orbit in metres; T is the orbital period in seconds; V is the orbital speed in m/s; G is the gravitational constant, approximately 6.673×10−11 Nm2/kg2; M is the mass of Earth, approximately 5.98×1024 kg (1.318×1025 lb).<br><br>^ Approximately 8.6 times (in radius and length) when the Moon is nearest (that is, 363,104 km/42,164 km), to 9.6 times when the Moon is farthest (that is, 405,696 km/42,164 km).<br><br><br>References[edit]<br><br><br>^ a b "Fiscal Year 2023 Program Funding". April 27, 2022. Retrieved September 24, 2023.<br><br>^ United States Department of Transportation; Federal Aviation Administration (October 31, 2008). "Global Positioning System Wide Area Augmentation System (WAAS) Performance Standard" (PDF). p. B-3. Archived (PDF) from the original on April 27, 2017. Retrieved January 3, 2012.<br><br>^ United States Department of Defense (September 2008). "Global Positioning System Standard Positioning Service Performance Standard - 4th Edition" (PDF). Archived (PDF) from the original on April 27, 2017. Retrieved April 21, 2017.<br><br>^ Science Reference Section (November 19, 2019). "What is a GPS? How does it work?". Everyday Mysteries. Library of Congress. Archived from the original on April 12, 2022. Retrieved April 12, 2022.<br><br>^ National Coordination Office for Space-Based Positioning, Navigation, and Timing (February 22, 2021). "What is GPS?". Archived from the original on May 6, 2021. Retrieved May 5, 2021.<br><br>^ McDuffie, Juquai (June 19, 2017). "Why the Military Released GPS to the Public". Popular Mechanics. Archived from the original on January 28, 2020. Retrieved February 1, 2020.<br><br>^ a b "Factsheets: GPS Advanced Control Segment (OCX)". Losangeles.af.mil. October 25, 2011. Archived from the original on May 3, 2012. Retrieved November 6, 2011.<br><br>^ Srivastava, Ishan (April 5, 2014). "How Kargil spurred India to design own GPS". The Times of India. Archived from the original on December 15, 2016. Retrieved December 9, 2014.<br><br>^ a b c National Coordination Office for Space-Based Positioning, Navigation, and Timing (March 3, 2022). "GPS Accuracy". GPS.gov. Archived from the original on April 12, 2022. Retrieved April 12, 2022.<br><br>^ Kastrenakes, Jacob (September 25, 2017). "GPS will be accurate within one foot in some phones next year". The Verge. Archived from the original on January 18, 2018. Retrieved January 17, 2018.<br><br>^ Moore, Samuel K. (September 21, 2017). "Superaccurate GPS Chips Coming to Smartphones in 2018". IEEE Spectrum. Archived from the original on January 18, 2018. Retrieved January 17, 2018.<br><br>^ "How Do You Measure Your Location Using GPS?". NIST. National Institute of Standards and Technology. March 17, 2021. Retrieved March 7, 2022.<br><br>^ "New Civil Signals". GPS.gov. Retrieved November 22, 2023.<br><br>^ National Research Council (U.S.). Committee on the Future of the Global Positioning System; National Academy of Public Administration (1995). The global positioning system: a shared national asset: recommendations for technical improvements and enhancements. National Academies Press. p. 16. ISBN 978-0-309-05283-2. Retrieved August 16, 2013.<br><br>^ Ann Darrin; Beth L. O'Leary (June 26, 2009). Handbook of Space Engineering, Archaeology, and Heritage. CRC Press. pp. 239–240. ISBN 978-1-4200-8432-0. Archived from the original on August 14, 2021. Retrieved July 28, 2021.<br><br>^ Butterly, Amelia (May 20, 2018). "100 Women: Gladys West - the 'hidden figure' of GPS". BBC News. Archived from the original on February 13, 2019. Retrieved January 17, 2019.<br><br>^ Mohdin, Aamna (November 19, 2020). "Gladys West: the hidden figure who helped invent GPS". The Guardian. ISSN 0261-3077. Retrieved November 29, 2023.<br><br>^ Relativistische Zeitdilatation eines künstlichen Satelliten (Relativistic time dilation of an artificial satellite. Astronautica Acta II (in German) (25). Retrieved October 19, 2014. Archived from the original on July 3, 2014. Retrieved October 20, 2014.<br><br>^ Guier, William H.; Weiffenbach, George C. (1997). "Genesis of Satellite Navigation" (PDF). Johns Hopkins APL Technical Digest. 19 (1): 178–181. Archived from the original (PDF) on May 12, 2012. Retrieved April 9, 2012.<br><br>^ Steven Johnson (2010), Where good ideas come from, the natural history of innovation, New York: Riverhead Books<br><br>^ Helen E. Worth; Mame Warren (2009). Transit to Tomorrow. Fifty Years of Space Research at The Johns Hopkins University Applied Physics Laboratory (PDF). Archived (PDF) from the original on December 26, 2020. Retrieved March 3, 2013.<br><br>^ a b Catherine Alexandrow (April 2008). "The Story of GPS". Archived from the original on February 24, 2013.<br><br>^ DARPA: 50 Years of Bridging the Gap. April 2008. Archived from the original on May 6, 2011.<br><br>^ Howell, Elizabeth. "Navstar: GPS Satellite Network". SPACE.com. Archived from the original on February 17, 2013. Retrieved February 14, 2013.<br><br>^ Jerry Proc. "Omega". Jproc.ca. Archived from the original on January 5, 2010. Retrieved December 8, 2009.<br><br>^ "Why Did the Department of Defense Develop GPS?". Trimble Navigation Ltd. Archived from the original on October 18, 2007. Retrieved January 13, 2010.<br><br>^ "Charting a Course Toward Global Navigation". The Aerospace Corporation. Archived from the original on November 1, 2002. Retrieved October 14, 2013.<br><br>^ "A Guide to the Global Positioning System (GPS) – GPS Timeline". Radio Shack. Archived from the original on February 13, 2010. Retrieved January 14, 2010.<br><br>^ "Geodetic Explorer – A Press Kit" (PDF). NASA. October 29, 1965. Archived (PDF) from the original on February 11, 2014. Retrieved October 20, 2015.<br><br>^ "SECOR Chronology". Mark Wade's Encyclopedia Astronautica. Archived from the original on January 16, 2010. Retrieved January 19, 2010.<br><br>^ Jury, H L, 1973, Application of Kalman Filter to Real-Time Navigation using Synchronous Satellites, Proceedings of the 10th International Symposium on Space Technology and Science, Tokyo, 945–952.<br><br>^ "MX Deployment Reconsidered". au.af.mil. Archived from the original on June 25, 2017. Retrieved June 7, 2013.<br><br>^ Dick, Steven; Launius, Roger (2007). Societal Impact of Spaceflight (PDF). Washington, DC: US Government Printing Office. p. 331. ISBN 978-0-16-080190-7. Archived (PDF) from the original on March 3, 2013. Retrieved July 20, 2019.<br><br>^ Michael Russell Rip; James M. Hasik (2002). The Precision Revolution: GPS and the Future of Aerial Warfare. Naval Institute Press. p. 65. ISBN 978-1-55750-973-4. Retrieved January 14, 2010.<br><br>^ a b Hegarty, Christopher J.; Chatre, Eric (December 2008). "Evolution of the Global Navigation SatelliteSystem (GNSS)". Proceedings of the IEEE. 96 (12): 1902–1917. doi:10.1109/JPROC.2008.2006090. S2CID 838848.<br><br>^ "ION Fellow - Mr. John A. Klobuchar". www.ion.org. Archived from the original on October 4, 2017. Retrieved June 17, 2017.<br><br>^ "GPS Signal Science". harveycohen.net. Archived from the original on May 29, 2017.<br><br>^ "ICAO Completes Fact-Finding Investigation". International Civil Aviation Organization. Archived from the original on May 17, 2008. Retrieved September 15, 2008.<br><br>^ "United States Updates Global Positioning System Technology". America.gov. February 3, 2006. Archived from the original on October 9, 2013. Retrieved June 17, 2019.<br><br>^ Rumerman, Judy A. (2009). NASA Historical Data Book, Volume VII (PDF). NASA. p. 136. Archived (PDF) from the original on December 25, 2017. Retrieved July 12, 2017.<br><br>^ The Global Positioning System<br>Assessing National Policies, by Scott Pace, Gerald P. Frost, Irving Lachow, David R. Frelinger, Donna Fossum, Don Wassem, Monica M. Pinto, Rand Corporation, 1995,Appendix B Archived March 4, 2016, at the Wayback Machine, GPS History, Chronology, and Budgets<br><br>^ "GPS & Selective Availability Q&A" (PDF). NOAA]. Archived from the original (PDF) on September 21, 2005. Retrieved May 28, 2010.<br><br>^ Steitz, David E. "National Positioning, Navigation and Timing Advisory Board Named". Archived from the original on January 13, 2010. Retrieved March 22, 2007.<br><br>^ GPS Wing Reaches GPS III IBR Milestone Archived May 23, 2013, at the Wayback Machine in Inside GNSS November 10, 2008<br><br>^ "GPS Constellation Status for 08/26/2015". Archived from the original on September 5, 2015. Retrieved August 26, 2015.<br><br>^ "Recap story: Three Atlas 5 launch successes in one month". October 31, 2015. Archived from the original on November 1, 2015. Retrieved October 31, 2015.<br><br>^ "GPS almanacs". Navcen.uscg.gov. Archived from the original on September 23, 2010. Retrieved October 15, 2010.<br><br>^ "Origin of Global Positioning System (GPS)". Rewire Security. Archived from the original on February 11, 2017. Retrieved February 9, 2017.<br><br>^ Dietrich Schroeer; Mirco Elena (2000). Technology Transfer. Ashgate. p. 80. ISBN 978-0-7546-2045-7. Retrieved May 25, 2008.<br><br>^ Michael Russell Rip; James M. Hasik (2002). The Precision Revolution: GPS and the Future of Aerial Warfare. Naval Institute Press. ISBN 978-1-55750-973-4. Retrieved May 25, 2008.<br><br>^ Dore, Richard (September 16, 1979). "Navstar - Global system will provide accurate data for navigation". The Daily Breeze. Torrance, California. p. 91. Archived from the original on May 23, 2023. Retrieved May 23, 2023 – via Newspapers.com.<br><br>^ a b Dore, Richard (September 16, 1979). "Satellite technology key to GPS". The Daily Breeze. Torrance, California. p. 97. Archived from the original on May 23, 2023. Retrieved May 23, 2023 – via Newspapers.com.<br><br>^ "AF Space Command Chronology". USAF Space Command. Archived from the original on August 17, 2011. Retrieved June 20, 2011.<br><br>^ "FactSheet: 2nd Space Operations Squadron". USAF Space Command. Archived from the original on June 11, 2011. Retrieved June 20, 2011.<br><br>^ The Global Positioning System: Assessing National Policies Archived December 30, 2015, at the Wayback Machine, p.245. RAND corporation<br><br>^ a b "USNO NAVSTAR Global Positioning System". U.S. Naval Observatory. Archived from the original on January 26, 2011. Retrieved January 7, 2011.<br><br>^ National Archives and Records Administration. U.S. Global Positioning System Policy Archived April 6, 2006, at the Wayback Machine. March 29, 1996.<br><br>^ "National Executive Committee for Space-Based Positioning, Navigation, and Timing". Pnt.gov. Archived from the original on May 28, 2010. Retrieved October 15, 2010.<br><br>^ "Assisted-GPS Test Calls for 3G WCDMA Networks". 3g.co.uk. November 10, 2004. Archived from the original on November 27, 2010. Retrieved November 24, 2010.<br><br>^ "Press release: First Modernized GPS Satellite Built by Lockheed Martin Launched Successfully by the U.S. Air Force – Sep 26, 2005". Lockheed Martin. Archived from the original on August 10, 2017. Retrieved August 9, 2017.<br><br>^ "losangeles.af.mil". losangeles.af.mil. September 17, 2007. Archived from the original on May 11, 2011. Retrieved October 15, 2010.<br><br>^ Johnson, Bobbie (May 19, 2009). "GPS system 'close to breakdown'". The Guardian. London. Archived from the original on September 26, 2013. Retrieved December 8, 2009.<br><br>^ Coursey, David (May 21, 2009). "Air Force Responds to GPS Outage Concerns". ABC News. Archived from the original on May 23, 2009. Retrieved May 22, 2009.<br><br>^ Elliott, Dan (June 1, 2010). "Air Force GPS Problem: Glitch Shows How Much U.S. Military Relies On GPS". The Huffington Post. Archived from the original on May 11, 2011. Retrieved October 15, 2010.<br><br>^ "Contract Award for Next Generation GPS Control Segment Announced". Los Angeles Air Force Base. February 25, 2010. Archived from the original on July 23, 2013. Retrieved December 14, 2012.<br><br>^ "President announces Roger Easton recipient of National Medal of Technology". EurekAlert!. United States Naval Research Laboratory. November 22, 2005. Archived from the original on October 11, 2007.<br><br>^ "Inducted Technologies / 1998: Global Positioning System (GPS)". Space Technology Hall of Fame. Archived from the original on June 12, 2012.<br><br>^ Williams Jr., Richard A. (October 5, 2011). "GPS Program Receives International Award". GPS.gov. Archived from the original on May 13, 2017. Retrieved December 24, 2018.<br><br>^ "Mathematician inducted into Space and Missiles Pioneers Hall of Fame". Air Force Space Command. December 7, 2018. Archived from the original on June 3, 2019. Retrieved August 3, 2021.<br><br>^ Amos, Jonathan (February 12, 2019). "Queen Elizabeth Prize for Engineering: GPS pioneers lauded". BBC News. Archived from the original on April 6, 2019. Retrieved April 6, 2019.<br><br>^ Nelson, Jon (June 19, 2019). "What Is an Atomic Clock?". NASA. Archived from the original on April 5, 2023. Retrieved April 4, 2023.<br><br>^ "Radio wave | Examples, Uses, Facts, & Range". Britannica. Retrieved April 4, 2023.<br><br>^ "JAXA | Positioning to know your location and time". global.jaxa.jp. Retrieved April 4, 2023.<br><br>^ a b c d Abel, J.S.; Chaffee, J.W. (1991). "Existence and uniqueness of GPS solutions". IEEE Transactions on Aerospace and Electronic Systems. 27 (6). Institute of Electrical and Electronics Engineers (IEEE): 952–956. Bibcode:1991ITAES..27..952A. doi:10.1109/7.104271. ISSN 0018-9251.<br><br>^ a b c Fang, B.T. (1992). "Comments on "Existence and uniqueness of GPS solutions" by J.S. Abel and J.W. Chaffee". IEEE Transactions on Aerospace and Electronic Systems. 28 (4). Institute of Electrical and Electronics Engineers (IEEE): 1163. doi:10.1109/7.165379. ISSN 0018-9251.<br><br>^ Grewal, Mohinder S.; Weill, Lawrence R.; Andrews, Angus P. (2007). Global Positioning Systems, Inertial Navigation, and Integration (2nd ed.). John Wiley & Sons. pp. 92–93. ISBN 978-0-470-09971-1.<br><br>^ Georg zur Bonsen; Daniel Ammann; Michael Ammann; Etienne Favey; Pascal Flammant (April 1, 2005). "Continuous Navigation Combining GPS with Sensor-Based Dead Reckoning". GPS World. Archived from the original on November 11, 2006.<br><br>^ a b "NAVSTAR GPS User Equipment Introduction" (PDF). United States Government. Archived (PDF) from the original on September 10, 2008. Retrieved August 22, 2008. Chapter 7<br><br>^ "GPS Support Notes" (PDF). January 19, 2007. Archived from the original (PDF) on March 27, 2009. Retrieved November 10, 2008.<br><br>^ a b "Global Positioning System". Gps.gov. Archived from the original on July 30, 2010. Retrieved June 26, 2010.<br><br>^ Daly, P. (December 1993). "Navstar GPS and GLONASS: global satellite navigation systems". Electronics & Communication Engineering Journal. 5 (6): 349–357. doi:10.1049/ecej:19930069.<br><br>^ Dana, Peter H. (August 8, 1996). "GPS Orbital Planes". Archived from the original (GIF) on January 26, 2018. Retrieved February 27, 2006.<br><br>^ GPS Overview from the NAVSTAR Joint Program Office Archived November 16, 2007, at the Wayback Machine. Retrieved December 15, 2006.<br><br>^ What the Global Positioning System Tells Us about Relativity Archived January 4, 2007, at the Wayback Machine. Retrieved January 2, 2007.<br><br>^ "The GPS Satellite Constellation". gmat.unsw.edu.au. Archived from the original on October 22, 2011. Retrieved October 27, 2011.<br><br>^ "USCG Navcen: GPS Frequently Asked Questions". Archived from the original on April 30, 2011. Retrieved January 31, 2007.<br><br>^ a b Thomassen, Keith. "How GPS Works". avionicswest.com. Archived from the original on March 30, 2016. Retrieved April 22, 2014.<br><br>^ Samama, Nel (2008). Global Positioning: Technologies and Performance. John Wiley & Sons. p. 65. ISBN 978-0-470-24190-5.,<br><br>^ Agnew, D.C.; Larson, K.M. (2007). "Finding the repeat times of the GPS constellation". GPS Solutions. 11 (1): 71–76. doi:10.1007/s10291-006-0038-4. S2CID 59397640. This article from author's web site Archived February 16, 2008, at the Wayback Machine, with minor correction.<br><br>^ "Space Segment". GPS.gov. Archived from the original on July 18, 2019. Retrieved July 27, 2019.<br><br>^ Massatt, Paul; Wayne Brady (Summer 2002). "Optimizing performance through constellation management" (PDF). Crosslink: 17–21. Archived from the original on January 25, 2012.<br><br>^ United States Coast Guard General GPS News 9–9–05<br><br>^ USNO NAVSTAR Global Positioning System Archived February 8, 2006, at the Wayback Machine. Retrieved May 14, 2006.<br><br>^ "DoD Decision Breathes New Life into Critical OCX Satellite Program". U.S. Department of Defense. Retrieved November 26, 2023.<br><br>^ "GPS.gov: Next Generation Operational Control System (OCX)". www.gps.gov. Retrieved November 26, 2023.<br><br>^ "The USA's GPS-III Satellites". Defense Industry Daily. October 13, 2011. Archived from the original on October 18, 2011. Retrieved October 27, 2011.<br><br>^ "GPS Completes Next Generation Operational Control System PDR". Air Force Space Command News Service. September 14, 2011. Archived from the original on October 2, 2011.<br><br>^ "GLOBAL POSITIONING SYSTEM: Updated Schedule Assessment Could Help Decision Makers Address Likely Delays Related to New Ground Control System" (PDF). US Government Accounting Office. May 2019. Archived (PDF) from the original on September 10, 2019. Retrieved August 24, 2019.<br><br>^ "Raytheon's $7 Billion GPS Stations Are Running 73% Over Estimates". Bloomberg.com. June 21, 2023. Retrieved November 26, 2023.<br><br>^ Albon, Courtney (June 9, 2023). "Space Force sees further delays to 'troubled' GPS ground segment". C4ISRNet. Retrieved November 26, 2023.<br><br>^ Hitchens, Theresa (November 7, 2023). "Next-gen GPS ground system expected to come online this summer: Calvelli". Breaking Defense. Retrieved November 26, 2023.<br><br>^ "Publications and Standards from the National Marine Electronics Association (NMEA)". National Marine Electronics Association. Archived from the original on August 4, 2009. Retrieved June 27, 2008.<br><br>^ Hadas, T.; Krypiak-Gregorczyk, A.; Hernández-Pajares, M.; Kaplon, J.; Paziewski, J.; Wielgosz, P.; Garcia-Rigo, A.; Kazmierski, K.; Sosnica, K.; Kwasniak, D.; Sierny, J.; Bosy, J.; Pucilowski, M.; Szyszko, R.; Portasiak, K.; Olivares-Pulido, G.; Gulyaeva, T.; Orus-Perez, R. (November 2017). "Impact and Implementation of Higher-Order Ionospheric Effects on Precise GNSS Applications: Higher-Order Ionospheric Effects in GNSS". Journal of Geophysical Research: Solid Earth. 122 (11): 9420–9436. doi:10.1002/2017JB014750. hdl:2117/114538. S2CID 54069697.<br><br>^ Sośnica, Krzysztof; Thaller, Daniela; Dach, Rolf; Jäggi, Adrian; Beutler, Gerhard (August 2013). "Impact of loading displacements on SLR-derived parameters and on the consistency between GNSS and SLR results" (PDF). Journal of Geodesy. 87 (8): 751–769. Bibcode:2013JGeod..87..751S. doi:10.1007/s00190-013-0644-1. S2CID 56017067. Archived (PDF) from the original on March 15, 2021. Retrieved March 2, 2021.<br><br>^ Bury, Grzegorz; Sośnica, Krzysztof; Zajdel, Radosław (December 2019). "Multi-GNSS orbit determination using satellite laser ranging". Journal of Geodesy. 93 (12): 2447–2463. Bibcode:2019JGeod..93.2447B. doi:10.1007/s00190-018-1143-1.

### GROUND TRUTH 2, ranked 11, continental_drift/Global_Positioning_System2.txt
> ReadEditView history<br><br><br><br><br><br><br><br>Tools<br><br><br><br><br><br>Tools<br>move to sidebar<br>hide<br><br><br><br>		Actions<br>	<br><br><br>ReadEditView history<br><br><br><br><br><br>		General<br>	<br><br><br>What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR codeWikidata item<br><br><br><br><br><br>		Print/export<br>	<br><br><br>Download as PDFPrintable version<br><br><br><br><br><br>		In other projects<br>	<br><br><br>Wikimedia Commons<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>From Wikipedia, the free encyclopedia<br><br><br>American satellite-based radio navigation service<br>This article is about the American global navigation satellite system. For similar systems, see Satellite navigation.<br>"GPS" redirects here. For GPS devices, see Satellite navigation device. For other uses, see GPS (disambiguation).<br><br><br>Global Positioning System (GPS)LogoCountry/ies of originUnited StatesOperator(s)US Space ForceTypeMilitary, civilianStatusOperationalCoverageGlobalAccuracy30–500 cm (0.98–16 ft)Constellation sizeNominal satellites24Current usable satellites38 (32 operational)First launchFebruary 22, 1978; 46 years ago (1978-02-22)Total launches75Orbital characteristicsRegime(s)6 MEO planesOrbital height20,180 km (12,540 mi)Orbital period1⁄2 sd or 11 hours and 58 minutesRevisit period1 sidereal dayOther detailsCost$12 billion[1](initial constellation)$1.84 billion per year (2023)[1](operating cost)Websitegps.gov<br>Artist's impression of GPS Block IIR satellite in Earth orbitCivilian GPS receivers ("GPS navigation device") in a marine applicationAutomotive navigation system in a taxicabAn Air Force Space Command Senior Airman runs through a checklist during Global Positioning System satellite operations.<br>Geodesy<br>Fundamentals<br>Geodesy<br>Geodynamics<br>Geomatics<br>History<br><br>Concepts<br>Geographical distance<br>Geoid<br>Figure of the Earth (radius and circumference)<br>Geodetic coordinates<br>Geodetic datum<br>Geodesic<br>Horizontal position representation<br>Latitude / Longitude<br>Map projection<br>Reference ellipsoid<br>Satellite geodesy<br>Spatial reference system<br>Spatial relations<br>Vertical positions<br><br>Technologies<br>Global Nav. Sat. Systems (GNSSs)<br>Global Pos. System (GPS)<br>GLONASS (Russia)<br>BeiDou (BDS) (China)<br>Galileo (Europe)<br>NAVIC (India)<br>Quasi-Zenith Sat. Sys. (QZSS) (Japan)<br>Discrete Global Grid and Geocoding<br><br>Standards (history) NGVD 29 Sea Level Datum 1929 OSGB36 Ordnance Survey Great Britain 1936 SK-42 Systema Koordinat 1942 goda ED50 European Datum 1950 SAD69 South American Datum 1969 GRS 80 Geodetic Reference System 1980 ISO 6709 Geographic point coord. 1983 NAD 83 North American Datum 1983 WGS 84 World Geodetic System 1984 NAVD 88 N. American Vertical Datum 1988 ETRS89 European Terrestrial Ref. Sys. 1989 GCJ-02 Chinese obfuscated datum 2002 Geo URI Internet link to a point  2010<br>International Terrestrial Reference System<br>Spatial Reference System Identifier (SRID)<br>Universal Transverse Mercator (UTM)<br>vte<br>The Global Positioning System (GPS), originally Navstar GPS,[2] is a satellite-based radio navigation system owned by the United States government and operated by the United States Space Force.[3] It is one of the global navigation satellite systems (GNSS) that provide geolocation and time information to a GPS receiver anywhere on or near the Earth where there is an unobstructed line of sight to four or more GPS satellites.[4] It does not require the user to transmit any data, and operates independently of any telephonic or Internet reception, though these technologies can enhance the usefulness of the GPS positioning information. It provides critical positioning capabilities to military, civil, and commercial users around the world. Although the United States government created, controls and maintains the GPS system, it is freely accessible to anyone with a GPS receiver.[5]<br><br><br>Overview[edit]<br>The GPS project was started by the U.S. Department of Defense in 1973. The first prototype spacecraft was launched in 1978 and the full constellation of 24 satellites became operational in 1993. Originally limited to use by the United States military, civilian use was allowed from the 1980s following an executive order from President Ronald Reagan after the Korean Air Lines Flight 007 disaster.[6] Advances in technology and new demands on the existing system have now led to efforts to modernize the GPS and implement the next generation of GPS Block IIIA satellites and Next Generation Operational Control System (OCX)[7] which was authorized by the U.S. Congress in 2000.<br>From the early 1990s, GPS positional accuracy was degraded by the United States government using a technology called Selective Availability, which could selectively degrade or deny access to the system at any time,[8] as happened to the Indian military in 1999 during the Kargil War. As a result, several non-US entities—including Russia, China, India, Japan, and the European Union—have developed or are developing their own global or regional satellite navigation systems. Selective Availability was discontinued on May 1, 2000, in accordance with a bill signed into law by President Bill Clinton.[9]<br>When Selective Availabilty was discontinued, GPS was accurate to about 5 meters (16 ft). GPS receivers that use the L5 band have much higher accuracy of 30 centimeters (12 in), while those for high-end applications such as engineering and land surveying are accurate to within 2 cm (3⁄4 in) and can even provide sub-millimeter accuracy with long-term measurements.[9][10][11] Consumer devices such as smartphones can be accurate to 4.9 m (16 ft) or better when used with assistive services like Wi-Fi positioning.[12]<br>As of July 2023[update], 18 GPS satellites broadcast L5 signals, which are considered pre-operational prior to being broadcast by a full complement of 24 satellites in 2027.[13]<br><br>History[edit]<br>Air Force film introducing the Navstar Global Positioning System, circa 1977<br>GPS constellation system animation<br>The GPS project was launched in the United States in 1973 to overcome the limitations of previous navigation systems,[14] combining ideas from several predecessors, including classified engineering design studies from the 1960s. The U.S. Department of Defense developed the system, which originally used 24 satellites, for use by the United States military, and became fully operational in 1995. Civilian use was allowed from the 1980s. Roger L. Easton of the Naval Research Laboratory, Ivan A. Getting of The Aerospace Corporation, and Bradford Parkinson of the Applied Physics Laboratory are credited with inventing it.[15] The work of Gladys West on the creation of the mathematical geodetic Earth model is credited as instrumental in the development of computational techniques for detecting satellite positions with the precision needed for GPS.[16][17]<br>The design of GPS is based partly on similar ground-based radio-navigation systems, such as LORAN and the Decca Navigator, developed in the early 1940s.<br>In 1955, Friedwardt Winterberg proposed a test of general relativity—detecting time slowing in a strong gravitational field using accurate atomic clocks placed in orbit inside artificial satellites. Special and general relativity predicted that the clocks on GPS satellites, as observed by those on Earth, run 38 microseconds faster per day than those on the Earth. The design of GPS corrects for this difference; because without doing so, GPS calculated positions would accumulate errors of up to 10 kilometers per day (6 mi/d).[18]<br><br>Predecessors[edit]<br>When the Soviet Union launched its first artificial satellite (Sputnik 1) in 1957, two American physicists, William Guier and George Weiffenbach, at Johns Hopkins University's Applied Physics Laboratory (APL) decided to monitor its radio transmissions.[19] Within hours they realized that, because of the Doppler effect, they could pinpoint where the satellite was along its orbit. The Director of the APL gave them access to their UNIVAC to do the heavy calculations required.<br><br>The Naval Research Laboratory’s managers for the Timation program and, later, the GPS program: Roger L. Easton (left) and Al Bartholemew.<br>Early the next year, Frank McClure, the deputy director of the APL, asked Guier and Weiffenbach to investigate the inverse problem: pinpointing the user's location, given the satellite's. (At the time, the Navy was developing the submarine-launched Polaris missile, which required them to know the submarine's location.) This led them and APL to develop the TRANSIT system.[20] In 1959, ARPA (renamed DARPA in 1972) also played a role in TRANSIT.[21][22][23]<br>TRANSIT was first successfully tested in 1960.[24] It used a constellation of five satellites and could provide a navigational fix approximately once per hour.<br>In 1967, the U.S. Navy developed the Timation satellite, which proved the feasibility of placing accurate clocks in space, a technology required for GPS.<br>In the 1970s, the ground-based OMEGA navigation system, based on phase comparison of signal transmission from pairs of stations,[25] became the first worldwide radio navigation system. Limitations of these systems drove the need for a more universal navigation solution with greater accuracy.<br>Although there were wide needs for accurate navigation in military and civilian sectors, almost none of those was seen as justification for the billions of dollars it would cost in research, development, deployment, and operation of a constellation of navigation satellites. During the Cold War arms race, the nuclear threat to the existence of the United States was the one need that did justify this cost in the view of the United States Congress. This deterrent effect is why GPS was funded. It is also the reason for the ultra-secrecy at that time. The nuclear triad consisted of the United States Navy's submarine-launched ballistic missiles (SLBMs) along with United States Air Force (USAF) strategic bombers and intercontinental ballistic missiles (ICBMs). Considered vital to the nuclear deterrence posture, accurate determination of the SLBM launch position was a force multiplier.<br>Precise navigation would enable United States ballistic missile submarines to get an accurate fix of their positions before they launched their SLBMs.[26] The USAF, with two thirds of the nuclear triad, also had requirements for a more accurate and reliable navigation system. The U.S. Navy and U.S. Air Force were developing their own technologies in parallel to solve what was essentially the same problem.<br>To increase the survivability of ICBMs, there was a proposal to use mobile launch platforms (comparable to the Soviet SS-24 and SS-25) and so the need to fix the launch position had similarity to the SLBM situation.<br>In 1960, the Air Force proposed a radio-navigation system called MOSAIC (MObile System for Accurate ICBM Control) that was essentially a 3-D LORAN. A follow-on study, Project 57, was performed in 1963 and it was "in this study that the GPS concept was born". That same year, the concept was pursued as Project 621B, which had "many of the attributes that you now see in GPS"[27] and promised increased accuracy for Air Force bombers as well as ICBMs.<br><br>Navigation Technology Satellite – II (Timation IV): NTS-II, the first satellite completely designed and built by NRL under GPS Joint Program funding. Launched June 23, 1977.<br>Updates from the Navy TRANSIT system were too slow for the high speeds of Air Force operation. The Naval Research Laboratory (NRL) continued making advances with their Timation (Time Navigation) satellites, first launched in 1967, second launched in 1969, with the third in 1974 carrying the first atomic clock into orbit and the fourth launched in 1977.[28]<br>Another important predecessor to GPS came from a different branch of the United States military. In 1964, the United States Army orbited its first Sequential Collation of Range (SECOR) satellite used for geodetic surveying.[29] The SECOR system included three ground-based transmitters at known locations that would send signals to the satellite transponder in orbit. A fourth ground-based station, at an undetermined position, could then use those signals to fix its location precisely. The last SECOR satellite was launched in 1969.[30]<br><br>Development[edit]<br>With these parallel developments in the 1960s, it was realized that a superior system could be developed by synthesizing the best technologies from 621B, Transit, Timation, and SECOR in a multi-service program. Satellite orbital position errors, induced by variations in the gravity field and radar refraction among others, had to be resolved. A team led by Harold L Jury of Pan Am Aerospace Division in Florida from 1970 to 1973, used real-time data assimilation and recursive estimation to do so, reducing systematic and residual errors to a manageable level to permit accurate navigation.[31]<br>During Labor Day weekend in 1973, a meeting of about twelve military officers at the Pentagon discussed the creation of a Defense Navigation Satellite System (DNSS). It was at this meeting that the real synthesis that became GPS was created. Later that year, the DNSS program was named Navstar.[32] Navstar is often erroneously considered an acronym for "NAVigation System using Timing And Ranging" but was never considered as such by the GPS Joint Program Office (TRW may have once advocated for a different navigational system that used that acronym).[33] With the individual satellites being associated with the name Navstar (as with the predecessors Transit and Timation), a more fully encompassing name was used to identify the constellation of Navstar satellites, Navstar-GPS.[34] Ten "Block I" prototype satellites were launched between 1978 and 1985 (an additional unit was destroyed in a launch failure).[35]<br>The effect of the ionosphere on radio transmission was investigated in a geophysics laboratory of Air Force Cambridge Research Laboratory, renamed to Air Force Geophysical Research Lab (AFGRL) in 1974. AFGRL developed the Klobuchar model for computing ionospheric corrections to GPS location.[36] Of note is work done by Australian space scientist Elizabeth Essex-Cohen at AFGRL in 1974. She was concerned with the curving of the paths of radio waves (atmospheric refraction) traversing the ionosphere from NavSTAR satellites.[37]<br>After Korean Air Lines Flight 007, a Boeing 747 carrying 269 people, was shot down by a Soviet interceptor aircraft after straying in prohibited airspace because of navigational errors,[38] in the vicinity of Sakhalin and Moneron Islands, President Ronald Reagan issued a directive making GPS freely available for civilian use, once it was sufficiently developed, as a common good.[39] The first Block II satellite was launched on February 14, 1989,[40] and the 24th satellite was launched in 1994. The GPS program cost at this point, not including the cost of the user equipment but including the costs of the satellite launches, has been estimated at US$5 billion (equivalent to $10 billion in 2023).[41]<br>Initially, the highest-quality signal was reserved for military use, and the signal available for civilian use was intentionally degraded, in a policy known as Selective Availability. This changed on May 1, 2000, with President Bill Clinton signing a policy directive to turn off Selective Availability to provide the same accuracy to civilians that was afforded to the military. The directive was proposed by the U.S. Secretary of Defense, William Perry, in view of the widespread growth of differential GPS services by private industry to improve civilian accuracy. Moreover, the U.S. military was developing technologies to deny GPS service to potential adversaries on a regional basis.[42]  Selective Availability was removed from the GPS architecture beginning with GPS-III.<br>Since its deployment, the U.S. has implemented several improvements to the GPS service, including new signals for civil use and increased accuracy and integrity for all users, all the while maintaining compatibility with existing GPS equipment. Modernization of the satellite system has been an ongoing initiative by the U.S. Department of Defense through a series of satellite acquisitions to meet the growing needs of the military, civilians, and the commercial market.<br>As of early 2015, high-quality Standard Positioning Service (SPS) GPS receivers provided horizontal accuracy of better than 3.5 meters (11 ft),[9] although many factors such as receiver and antenna quality and atmospheric issues can affect this accuracy.<br>GPS is owned and operated by the United States government as a national resource. The Department of Defense is the steward of GPS. The Interagency GPS Executive Board (IGEB) oversaw GPS policy matters from 1996 to 2004. After that, the National Space-Based Positioning, Navigation and Timing Executive Committee was established by presidential directive in 2004 to advise and coordinate federal departments and agencies on matters concerning the GPS and related systems.[43] The executive committee is chaired jointly by the Deputy Secretaries of Defense and Transportation. Its membership includes equivalent-level officials from the Departments of State, Commerce, and Homeland Security, the Joint Chiefs of Staff and NASA. Components of the executive office of the president participate as observers to the executive committee, and the FCC chairman participates as a liaison.<br>The U.S. Department of Defense is required by law to "maintain a Standard Positioning Service (as defined in the federal radio navigation plan and the standard positioning service signal specification) that will be available on a continuous, worldwide basis" and "develop measures to prevent hostile use of GPS and its augmentations without unduly disrupting or degrading civilian uses".<br><br>Timeline and modernization[edit]<br>This section is in list format but may read better as prose. You can help by converting this section, if appropriate. Editing help is available. (July 2023)<br><br>Summary of satellites[44][45][46]<br><br><br>Block<br>Launch period<br>Satellite launches<br>Currently in orbit and healthy<br><br><br>Success<br>Failure<br>Inpreparation<br>Planned<br><br><br>I<br><br>1978–1985<br>10<br>1<br>0<br>0<br>0<br><br><br>II<br><br>1989–1990<br>9<br>0<br>0<br>0<br>0<br><br><br>IIA<br><br>1990–1997<br>19<br>0<br>0<br>0<br>0<br><br><br>IIR<br><br>1997–2004<br>12<br>1<br>0<br>0<br>7<br><br><br>IIR-M<br><br>2005–2009<br>8<br>0<br>0<br>0<br>7<br><br><br>IIF<br><br>2010–2016<br>12<br>0<br>0<br>0<br>12<br><br><br>IIIA<br><br>2018–<br>6<br>0<br>4<br>0<br>6<br><br><br>IIIF<br><br>—<br>0<br>0<br>0<br>22<br>0<br><br><br>Total<br><br>76<br>2<br>4<br>22<br>32<br><br><br>(Last update: September 3, 2023)<br>USA-203 from Block IIR-M is unhealthy[47] For a more complete list, see List of GPS satellites<br><br><br>In 1972, the USAF Central Inertial Guidance Test Facility (Holloman AFB) conducted developmental flight tests of four prototype GPS receivers in a Y configuration over White Sands Missile Range, using ground-based pseudo-satellites.[48]<br>In 1978, the first experimental Block-I GPS satellite was launched.[35]<br>In 1983, after Soviet interceptor aircraft shot down the civilian airliner KAL 007 that strayed into prohibited airspace because of navigational errors, killing all 269 people on board, U.S. President Ronald Reagan announced that GPS would be made available for civilian uses once it was completed,[49][50] although it had been publicly known as early as 1979, that the CA code (Coarse/Acquisition code) would be available to civilian users.[51][52]<br>By 1985, ten more experimental Block-I satellites had been launched to validate the concept.<br>Beginning in 1988, command and control of these satellites was moved from Onizuka AFS, California to the 2nd Satellite Control Squadron (2SCS) located at Falcon Air Force Station in Colorado Springs, Colorado.[53][54]<br>On February 14, 1989, the first modern Block-II satellite was launched.<br>The Gulf War from 1990 to 1991 was the first conflict in which the military widely used GPS.[55]<br>In 1991, a project to create a miniature GPS receiver successfully ended, replacing the previous 16 kg (35 lb) military receivers with a 1.25 kg (2.8 lb) handheld receiver.[22]<br>In 1991, TomTom, a Dutch sat-nav manufacturer was founded.<br>In 1992, the 2nd Space Wing, which originally managed the system, was inactivated and replaced by the 50th Space Wing.Emblem of the 50th Space Wing<br>By December 1993, GPS achieved initial operational capability (IOC), with a full constellation (24 satellites) available and providing the Standard Positioning Service (SPS).[56]<br>Full Operational Capability (FOC) was declared by Air Force Space Command (AFSPC) in April 1995, signifying full availability of the military's secure Precise Positioning Service (PPS).[56]<br>In 1996, recognizing the importance of GPS to civilian users as well as military users, U.S. President Bill Clinton issued a policy directive[57] declaring GPS a dual-use system and establishing an Interagency GPS Executive Board to manage it as a national asset.<br>In 1998, United States Vice President Al Gore announced plans to upgrade GPS with two new civilian signals for enhanced user accuracy and reliability, particularly with respect to aviation safety, and in 2000 the United States Congress authorized the effort, referring to it as GPS III.<br>On May 2, 2000 "Selective Availability" was discontinued as a result of the 1996 executive order, allowing civilian users to receive a non-degraded signal globally.<br>In 2004, the United States government signed an agreement with the European Community establishing cooperation related to GPS and Europe's Galileo system.<br>In 2004, United States President George W. Bush updated the national policy and replaced the executive board with the National Executive Committee for Space-Based Positioning, Navigation, and Timing.[58]<br>November 2004, Qualcomm announced successful tests of assisted GPS for mobile phones.[59]<br>In 2005, the first modernized GPS satellite was launched and began transmitting a second civilian signal (L2C) for enhanced user performance.[60]<br>On September 14, 2007, the aging mainframe-based Ground Segment Control System was transferred to the new Architecture Evolution Plan.[61]<br>On May 19, 2009, the United States Government Accountability Office issued a report warning that some GPS satellites could fail as soon as 2010.[62]<br>On May 21, 2009, the Air Force Space Command allayed fears of GPS failure, saying: "There's only a small risk we will not continue to exceed our performance standard."[63]<br>On January 11, 2010, an update of ground control systems caused a software incompatibility with 8,000 to 10,000 military receivers manufactured by a division of Trimble Navigation Limited of Sunnyvale, Calif.[clarification needed][64]<br>On February 25, 2010,[65] the U.S. Air Force awarded the contract to Raytheon Company to develop the GPS Next Generation Operational Control System (OCX) to improve accuracy and availability of GPS navigation signals, and serve as a critical part of GPS modernization.<br>Awards[edit]<br>AFSPC Vice Commander Lt. Gen. DT Thompson presents Gladys West with an award as she is inducted into the Air Force Space and Missile Pioneers Hall of Fame.<br>On February 10, 1993, the National Aeronautic Association selected the GPS Team as winners of the 1992 Robert J. Collier Trophy, the US's most prestigious aviation award. This team combines researchers from the Naval Research Laboratory, the USAF, the Aerospace Corporation, Rockwell International Corporation, and IBM Federal Systems Company. The citation honors them "for the most significant development for safe and efficient navigation and surveillance of air and spacecraft since the introduction of radio navigation 50 years ago".<br>Two GPS developers received the National Academy of Engineering Charles Stark Draper Prize for 2003:<br><br>Ivan Getting, emeritus president of The Aerospace Corporation and an engineer at MIT, established the basis for GPS, improving on the World War II land-based radio system called LORAN (Long-range Radio Aid to Navigation).<br>Bradford Parkinson, professor of aeronautics and astronautics at Stanford University, conceived the present satellite-based system in the early 1960s and developed it in conjunction with the U.S. Air Force. Parkinson served twenty-one years in the Air Force, from 1957 to 1978, and retired with the rank of colonel.<br>GPS developer Roger L. Easton received the National Medal of Technology on February 13, 2006.[66]<br>Francis X. Kane (Col. USAF, ret.) was inducted into the U.S. Air Force Space and Missile Pioneers Hall of Fame at Lackland A.F.B., San Antonio, Texas, March 2, 2010, for his role in space technology development and the engineering design concept of GPS conducted as part of Project 621B.<br>In 1998, GPS technology was inducted into the Space Foundation Space Technology Hall of Fame.[67]<br>On October 4, 2011, the International Astronautical Federation (IAF) awarded the Global Positioning System (GPS) its 60th Anniversary Award, nominated by IAF member, the American Institute for Aeronautics and Astronautics (AIAA). The IAF Honors and Awards Committee recognized the uniqueness of the GPS program and the exemplary role it has played in building international collaboration for the benefit of humanity.[68]<br>On December 6, 2018, Gladys West was inducted into the Air Force Space and Missile Pioneers Hall of Fame in recognition of her work on an extremely accurate geodetic Earth model, which was ultimately used to determine the orbit of the GPS constellation.[69]<br>On February 12, 2019, four founding members of the project were awarded the Queen Elizabeth Prize for Engineering with the chair of the awarding board stating: "Engineering is the foundation of civilisation; there is no other foundation; it makes things happen. And that's exactly what today's Laureates have done –  they've made things happen. They've re-written, in a major way, the infrastructure of our world."[70]<br><br>Principles[edit]<br>This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed. (March 2015) (Learn how and when to remove this template message)<br>The GPS satellites carry very stable atomic clocks that are synchronized with one another and with the reference atomic clocks at the ground control stations; any drift of the clocks aboard the satellites from the reference time maintained on the ground stations is corrected regularly.[71] Since the speed of radio waves (speed of light)[72] is constant and independent of the satellite speed, the time delay between when the satellite transmits a signal and the ground station receives it is proportional to the distance from the satellite to the ground station. With the distance information collected from multiple ground stations, the location coordinates of any satellite at any time can be calculated with great precision.<br>Each GPS satellite carries an accurate record of its own position and time, and broadcasts that data continuously. Based on data received from multiple GPS satellites, an end user's GPS receiver can calculate its own four-dimensional position in spacetime; However, at a minimum, four satellites must be in view of the receiver for it to compute four unknown quantities (three position coordinates and the deviation of its own clock from satellite time).[73]<br><br>More detailed description[edit]<br>Each GPS satellite continually broadcasts a signal (carrier wave with modulation) that includes:<br><br>A pseudorandom code (sequence of ones and zeros) that is known to the receiver. By time-aligning a receiver-generated version and the receiver-measured version of the code, the time of arrival (TOA) of a defined point in the code sequence, called an epoch, can be found in the receiver clock time scale<br>A message that includes the time of transmission (TOT) of the code epoch (in GPS time scale) and the satellite position at that time<br>Conceptually, the receiver measures the TOAs (according to its own clock) of four satellite signals. From the TOAs and the TOTs, the receiver forms four time of flight (TOF) values, which are (given the speed of light) approximately equivalent to receiver-satellite ranges plus time difference between the receiver and GPS satellites multiplied by speed of light, which are called pseudo-ranges. The receiver then computes its three-dimensional position and clock deviation from the four TOFs.<br>In practice the receiver position (in three dimensional Cartesian coordinates with origin at the Earth's center) and the offset of the receiver clock relative to the GPS time are computed simultaneously, using the navigation equations to process the TOFs.<br>The receiver's Earth-centered solution location is usually converted to latitude, longitude and height relative to an ellipsoidal Earth model. The height may then be further converted to height relative to the geoid, which is essentially mean sea level. These coordinates may be displayed, such as on a moving map display, or recorded or used by some other system, such as a vehicle guidance system.<br><br>User-satellite geometry[edit]<br>Further information: § Geometric interpretation<br>Although usually not formed explicitly in the receiver processing, the conceptual time differences of arrival (TDOAs) define the measurement geometry. Each TDOA corresponds to a hyperboloid of revolution (see Multilateration). The line connecting the two satellites involved (and its extensions) forms the axis of the hyperboloid. The receiver is located at the point where three hyperboloids intersect.[74][75]<br>It is sometimes incorrectly said that the user location is at the intersection of three spheres. While simpler to visualize, this is the case only if the receiver has a clock synchronized with the satellite clocks (i.e., the receiver measures true ranges to the satellites rather than range differences). There are marked performance benefits to the user carrying a clock synchronized with the satellites. Foremost is that only three satellites are needed to compute a position solution. If it were an essential part of the GPS concept that all users needed to carry a synchronized clock, a smaller number of satellites could be deployed, but the cost and complexity of the user equipment would increase.<br><br>Receiver in continuous operation[edit]<br>The description above is representative of a receiver start-up situation. Most receivers have a track algorithm, sometimes called a tracker, that combines sets of satellite measurements collected at different times—in effect, taking advantage of the fact that successive receiver positions are usually close to each other. After a set of measurements are processed, the tracker predicts the receiver location corresponding to the next set of satellite measurements. When the new measurements are collected, the receiver uses a weighting scheme to combine the new measurements with the tracker prediction. In general, a tracker can (a) improve receiver position and time accuracy, (b) reject bad measurements, and (c) estimate receiver speed and direction.<br>The disadvantage of a tracker is that changes in speed or direction can be computed only with a delay, and that derived direction becomes inaccurate when the distance traveled between two position measurements drops below or near the random error of position measurement. GPS units can use measurements of the Doppler shift of the signals received to compute velocity accurately.[76] More advanced navigation systems use additional sensors like a compass or an inertial navigation system to complement GPS.<br><br>Non-navigation applications[edit]<br>For a list of applications, see § Applications.<br>GPS requires four or more satellites to be visible for accurate navigation. The solution of the navigation equations gives the position of the receiver along with the difference between the time kept by the receiver's on-board clock and the true time-of-day, thereby eliminating the need for a more precise and possibly impractical receiver based clock. Applications for GPS such as time transfer, traffic signal timing, and synchronization of cell phone base stations, make use of this cheap and highly accurate timing. Some GPS applications use this time for display, or, other than for the basic position calculations, do not use it at all.<br>Although four satellites are required for normal operation, fewer apply in special cases. If one variable is already known, a receiver can determine its position using only three satellites. For example, a ship on the open ocean usually has a known elevation close to 0m, and the elevation of an aircraft may be known.[a] Some GPS receivers may use additional clues or assumptions such as reusing the last known altitude, dead reckoning, inertial navigation, or including information from the vehicle computer, to give a (possibly degraded) position when fewer than four satellites are visible.[77][78][79]<br><br>Structure[edit]<br>This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed. (March 2015) (Learn how and when to remove this template message)<br>The current GPS consists of three major segments. These are the space segment, a control segment, and a user segment.[52] The U.S. Space Force develops, maintains, and operates the space and control segments. GPS satellites broadcast signals from space, and each GPS receiver uses these signals to calculate its three-dimensional location (latitude, longitude, and altitude) and the current time.[80]<br><br>Space segment[edit]<br>See also: GPS satellite blocks and List of GPS satellites<br>GPS II underwent a four-month series of qualification tests in the AEDC Mark I Space Chamber to determine whether the satellite could withstand extreme heat and cold in space, 1985.<br>A visual example of a 24-satellite GPS constellation in motion with the Earth rotating. Notice how the number of satellites in view from a given point on the Earth's surface changes with time. The point in this example is in Golden, Colorado, USA (39°44′49″N 105°12′39″W﻿ / ﻿39.7469°N 105.2108°W﻿ / 39.7469; -105.2108).<br>The space segment (SS) is composed of 24 to 32 satellites, or Space Vehicles (SV), in medium Earth orbit, and also includes the payload adapters to the boosters required to launch them into orbit. The GPS design originally called for 24 SVs, eight each in three approximately circular orbits,[81] but this was modified to six orbital planes with four satellites each.[82] The six orbit planes have approximately 55° inclination (tilt relative to the Earth's equator) and are separated by 60° right ascension of the ascending node (angle along the equator from a reference point to the orbit's intersection).[83] The orbital period is one-half of a sidereal day, i.e., 11 hours and 58 minutes, so that the satellites pass over the same locations[84] or almost the same locations[85] every day. The orbits are arranged so that at least six satellites are always within line of sight from everywhere on the Earth's surface (see animation at right).[86] The result of this objective is that the four satellites are not evenly spaced (90°) apart within each orbit. In general terms, the angular difference between satellites in each orbit is 30°, 105°, 120°, and 105° apart, which sum to 360°.[87]<br>Orbiting at an altitude of approximately 20,200 km (12,600 mi); orbital radius of approximately 26,600 km (16,500 mi),[88] each SV makes two complete orbits each sidereal day, repeating the same ground track each day.[89] This was very helpful during development because even with only four satellites, correct alignment means all four are visible from one spot for a few hours each day. For military operations, the ground track repeat can be used to ensure good coverage in combat zones.<br>As of February 2019[update],[90] there are 31 satellites in the GPS constellation, 27 of which are in use at a given time with the rest allocated as stand-bys. A 32nd was launched in 2018, but as of July 2019 is still in evaluation. More decommissioned satellites are in orbit and available as spares. The additional satellites improve the precision of GPS receiver calculations by providing redundant measurements. With the increased number of satellites, the constellation was changed to a nonuniform arrangement. Such an arrangement was shown to improve accuracy but also improves reliability and availability of the system, relative to a uniform system, when multiple satellites fail.[91] With the expanded constellation, nine satellites are usually visible at any time from any point on the Earth with a clear horizon, ensuring considerable redundancy over the minimum four satellites needed for a position.<br><br>Control segment[edit]<br>Ground monitor station used from 1984 to 2007, on display at the Air Force Space and Missile Museum<br>The control segment (CS) is composed of:<br><br>a master control station (MCS),<br>an alternative master control station,<br>four dedicated ground antennas, and<br>six dedicated monitor stations.<br>The MCS can also access Satellite Control Network (SCN) ground antennas (for additional command and control capability) and NGA (National Geospatial-Intelligence Agency) monitor stations. The flight paths of the satellites are tracked by dedicated U.S. Space Force monitoring stations in Hawaii, Kwajalein Atoll, Ascension Island, Diego Garcia, Colorado Springs, Colorado and Cape Canaveral, along with shared NGA monitor stations operated in England, Argentina, Ecuador, Bahrain, Australia and Washington DC.[92] The tracking information is sent to the MCS at Schriever Space Force Base 25 km (16 mi) ESE of Colorado Springs, which is operated by the 2nd Space Operations Squadron (2 SOPS) of the U.S. Space Force. Then 2 SOPS contacts each GPS satellite regularly with a navigational update using dedicated or shared (AFSCN) ground antennas (GPS dedicated ground antennas are located at Kwajalein, Ascension Island, Diego Garcia, and Cape Canaveral). These updates synchronize the atomic clocks on board the satellites to within a few nanoseconds of each other, and adjust the ephemeris of each satellite's internal orbital model. The updates are created by a Kalman filter that uses inputs from the ground monitoring stations, space weather information, and various other inputs.[93]<br>When a satellite's orbit is being adjusted, the satellite is marked unhealthy, so receivers do not use it. After the maneuver, engineers track the new orbit from the ground, upload the new ephemeris, and mark the satellite healthy again.<br>The operation control segment (OCS) currently serves as the control segment of record. It provides the operational capability that supports GPS users and keeps the GPS operational and performing within specification.<br>OCS successfully replaced the legacy 1970s-era mainframe computer at Schriever Air Force Base in September 2007. After installation, the system helped enable upgrades and provide a foundation for a new security architecture that supported U.S. armed forces.<br>OCS will continue to be the ground control system of record until the new segment, Next Generation GPS Operation Control System[7] (OCX), is fully developed and functional. The US Department of Defense has claimed that the new capabilities provided by OCX will be the cornerstone for revolutionizing GPS's mission capabilities, enabling U.S. Space Force to greatly enhance GPS operational services to U.S. combat forces, civil partners and myriad domestic and international users.[94][95] The GPS OCX program also will reduce cost, schedule and technical risk. It is designed to provide 50%[96] sustainment cost savings through efficient software architecture and Performance-Based Logistics. In addition, GPS OCX is expected to cost millions less than the cost to upgrade OCS while providing four times the capability.<br>The GPS OCX program represents a critical part of GPS modernization and provides significant information assurance improvements over the current GPS OCS program.<br><br>OCX will have the ability to control and manage GPS legacy satellites as well as the next generation of GPS III satellites, while enabling the full array of military signals.<br>Built on a flexible architecture that can rapidly adapt to the changing needs of today's and future GPS users allowing immediate access to GPS data and constellation status through secure, accurate and reliable information.<br>Provides the warfighter with more secure, actionable and predictive information to enhance situational awareness.<br>Enables new modernized signals (L1C, L2C, and L5) and has M-code capability, which the legacy system is unable to do.<br>Provides significant information assurance improvements over the current program including detecting and preventing cyber attacks, while isolating, containing and operating during such attacks.<br>Supports higher volume near real-time command and control capabilities and abilities.<br>On September 14, 2011,[97] the U.S. Air Force announced the completion of GPS OCX Preliminary Design Review and confirmed that the OCX program is ready for the next phase of development. The GPS OCX program missed major milestones and pushed its launch into 2021, 5 years past the original deadline. According to the Government Accounting Office in 2019, the 2021 deadline looked shaky.[98]<br>The project remained delayed in 2023, and was (as of June 2023) 73% over its original estimated budget.[99][100] In late 2023, Frank Calvelli, the assistant secretary of the Air Force for space acquisitions and integration, stated that the project was estimated to go live some time during the summer of 2024.[101]<br><br>User segment[edit]<br>Further information: GPS navigation device<br>GPS receivers come in a variety of formats, from devices integrated into cars, phones, and watches, to dedicated devices such as these.<br>The first portable GPS survey unit, a Leica WM 101, displayed at the Irish National Science Museum at Maynooth<br>The user segment (US) is composed of hundreds of thousands of U.S. and allied military users of the secure GPS Precise Positioning Service, and tens of millions of civil, commercial and scientific users of the Standard Positioning Service. In general, GPS receivers are composed of an antenna, tuned to the frequencies transmitted by the satellites, receiver-processors, and a highly stable clock (often a crystal oscillator). They may also include a display for providing location and speed information to the user. <br>GPS receivers may include an input for differential corrections, using the RTCM SC-104 format. This is typically in the form of an RS-232 port at 4,800 bit/s speed. Data is actually sent at a much lower rate, which limits the accuracy of the signal sent using RTCM.[citation needed] Receivers with internal DGPS receivers can outperform those using external RTCM data.[citation needed] As of 2006[update], even low-cost units commonly include Wide Area Augmentation System (WAAS) receivers.<br><br>A typical GPS receiver with integrated antenna<br>Many GPS receivers can relay position data to a PC or other device using the NMEA 0183 protocol. Although this protocol is officially defined by the National Marine Electronics Association (NMEA),[102] references to this protocol have been compiled from public records, allowing open source tools like gpsd to read the protocol without violating intellectual property laws.[clarification needed] Other proprietary protocols exist as well, such as the SiRF and MTK protocols. Receivers can interface with other devices using methods including a serial connection, USB, or Bluetooth.<br><br>Applications[edit]<br>This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed. (March 2015) (Learn how and when to remove this template message)<br>Main article: GNSS applications<br>While originally a military project, GPS is considered a dual-use technology, meaning it has significant civilian applications as well.<br>GPS has become a widely deployed and useful tool for commerce, scientific uses, tracking, and surveillance. GPS's accurate time facilitates everyday activities such as banking, mobile phone operations, and even the control of power grids by allowing well synchronized hand-off switching.[80]<br><br>Civilian[edit]<br>This antenna is mounted on the roof of a hut containing a scientific experiment needing precise timing.<br>Many civilian applications use one or more of GPS's three basic components: absolute location, relative movement, and time transfer.<br><br>Amateur radio:  clock synchronization required for several digital modes such as FT8, FT4 and JS8; also used with APRS for position reporting; is often critical during emergency and disaster communications support.<br>Atmosphere: studying the troposphere delays (recovery of the water vapor content) and ionosphere delays (recovery of the number of free electrons).[103] Recovery of Earth surface displacements due to the atmospheric pressure loading.[104]<br>Astronomy: both positional and clock synchronization data is used in astrometry and celestial mechanics and precise orbit determination.[105] GPS is also used in both amateur astronomy with small telescopes as well as by professional observatories for finding extrasolar planets.<br>Automated vehicle: applying location and routes for cars and trucks to function without a human driver.<br>Cartography: both civilian and military cartographers use GPS extensively.<br>Cellular telephony: clock synchronization enables time transfer, which is critical for synchronizing its spreading codes with other base stations to facilitate inter-cell handoff and support hybrid GPS/cellular position detection for mobile emergency calls and other applications. The first handsets with integrated GPS launched in the late 1990s. The U.S. Federal Communications Commission (FCC) mandated the feature in either the handset or in the towers (for use in triangulation) in 2002 so emergency services could locate 911 callers. Third-party software developers later gained access to GPS APIs from Nextel upon launch, followed by Sprint in 2006, and Verizon soon thereafter.<br>Clock synchronization: the accuracy of GPS time signals (±10 ns)[106] is second only to the atomic clocks they are based on, and is used in applications such as GPS disciplined oscillators.<br>Disaster relief/emergency services: many emergency services depend upon GPS for location and timing capabilities.<br>GPS-equipped radiosondes and dropsondes: measure and calculate the atmospheric pressure, wind speed and direction up to 27 km (89,000 ft) from the Earth's surface.<br>Radio occultation for weather and atmospheric science applications.[107]<br>Fleet tracking: used to identify, locate and maintain contact reports with one or more fleet vehicles in real-time.<br>Geodesy: determination of Earth orientation parameters including the daily and sub-daily polar motion,[108] and length-of-day variabilities,[109] Earth's center-of-mass - geocenter motion,[110] and low-degree gravity field parameters.[111]<br>Geofencing: vehicle tracking systems, person tracking systems, and pet tracking systems use GPS to locate devices that are attached to or carried by a person, vehicle, or pet. The application can provide continuous tracking and send notifications if the target leaves a designated (or "fenced-in") area.[112]<br>Geotagging: applies location coordinates to digital objects such as photographs (in Exif data) and other documents for purposes such as creating map overlays with devices like Nikon GP-1<br>GPS aircraft tracking<br>GPS for mining: the use of RTK GPS has significantly improved several mining operations such as drilling, shoveling, vehicle tracking, and surveying. RTK GPS provides centimeter-level positioning accuracy.[113][114]<br>GPS data mining: It is possible to aggregate GPS data from multiple users to understand movement patterns, common trajectories and interesting locations.[115] GPS data is today used in transportation and disaster engineering to forecast mobility in normal and evacuation situations (e.g., hurricanes, wildfires, earthquakes).[116][117][118][119]<br>GPS tours: location determines what content to display; for instance, information about an approaching point of interest.<br>Mental health: tracking mental health functioning and sociability.[120]<br>Navigation: navigators value digitally precise velocity and orientation measurements, as well as precise positions in real-time with a support of orbit and clock corrections.[121]<br>Orbit determination of low-orbiting satellites with GPS receiver installed on board, such as GOCE,[122] GRACE, Jason-1, Jason-2, TerraSAR-X, TanDEM-X, CHAMP, Sentinel-3,[123] and some cubesats, e.g., CubETH.<br>Phasor measurements: GPS enables highly accurate timestamping of power system measurements, making it possible to compute phasors.<br>Recreation: for example, Geocaching, Geodashing, GPS drawing, waymarking, and other kinds of location based mobile games such as Pokémon Go.<br>Reference frames: realization and densification of the terrestrial reference frames[124] in the framework of Global Geodetic Observing System. Co-location in space between Satellite laser ranging[125] and microwave observations[126] for deriving global geodetic parameters.[127][128]<br>Robotics: self-navigating, autonomous robots using GPS sensors,[129] which calculate latitude, longitude, time, speed, and heading.<br>Sport: used in football and rugby for the control and analysis of the training load.[130]<br>Surveying: surveyors use absolute locations to make maps and determine property boundaries.<br>Tectonics: GPS enables direct fault motion measurement of earthquakes. Between earthquakes GPS can be used to measure crustal motion and deformation[131] to estimate seismic strain buildup for creating seismic hazard maps.<br>Telematics: GPS technology integrated with computers and mobile communications technology in automotive navigation systems.<br>Restrictions on civilian use[edit]<br>The U.S. government controls the export of some civilian receivers. All GPS receivers capable of functioning above 60,000 ft (18 km) above sea level and 1,000 kn (500 m/s; 2,000 km/h; 1,000 mph), or designed or modified for use with unmanned missiles and aircraft, are classified as munitions (weapons)—which means they require State Department export licenses.[132] This rule applies even to otherwise purely civilian units that only receive the L1 frequency and the C/A (Coarse/Acquisition) code.<br>Disabling operation above these limits exempts the receiver from classification as a munition. Vendor interpretations differ. The rule refers to operation at both the target altitude and speed, but some receivers stop operating even when stationary. This has caused problems with some amateur radio balloon launches that regularly reach 30 km (100,000 feet).<br>These limits only apply to units or components exported from the United States. A growing trade in various components exists, including GPS units from other countries. These are expressly sold as ITAR-free.<br><br>Military[edit]<br>AN/PRC-119F SINCGARS radio, which requires accurate clock time supplied by an external GPS system to enable frequency hopping operation with other radiosAttaching a GPS guidance kit to a dumb bomb, March 2003<br>M982 Excalibur GPS-guided artillery shell<br>As of 2009, military GPS applications include:<br><br>Navigation: Soldiers use GPS to find objectives, even in the dark or in unfamiliar territory, and to coordinate troop and supply movement. In the United States armed forces, commanders use the Commander's Digital Assistant and lower ranks use the Soldier Digital Assistant.[133]<br>Frequency-Hopping Radio Clock Coordination: Military radio systems using frequency hopping modes, such as SINCGARS and HAVEQUICK, require all radios within a network to have the same time input to their internal clocks (+/-4 seconds in the case of SINCGARS) to be on the correct frequency at a given time. Military GPS receivers, such as the Precision Lightweight GPS Receiver (PLGR) and Defense Advanced GPS Receiver (DAGR), are used by radio operators within a radio network to properly input an accurate time to said radios internal clock. More modern military radios have internal GPS receivers that syncronize the internal clock automatically.<br>Target tracking: Various military weapons systems use GPS to track potential ground and air targets before flagging them as hostile.[citation needed] These weapon systems pass target coordinates to precision-guided munitions to allow them to engage targets accurately. Military aircraft, particularly in air-to-ground roles, use GPS to find targets.<br>Missile and projectile guidance: GPS allows accurate targeting of various military weapons including ICBMs, cruise missiles, precision-guided munitions and artillery shells. Embedded GPS receivers able to withstand accelerations of 12,000 g[134] or about 118 km/s2 (260,000 mph/s) have been developed for use in 155-millimeter (6.1 in) howitzer shells.[135]<br>Search and rescue.<br>Reconnaissance: Patrol movement can be managed more closely.<br>GPS satellites carry a set of nuclear detonation detectors consisting of an optical sensor called a bhangmeter, an X-ray sensor, a dosimeter, and an electromagnetic pulse (EMP) sensor (W-sensor), that form a major portion of the United States Nuclear Detonation Detection System.[136][137] General William Shelton has stated that future satellites may drop this feature to save money.[138]<br>GPS type navigation was first used in war in the 1991 Persian Gulf War, before GPS was fully developed in 1995, to assist Coalition Forces to navigate and perform maneuvers in the war. The war also demonstrated the vulnerability of GPS to being jammed, when Iraqi forces installed jamming devices on likely targets that emitted radio noise, disrupting reception of the weak GPS signal.[139]<br>GPS's vulnerability to jamming is a threat that continues to grow as jamming equipment and experience grows.[140][141] GPS signals have been reported to have been jammed many times over the years for military purposes. Russia seems to have several objectives for this approach, such as intimidating neighbors while undermining confidence in their reliance on American systems, promoting their GLONASS alternative, disrupting Western military exercises, and protecting assets from drones.[142] China uses jamming to discourage US surveillance aircraft near the contested Spratly Islands.[143] North Korea has mounted several major jamming operations near its border with South Korea and offshore, disrupting flights, shipping and fishing operations.[144] Iranian Armed Forces disrupted the civilian airliner plane Flight PS752's GPS when it shot down the aircraft.[145][146]<br><br>Timekeeping [edit]<br>Leap seconds[edit]<br>While most clocks derive their time from Coordinated Universal Time (UTC), the atomic clocks on the satellites are set to GPS time. The difference is that GPS time is not corrected to match the rotation of the Earth, so it does not contain new leap seconds or other corrections that are periodically added to UTC. GPS time was set to match UTC in 1980, but has since diverged. The lack of corrections means that GPS time remains at a constant offset with International Atomic Time (TAI) (TAI - GPS = 19 seconds). Periodic corrections are performed to the on-board clocks to keep them synchronized with ground clocks.[78]: Section 1.2.2 <br>The GPS navigation message includes the difference between GPS time and UTC. As of January 2017,[update] GPS time is 18 seconds ahead of UTC because of the leap second added to UTC on December 31, 2016.[147] Receivers subtract this offset from GPS time to calculate UTC and specific time zone values. New GPS units may not show the correct UTC time until after receiving the UTC offset message. The GPS-UTC offset field can accommodate 255 leap seconds (eight bits).<br><br>Accuracy[edit]<br>GPS time is theoretically accurate to about 14 nanoseconds, due to the clock drift relative to International Atomic Time that the atomic clocks in GPS transmitters experience.[148] Most receivers lose some accuracy in their interpretation of the signals and are only accurate to about 100 nanoseconds.[149][150]<br><br>Relativistic corrections[edit]<br>The GPS implements two major corrections to its time signals for relativistic effects: one for relative velocity of satellite and receiver, using the special theory of relativity, and one for the difference in gravitational potential between satellite and receiver, using general relativity. The acceleration of the satellite could also be computed independently as a correction, depending on purpose, but normally the effect is already dealt with in the first two corrections.[151][152]<br><br>Format[edit]<br>Further information: GPS week number rollover<br>As opposed to the year, month, and day format of the Gregorian calendar, the GPS date is expressed as a week number and a seconds-into-week number. The week number is transmitted as a ten-bit field in the C/A and P(Y) navigation messages, and so it becomes zero again every 1,024 weeks (19.6 years). GPS week zero started at 00:00:00 UTC (00:00:19 TAI) on January 6, 1980, and the week number became zero again for the first time at 23:59:47 UTC on August 21, 1999 (00:00:19 TAI on August 22, 1999). It happened the second time at 23:59:42 UTC on April 6, 2019. To determine the current Gregorian date, a GPS receiver must be provided with the approximate date (to within 3,584 days) to correctly translate the GPS date signal. To address this concern in the future the modernized GPS civil navigation (CNAV) message will use a 13-bit field that only repeats every 8,192 weeks (157 years), thus lasting until 2137 (157 years after GPS week zero).<br><br>Communication[edit]<br>Main article: GPS signals<br>The navigational signals transmitted by GPS satellites encode a variety of information including satellite positions, the state of the internal clocks, and the health of the network. These signals are transmitted on two separate carrier frequencies that are common to all satellites in the network. Two different encodings are used: a public encoding that enables lower resolution navigation, and an encrypted encoding used by the U.S. military.[citation needed]<br><br>Message format[edit]<br><br>GPS message format<br><br><br>Subframes<br>Description<br><br><br>1<br>Satellite clock,GPS time relationship<br><br><br>2–3<br>Ephemeris(precise satellite orbit)<br><br><br>4–5<br>Almanac component(satellite network synopsis,error correction)<br><br>Each GPS satellite continuously broadcasts a navigation message on L1 (C/A and P/Y) and L2 (P/Y) frequencies at a rate of 50 bits per second (see bitrate). Each complete message takes 750 seconds (12+1⁄2 minutes) to complete. The message structure has a basic format of a 1500-bit-long frame made up of five subframes, each subframe being 300 bits (6 seconds) long. Subframes 4 and 5 are subcommutated 25 times each, so that a complete data message requires the transmission of 25 full frames. Each subframe consists of ten words, each 30 bits long. Thus, with 300 bits in a subframe times 5 subframes in a frame times 25 frames in a message, each message is 37,500 bits long. At a transmission rate of 50-bit/s, this gives 750 seconds to transmit an entire almanac message (GPS). Each 30-second frame begins precisely on the minute or half-minute as indicated by the atomic clock on each satellite.[153]<br>The first subframe of each frame encodes the week number and the time within the week,[154] as well as the data about the health of the satellite. The second and the third subframes contain the ephemeris – the precise orbit for the satellite. The fourth and fifth subframes contain the almanac, which contains coarse orbit and status information for up to 32 satellites in the constellation as well as data related to error correction. Thus, to obtain an accurate satellite location from this transmitted message, the receiver must demodulate the message from each satellite it includes in its solution for 18 to 30 seconds. To collect all transmitted almanacs, the receiver must demodulate the message for 732 to 750 seconds or 12+1⁄2 minutes.[155]<br>All satellites broadcast at the same frequencies, encoding signals using unique code-division multiple access (CDMA) so receivers can distinguish individual satellites from each other. The system uses two distinct CDMA encoding types: the coarse/acquisition (C/A) code, which is accessible by the general public, and the precise (P(Y)) code, which is encrypted so that only the U.S. military and other NATO nations who have been given access to the encryption code can access it.[156]<br>The ephemeris is updated every 2 hours and is sufficiently stable for 4 hours, with provisions for updates every 6 hours or longer in non-nominal conditions. The almanac is updated typically every 24 hours. Additionally, data for a few weeks following is uploaded in case of transmission updates that delay data upload.[citation needed]<br><br>Satellite frequencies[edit]<br><br>GPS frequency overview[157]: 607 <br><br><br>Band<br>Frequency<br>Description<br><br><br>L1<br>1575.42 MHz<br>Coarse-acquisition (C/A) and encrypted precision (P(Y)) codes, plus the L1 civilian (L1C) and military (M) codes on Block III and newer satellites.<br><br><br>L2<br>1227.60 MHz<br>P(Y) code, plus the L2C and military codes on the Block IIR-M and newer satellites.<br><br><br>L3<br>1381.05 MHz<br>Used for nuclear detonation (NUDET) detection.<br><br><br>L4<br>1379.913 MHz<br>Being studied for additional ionospheric correction.<br><br><br>L5<br>1176.45 MHz<br>Used as a civilian safety-of-life (SoL) signal on Block IIF and newer satellites.<br><br>All satellites broadcast at the same two frequencies, 1.57542 GHz (L1 signal) and 1.2276 GHz (L2 signal). The satellite network uses a CDMA spread-spectrum technique[157]: 607  where the low-bitrate message data is encoded with a high-rate pseudo-random (PRN) sequence that is different for each satellite. The receiver must be aware of the PRN codes for each satellite to reconstruct the actual message data. The C/A code, for civilian use, transmits data at 1.023 million chips per second, whereas the P code, for U.S. military use, transmits at 10.23 million chips per second. The actual internal reference of the satellites is 10.22999999543 MHz to compensate for relativistic effects[158][159] that make observers on the Earth perceive a different time reference with respect to the transmitters in orbit. The L1 carrier is modulated by both the C/A and P codes, while the L2 carrier is only modulated by the P code.[87] The P code can be encrypted as a so-called P(Y) code that is only available to military equipment with a proper decryption key. Both the C/A and P(Y) codes impart the precise time-of-day to the user.<br>The L3 signal at a frequency of 1.38105 GHz is used to transmit data from the satellites to ground stations. This data is used by the United States Nuclear Detonation (NUDET) Detection System (USNDS) to detect, locate, and report nuclear detonations (NUDETs) in the Earth's atmosphere and near space.[160] One usage is the enforcement of nuclear test ban treaties.<br>The L4 band at 1.379913 GHz is being studied for additional ionospheric correction.[157]: 607 <br>The L5 frequency band at 1.17645 GHz was added in the process of GPS modernization. This frequency falls into an internationally protected range for aeronautical navigation, promising little or no interference under all circumstances. The first Block IIF satellite that provides this signal was launched in May 2010.[161] On February 5, 2016, the 12th and final Block IIF satellite was launched.[162] The L5 consists of two carrier components that are in phase quadrature with each other. Each carrier component is bi-phase shift key (BPSK) modulated by a separate bit train. "L5, the third civil GPS signal, will eventually support safety-of-life applications for aviation and provide improved availability and accuracy."[163]<br><br>This section needs to be updated. Please help update this article to reflect recent events or newly available information. (May 2021)<br>In 2011, a conditional waiver was granted to LightSquared to operate a terrestrial broadband service near the L1 band. Although LightSquared had applied for a license to operate in the 1525 to 1559 band as early as 2003 and it was put out for public comment, the FCC asked LightSquared to form a study group with the GPS community to test GPS receivers and identify issues that might arise due to the larger signal power from the LightSquared terrestrial network. The GPS community had not objected to the LightSquared (formerly MSV and SkyTerra) applications until November 2010, when LightSquared applied for a modification to its Ancillary Terrestrial Component (ATC) authorization. This filing (SAT-MOD-20101118-00239) amounted to a request to run several orders of magnitude more power in the same frequency band for terrestrial base stations, essentially repurposing what was supposed to be a "quiet neighborhood" for signals from space as the equivalent of a cellular network. Testing in the first half of 2011 has demonstrated that the impact of the lower 10 MHz of spectrum is minimal to GPS devices (less than 1% of the total GPS devices are affected). The upper 10 MHz intended for use by LightSquared may have some impact on GPS devices. There is some concern that this may seriously degrade the GPS signal for many consumer uses.[164][165] Aviation Week magazine reports that the latest testing (June 2011) confirms "significant jamming" of GPS by LightSquared's system.[166]<br><br>Demodulation and decoding[edit]<br>Demodulating and Decoding GPS Satellite Signals using the Coarse/Acquisition Gold code<br>Because all of the satellite signals are modulated onto the same L1 carrier frequency, the signals must be separated after demodulation. This is done by assigning each satellite a unique binary sequence known as a Gold code. The signals are decoded after demodulation using addition of the Gold codes corresponding to the satellites monitored by the receiver.[167][168]<br>If the almanac information has previously been acquired, the receiver picks the satellites to listen for by their PRNs, unique numbers in the range 1 through 32. If the almanac information is not in memory, the receiver enters a search mode until a lock is obtained on one of the satellites. To obtain a lock, it is necessary that there be an unobstructed line of sight from the receiver to the satellite. The receiver can then acquire the almanac and determine the satellites it should listen for. As it detects each satellite's signal, it identifies it by its distinct C/A code pattern. There can be a delay of up to 30 seconds before the first estimate of position because of the need to read the ephemeris data.<br>Processing of the navigation message enables the determination of the time of transmission and the satellite position at this time. For more information see Demodulation and Decoding, Advanced.<br><br>Navigation equations[edit]<br>Further information: GNSS positioning calculation<br>See also: Pseudorange<br>Problem statement[edit]<br>The receiver uses messages received from satellites to determine the satellite positions and time sent. The x, y, and z components of satellite position and the time sent (s) are designated as [xi, yi, zi, si] where the subscript i denotes the satellite and has the value 1, 2, ..., n, where n ≥ 4. When the time of message reception indicated by the on-board receiver clock is <br><br><br><br><br><br><br><br>t<br>~<br><br><br><br><br>i<br><br><br><br><br>{\displaystyle {\tilde {t}}_{i}}<br><br>, the true reception time is <br><br><br><br><br>t<br><br>i<br><br><br>=<br><br><br><br><br>t<br>~<br><br><br><br><br>i<br><br><br>−<br>b<br><br><br>{\displaystyle t_{i}={\tilde {t}}_{i}-b}<br><br>, where b is the receiver's clock bias from the much more accurate GPS clocks employed by the satellites. The receiver clock bias is the same for all received satellite signals (assuming the satellite clocks are all perfectly synchronized). The message's transit time is <br><br><br><br><br><br><br><br>t<br>~<br><br><br><br><br>i<br><br><br>−<br>b<br>−<br><br>s<br><br>i<br><br><br><br><br>{\displaystyle {\tilde {t}}_{i}-b-s_{i}}<br><br>, where si is the satellite time. Assuming the message traveled at the speed of light, c, the distance traveled is <br><br><br><br><br>(<br><br><br><br><br><br>t<br>~<br><br><br><br><br>i<br><br><br>−<br>b<br>−<br><br>s<br><br>i<br><br><br><br>)<br><br>c<br><br><br>{\displaystyle \left({\tilde {t}}_{i}-b-s_{i}\right)c}

### GROUND TRUTH 3, ranked 3, continental_drift/Paleomagnetism3.txt
> Toggle the table of contents<br><br><br><br><br><br><br><br>Paleomagnetism<br><br><br><br>42 languages<br><br><br><br><br>AfrikaansالعربيةAzərbaycancaBosanskiCatalàČeštinaDeutschEspañolEuskaraفارسیFrançaisGaeilgeGalego한국어Հայերենहिन्दीHrvatskiBahasa IndonesiaItalianoעבריתҚазақшаMagyarमराठीBahasa MelayuNederlands日本語Norsk bokmålNorsk nynorskپښتوPolskiPortuguêsРусскийSlovenčinaSlovenščinaСрпски / srpskiSrpskohrvatski / српскохрватскиSuomiSvenskaTürkçeУкраїнськаTiếng Việt中文<br><br>Edit links<br><br><br><br><br><br><br><br><br><br><br><br>ArticleTalk<br><br><br><br><br><br>English<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>ReadEditView history<br><br><br><br><br><br><br><br>Tools<br><br><br><br><br><br>Tools<br>move to sidebar<br>hide<br><br><br><br>		Actions<br>	<br><br><br>ReadEditView history<br><br><br><br><br><br>		General<br>	<br><br><br>What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR codeWikidata item<br><br><br><br><br><br>		Print/export<br>	<br><br><br>Download as PDFPrintable version<br><br><br><br><br><br>		In other projects<br>	<br><br><br>Wikimedia Commons<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>From Wikipedia, the free encyclopedia<br><br><br>Study of Earth's magnetic field in past<br><br><br><br>Magnetic stripes are the result of reversals of the Earth's field and seafloor spreading. New oceanic crust is magnetized as it forms and then it moves away from the ridge in both directions. The models show a ridge (a) about 5 million years ago (b) about 2 million years ago and (c) in the present.[1]<br>Paleomagnetism (occasionally palaeomagnetism) is the study of prehistoric Earth's magnetic fields recorded in rocks, sediment, or archeological materials. Geophysicists who specialize in paleomagnetism are called paleomagnetists.<br>Certain magnetic minerals in rocks can record the direction and intensity of Earth's magnetic field at the time they formed. This record provides information on the past behavior of the geomagnetic field and the past location of tectonic plates. The record of geomagnetic reversals preserved in volcanic and sedimentary rock sequences (magnetostratigraphy) provides a time-scale that is used as a geochronologic tool.<br>Evidence from paleomagnetism led to the revival of the continental drift hypothesis and its transformation into the modern theory of plate tectonics. Apparent polar wander paths provided the first clear geophysical evidence for continental drift, while marine magnetic anomalies did the same for seafloor spreading. Paleomagnetic data continues to extend the history of plate tectonics back in time, constraining the ancient position and movement of continents and continental fragments (terranes).

### GROUND TRUTH 4, ranked 5, continental_drift/Paleomagnetism4.txt
> The field of paleomagnetism also encompasses equivalent measurements of samples from other Solar System bodies, such as Moon rocks and meteorites, where it is used to investigate the ancient magnetic fields of those bodies and dynamo theory. Paleomagnetism relies on developments in rock magnetism and overlaps with biomagnetism, magnetic fabrics (used as strain indicators in rocks and soils), and environmental magnetism.<br><br><br>History[edit]<br>Main article: History of geomagnetism<br>As early as the 18th century, it was noticed that compass needles deviated near strongly magnetized outcrops. In 1797, Alexander von Humboldt attributed this magnetization to lightning strikes (and lightning strikes do often magnetize surface rocks).[2][3][4] 19th century studies of the direction of magnetization in rocks showed that some recent lavas were magnetized parallel to Earth's magnetic field. Early in the 20th century, work by David, Bernard Brunhes and Paul Louis Mercanton showed that many rocks were magnetized antiparallel to the field. Japanese geophysicist Motonori Matuyama showed in the late 1920s that Earth's magnetic field reversed in the mid-Quaternary, a reversal now known as the Brunhes–Matuyama reversal.[5][3]<br>British physicist P.M.S. Blackett provided a major impetus to paleomagnetism by inventing a sensitive astatic magnetometer in 1956. His intent was to test his theory that the geomagnetic field was related to Earth's rotation, a theory that he ultimately rejected; but the astatic magnetometer became the basic tool of paleomagnetism and led to a revival of the theory of continental drift. <br>Alfred Wegener first proposed in 1915 that continents had once been joined together and had since moved apart.[6][7] Although he produced an abundance of circumstantial evidence, his theory met with little acceptance for two reasons: (1) no mechanism for continental drift was known, and (2) there was no way to reconstruct the movements of the continents over time. Keith Runcorn[8] and Edward A. Irving[9] constructed apparent polar wander paths for Europe and North America. These curves diverged but could be reconciled if it was assumed that the continents had been in contact up to 200 million years ago. This provided the first clear geophysical evidence for continental drift. Then in 1963, Morley, Vine and Matthews showed that marine magnetic anomalies provided evidence for seafloor spreading.<br><br>Fields[edit]<br>Paleomagnetism is studied on a number of scales:<br><br>Geomagnetic secular variation is the small-scale changes in the direction and intensity of Earth's magnetic field. The magnetic north pole is constantly shifting relative to the axis of rotation of Earth. Magnetism is a vector and so magnetic field variation is studied by palaeodirectional measurements of magnetic declination and magnetic inclination and palaeointensity measurements.<br>Earth's magnetic polarity reversals in last 5 million years. Dark regions represent normal polarity (same as present field); light regions represent reversed polarity.<br>Magnetostratigraphy uses the polarity reversal history of Earth's magnetic field recorded in rocks to determine the age of those rocks. Reversals have occurred at irregular intervals throughout Earth's history. The age and pattern of these reversals is known from the study of sea floor spreading zones and the dating of volcanic rocks.<br>Principles[edit]<br>The study of paleomagnetism is possible because iron-bearing minerals such as magnetite may record past polarity of Earth's magnetic field. Magnetic signatures in rocks can be recorded by several different mechanisms.<br><br>Thermoremanent magnetization[edit]<br>Main article: Thermoremanent magnetization<br>Iron-titanium oxide minerals in basalt and other igneous rocks may preserve the direction of Earth's magnetic field when the rocks cool through the Curie temperatures of those minerals. The Curie temperature of magnetite, a spinel-group iron oxide, is about 580 °C, whereas most basalt and gabbro are completely crystallized at temperatures below 900 °C. Hence, the mineral grains are not rotated physically to align with Earth's magnetic field, but rather they may record the orientation of that field. The record so preserved is called a thermoremanent magnetization (TRM). <br>Because complex oxidation reactions may occur as igneous rocks cool after crystallization, the orientations of Earth's magnetic field are not always accurately recorded, nor is the record necessarily maintained. Nonetheless, the record has been preserved well enough in basalts of oceanic crust to have been critical in the development of theories of sea floor spreading related to plate tectonics. <br>TRM can also be recorded in pottery kilns, hearths, and burned adobe buildings. The discipline based on the study of thermoremanent magnetisation in archaeological materials is called archaeomagnetic dating.[10] Although the Māori people of New Zealand do not make pottery, their 700- to 800-year-old steam ovens, or hāngī, provide adequate archaeomagnetic material.[11]<br><br>Detrital remanent magnetization[edit]<br>In a completely different process, magnetic grains in sediments may align with the magnetic field during or soon after deposition; this is known as detrital remanent magnetization. If the magnetization is acquired as the grains are deposited, the result is a depositional detrital remanent magnetization; if it is acquired soon after deposition, it is a post-depositional detrital remanent magnetization.[12]<br><br>Chemical remanent magnetization[edit]<br>See also: Chemical remanent magnetization<br>In a third process, magnetic grains grow during chemical reactions and record the direction of the magnetic field at the time of their formation. The field is said to be recorded by chemical remanent magnetization (CRM). A common form is held by the mineral hematite, another iron oxide. Hematite forms through chemical oxidation reactions of other minerals in the rock including magnetite. Red beds, clastic sedimentary rocks (such as sandstones) are red because of hematite that formed during sedimentary diagenesis. The CRM signatures in red beds can be quite useful, and they are common targets in magnetostratigraphy studies.[13]<br><br>Isothermal remanent magnetization[edit]<br>Remanence that is acquired at a fixed temperature is called isothermal remanent magnetization (IRM). Remanence of this sort is not useful for paleomagnetism, but it can be acquired as a result of lightning strikes. Lightning-induced remanent magnetization can be distinguished by its high intensity and rapid variation in direction over scales of centimeters.[14][13]<br>IRM is often induced in drill cores by the magnetic field of the steel core barrel. This contaminant is generally parallel to the barrel, and most of it can be removed by heating up to about 400 °C or demagnetizing in a small alternating field. In the laboratory, IRM is induced by applying fields of various strengths and is used for many purposes in rock magnetism.<br><br>Viscous remanent magnetization[edit]<br>Viscous remanent magnetization is remanence that is acquired by ferromagnetic materials influenced by a magnetic field for some time. In rocks, this remanence is typically aligned in the direction of the modern-day geomagnetic field. The fraction of a rock’s overall magnetization that is a viscous remanent magnetization is dependent on the magnetic mineralogy.<br><br>Sampling[edit]<br>The oldest rocks on the ocean floor are 200 Ma: very young when compared with the oldest continental rocks which date from 3.8 Ga. In order to collect paleomagnetic data dating beyond 200 Ma, scientists turn to magnetite-bearing samples on land to reconstruct Earth's ancient field orientation. Paleomagnetists, like many geologists, gravitate towards outcrops because layers of rock are exposed. Road cuts are a convenient man-made source of outcrops.<br><br>"And everywhere, in profusion along this half mile of [roadcut], there are small, neatly cored holes ... appears to be a Hilton for wrens and purple martins."[15]<br>There are two main goals of sampling:<br><br>Retrieve samples with accurate orientations, and<br>Reduce statistical uncertainty.<br>One way to achieve the first goal is to use a rock coring drill that has an auger tipped with diamond bits. The drill cuts a cylindrical space around some rock. Into this space is inserted a pipe with a compass and inclinometer attached. These provide the orientations. Before this device is removed, a mark is scratched on the sample. After the sample is broken off, the mark can be augmented for clarity.[16]<br><br>Applications[edit]<br>Paleomagnetic evidence of both reversals and polar wandering data was instrumental in verifying the theories of continental drift and plate tectonics in the 1960s and 1970s. Some applications of paleomagnetic evidence to reconstruct histories of terranes have continued to arouse controversies. Paleomagnetic evidence is also used in constraining possible ages for rocks and processes and in reconstructions of the deformational histories of parts of the crust.[4]<br>Reversal magnetostratigraphy is often used to estimate the age of sites bearing fossils and hominin remains.[17] Conversely, for a fossil of known age, the paleomagnetic data can fix the latitude at which the fossil was laid down. Such a paleolatitude provides information about the geological environment at the time of deposition. Paleomagnetic studies are combined with geochronological methods to determine absolute ages for rocks in which the magnetic record is preserved. For igneous rocks such as basalt, commonly used methods include potassium–argon and argon–argon geochronology.<br><br>See also[edit]<br>Geophysics – Physics of the Earth and its vicinity<br>Magnetochemistry – Study of magnetic properties of chemical compounds<br>Paleoclimatology – Study of changes in ancient climate<br>Plate reconstruction – Process of reconstructing the positions of tectonic plates in the geological past<br>Rock magnetism – The study of magnetism in rocks<br>Notes[edit]<br><br><br>^ W. Jacquelyne, Kious; Robert I., Tilling (2001). "Developing the theory". This dynamic earth: the story of plate tectonics (online edition version 1.20). Washington, D.C.: U.S. Geological Survey. ISBN 0-16-048220-8. Retrieved 6 November 2016.<br><br>^ Humboldt, F.A. v. (1797). "Ueber die merkwürdige magnetische Polarität einer Gebirgskuppe von Serpentinstein" [About the strange magnetic polarity of a mountain peak of serpentine]. Neues Journal der Physik (in German). 4: 136–140.  On pp. 136-137 Humboldt found that a peak in the Oberpfalz mountains was magnetic.  On p. 138, Humboldt noted that a mountain peak in the Harz Mountains — specifically, the Schuarcher (the snorer) — also showed magnetization.  He attributed the magnetization to lightning strikes. From p. 138:  "Bey den Schuarchern ist es […] nicht unwahrscheinlich, daß ein Blitzstrahl in dem Granit jenen magnetischen Streifen hervorgebracht habe, […] " (In the case of the Schuarcher […] it's not improbable that a bolt of lightning produced in the granite that magnetic streak, […] )  Humboldt thought that this explanation was even more likely in the case of peak in the Oberpfalz because even fragments of the rock were magnetized:  "Nicht bloß das anstehende Gestein, sondern auch jedes noch so klein abgeschlagene Stück hat seine beiden Pole, seine eigene magnetische Achse."  (Not just the outcrop but also every chip, however small, has both [magnetic] poles, its own magnetic axis.)  <br><br>^ a b Glen 1982, p. [page needed].<br><br>^ a b McElhinny & McFadden 2000<br><br>^ Matuyama, Motonori (1929). "On the Direction of Magnetization of Basalt in Japan, Tyōsen [Korea] and Manchuria". Proceedings of the Imperial Academy of Japan. 5: 203–205. doi:10.2183/pjab1912.5.203.<br><br>^ Wegener, Alfred (1915). Die Entstehung der Kontinente und Ozeane [The Origin of Continents and Oceans] (in German). Braunschweig, Germany: Vieweg.<br><br>^ Glen 1982, pp. 4–5.<br><br>^ Runcorn, S. K. (1956). "Paleomagnetic comparisons between Europe and North America". Proc. Geol. Assoc. Canada. 8: 77–85.<br><br>^ Irving, E. (1956). "Paleomagnetic and palaeoclimatological aspects of polar wandering". Geofis. Pura. Appl. 33 (1): 23–41. Bibcode:1956GeoPA..33...23I. doi:10.1007/BF02629944. S2CID 129781412.<br><br>^ Herries, A. I. R.; Adams, J. W.; Kuykendall, K. L.; Shaw, J. (2006). "Speleology and magnetobiostratigraphic chronology of the GD 2 locality of the Gondolin hominin-bearing paleocave deposits, North West Province, South Africa". Journal of Human Evolution. 51 (6): 617–31. doi:10.1016/j.jhevol.2006.07.007. PMID 16949648.<br><br>^ Amos, Jonathan (7 December 2012). "Maori stones hold magnetic clues". BBC News. Retrieved 7 December 2012.<br><br>^ "Detrital Remanent Magnetization (DRM)". MagWiki: A Magnetic Wiki for Earth Scientists. Retrieved 11 November 2011.<br><br>^ a b Tauxe, Lisa (24 May 2016). "Chemical remanent magnetization". Essentials of Paleomagnetism: Web Edition 3.0. Retrieved 18 September 2017.<br><br>^ Dunlop & Özdemir 1997<br><br>^ McPhee 1998, pp. 21–22<br><br>^ Tauxe 1998<br><br>^ Herries, A. I. R.; Kovacheva, M.; Kostadinova, M.; Shaw, J. (2007). "Archaeo-directional and -intensity data from burnt structures at the Thracian site of Halka Bunar (Bulgaria): The effect of magnetic mineralogy, temperature and atmosphere of heating in antiquity". Physics of the Earth and Planetary Interiors. 162 (3–4): 199–216. Bibcode:2007PEPI..162..199H. doi:10.1016/j.pepi.2007.04.006.<br><br><br>References[edit]<br><br>Dunlop, David J.; Özdemir, Özden (1997). Rock Magnetism: Fundamentals and Frontiers. Cambridge Univ. Press. ISBN 0-521-32514-5.<br>Glen, William (1982). The Road to Jaramillo: Critical Years of the Revolution in Earth Science. Stanford University Press. ISBN 0-8047-1119-4.<br>McElhinny, Michael W.; McFadden, Phillip L. (2000). Paleomagnetism: Continents and Oceans. Academic Press. ISBN 0-12-483355-1.<br>McPhee, John (1998). Annals of the Former World. Farrar, Straus and Giroux. ISBN 0-374-10520-0.<br>Tauxe, Lisa (1998). Paleomagnetic Principles and Practice. Kluwer. ISBN 0-7923-5258-0.<br><br>Further reading[edit]<br><br>Butler, Robert F. (1992). Paleomagnetism: Magnetic Domains to Geologic Terranes. Blackwell. ISBN 0-86542-070-X. Archived from the original on 18 February 1999.<br>Tauxe, Lisa (2010). Essentials of Paleomagnetism. University of California Press. ISBN 978-0-520-26031-3.<br><br>External links[edit]<br><br><br><br>The Wikibook Historical Geology has a page on the topic of: Paleomagnetic dating<br><br>Geomagnetism & Paleomagnetism background material<br>Paleomagnetic Data from NGDC / WDC Boulder<br>The Great Magnet, The Earth<br>Paleomagnetic database at the Scripps Institution of Oceanography (MagIC)<br>vteChronologyKey topics<br>Archaeology<br>Astronomy<br>Geology<br>History<br>Big History<br>Paleontology<br>Time<br>PeriodsErasEpochsCalendar eras<br>Human Era<br>Ab urbe condita<br>Anno Domini / Common Era<br>Anno Mundi<br>Bosporan era<br>Bostran era<br>Byzantine era<br>Seleucid era<br>Era of Caesar (Iberia)<br>Before present<br>Hijri<br>Egyptian<br>Sothic cycle<br>Hindu units of time (Yuga)<br>Mesoamerican<br>Long Count<br>Short Count<br>Tzolk'in<br>Haab'<br>Regnal year<br>Anka year<br>Canon of Kings<br>English and British regnal year<br>Lists of kings<br>Limmu<br>Era names<br>Chinese<br>Japanese<br>Korean<br>Vietnamese<br>CalendarsPre-Julian / Julian<br>Pre-Julian Roman<br>Original Julian<br>Proleptic Julian
