[
    "Is there a melt command in Snowflake?\n\nIs there a Snowflake command that will transform a table like this:\n```\na,b,c\n1,10,0.1\n2,11,0.12\n3,12,0.13\n```\nto a table like this:\n```\nkey,value\na,1\na,2\na,3\nb,10\nb,11\nb,13\nc,0.1\nc,0.12\nc,0.13\n```\n?\n\nThis operation is often called melt in other tabular systems, but the basic idea is to convert the table into a list of key value pairs.\n\nThere is an UNPIVOT in SnowSQL, but as I understand it UNPIVOT requires to manually specify every single column. This doesn't seem practical for a large number of columns.",
    "Python split a column value into multiple columns and keep remaining column same\n\nThe task is to split the values of column A to into different columns and have values of corresponding column2 values and need column3 to contain the corresponding value of the group.\n\n```\nColumn1 Column2 Column3\nGroup1  Value1  V1\nGroup1  Value2  V2\nGroup1  Value3  V3\nGroup1  Value4  V4\nGroup2  Value1  x1\nGroup2  Value2  x2\nGroup2  Value3  x3\nGroup2  Value4  x4\nGroup3  Value1  y1\nGroup3  Value2  y2\n```\n\nto a table like this:\n\n```\nGroup1 Group2 Group3 Column3.Group1 Column3.Group2 Column3.Group3\nValue1 Value1 Value1  v1             x1                y1\nValue2 Value2 Value2  v2             x2                y1\nValue3 Value3 NaN     v3             x3                NaN\nValue4 Value4 NaN     v4             x4                NaN\n```\n\nAny way to achieve this output in python?",
    "Python type hints: what should I use for a variable that can be any iterable sequence?\n\n```\ndef mysum(x)->int:\n    s = 0\n    for i in x:\n        s += i\n    return s\n```\n\nThe argument x can be list[int] or set[int], it can also be d.keys() where d is a dict, it can be range(10), as well as possibly many other sequences, where the item is of type int. What is the correct type-hint for x?",
    "I have below scenario where list str columns need to be merged with the dataframe.\n\n```\ncolumns = [\"server\", \"ip\"]\n \ndataframes = [\n        df1,\n        df2,\n        df3,\n        df4,\n]\n\ndf_res = pd.merge(dataframes, columns )\n```\n\ndf1 name , server , df1,df2,df3 and df4 contains column \"server\" and \"ip\" and other columns too.\n\nSo, i want to merge all the columns with server and ip in the df_res.\n\nBut i am getting issue as below:\n\nCan only merge Series or DataFrame objects, a <class 'list'> was passed. Please help.",
    "I have a custom PyTorch model that bottlenecks my application due to how it is currently used.\n\nThe application is a web server built in Flask that receives job submissions for the PyTorch model to process. Due to the processing time of each job, I use Celery to handle the computation, where Flask queues the tasks for Celery to execute.\n\nEach job consists of loading the PyTorch model from the disk, moving the model and data to a GPU, and making a prediction on the data submitted. However, loading the model takes around 6 seconds. In many instances, that is a magnitude or two larger than prediction time.\n\nThus, is it possible to load the model and move it to a GPU on server startup (specifically when the Celery worker starts), avoiding the time needed to load the model and copy it to the GPU every job? Ideally, I'd want to load the model and copy it to every available GPU on server startup, leaving each Celery job to choose an available GPU and copy the data over. Currently, I only have one GPU, so a multi-GPU solution is not a requirement at the moment, but I'm planning ahead.\n\nFurther, the memory constraints of the model and data allow for only one job per GPU at a time, so I have a single Celery worker that processes jobs sequentially. This could reduce the complexity of the solution due to avoiding multiple jobs attempting to use the model in shared memory at the same time, so I figured I'd mention it.\n\nHow can I deal with it?",
    "Dropping elements from lists in a nested Polars column\n\nHow do I get this behaviour:\n\n```\npl.Series(['abc_remove_def', 'remove_abc_def', 'abc_def_remove']).str.split('_').map_elements(lambda x: [y for y in x if y != 'remove']).list.join('_')\n```\n\nWithout using the slower map_elements? I have tried using .list.eval and pl.element() but I can't find anything that actually excludes elements from a list by name (i.e. by the word 'remove' in this case)",
    "I'm trying to write an LLM class as below:\n\n```\nfrom langchain_openai import ChatOpenAI\n\nclass LLM:\n    def __init__(self,model_name):\n        super().__init__(model_name=model_name)\n        self.model_name = model_name  \n\nclass OpenAILLM(LLM,ChatOpenAI):\n    def __init__(self,model_name):\n        super().__init__(model_name=model_name)\n        self.model_name = model_name\n```\nwhich works fine but when I try to add another variable in __init__ of OpenAILLM class as below\n\n```\nfrom langchain_openai import ChatOpenAI\n\nclass LLM:\n    def __init__(self,model_name):\n        super().__init__(model_name=model_name)\n        self.model_name = model_name  \n\nclass OpenAILLM(LLM,ChatOpenAI):\n    def __init__(self,model_name):\n        super().__init__(model_name=model_name)\n        self.model_name = model_name\n        self.var = 'var'\n```\n\nThe object creation for OpenAILLM fails and gives ValueError: \"OpenAILLM\" object has no field \"var\"\n\nCan anyone help me how I can add more variables?\n\nAnother thing I tried is the get_var function define below works but the set_var function defined below gives same error as above\n\n```\nfrom langchain_openai import ChatOpenAI\n\nclass LLM():\n    var = 1\n    def __init__(self,model_name):\n        super().__init__(model_name=model_name)\n        self.model_name = model_name  \n\nclass OpenAILLM(LLM,ChatOpenAI):\n    def __init__(self,model_name):\n        super().__init__(model_name=model_name)\n        self.model_name = model_name\n    def get_var(self):\n        return self.var\n    def set_var(self, var):\n        print('self var',self.var)\n        self.var = var\n        return True\n```\n\nThe mro of OpenAILLM is as below\n\n```\n(__main__.OpenAILLM,\n __main__.LLM,\n langchain_openai.chat_models.base.ChatOpenAI,\n langchain_core.language_models.chat_models.BaseChatModel,\n langchain_core.language_models.base.BaseLanguageModel,\n langchain_core.runnables.base.RunnableSerializable,\n langchain_core.load.serializable.Serializable,\n pydantic.v1.main.BaseModel,\n pydantic.v1.utils.Representation,\n langchain_core.runnables.base.Runnable,\n typing.Generic,\n abc.ABC,\n object)\n```\n\nI think this has to do something with pydantic, but I'm not sure. And I don't know how to resolve it. Please help.",
    "Create a New Column Based on the Value of two Columns in Pandas with conditionals\n\nI have a dataframe with two different columns i need to use to calculate a score:\n```\nid        Pos        Player        GW        VP        Final        Drop        TournamentPoints\n0        1        1        Alessio Bianchi        2        7.0        5.0        NaN\n1        2        2        Gianluca Bianco        2        7.0        0.0        NaN\n2        3        2        Sara Rossi        1        5.0        0.0        NaN\n3        4        2        Gabriele Verdi        1        4.5        0.0        NaN\n4        5        2        Luca Gialli        1        3.0        0.0        NaN\n```\n\nTournament points is calculated from GW and VP with a formula:\n```\ndf['TournamentPoints'] = ((number_of_players / 10) * (df[\"VP\"] + 1)) + (df['GW'] * x)\n```\nwhere number_of_players and X are calculated previously.\n\nHowever i need another step:\n1. add 50 to the row with the highest value in \"Final\" columns (in this case Alessio Bianchi)\n2. if two rows have the same value in \"Final\" and it's the highest, only the row with the lowest \"Pos\" must receive the 50 boost",
    "I set up a local simple http server in python on windows.\n\nI set up an HTML file with javascript that uses setInterval() to request a JSON in the local directory every second. (Then updates the webpage with json content.)\n\nGreat, this works. Until after 15-60 seconds, the browser stops making requests, based on the server log in the terminal. The response 304 always precedes the break.\n\nHow can I avoid this and force the server always serve the json file every second?\n\nVery new to this attempt and had to do tricks to make the browser even make the requests for local jsons or so due to security protocols. In part why the server is necessary, as via file:/// it can't be done.\n\nMy thought is change something in the server so if it wants to respond with 304, it will give a 200. I hope if it's always 200, the browser won't pause requests.\n\nMy other thought is ensure the json is always changing, hopefully avoiding the idea of it cached.",
    "I have a dataframe with people and the food they like:\n\n```\ndf_class = pl.DataFrame(\n    {\n        'people': ['alan', 'bob', 'charlie'],\n        'food': [['orange', 'apple'], ['banana', 'cherry'], ['banana', 'grape']]\n    }\n)\nprint(df_class)\n\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 people    \u2506 food      \u2502\n\u2502 ---           \u2506 ---          \u2502\n\u2502 str           \u2506 list[str]   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 alan     \u2506 [\"orange\", \"apple\"]   \u2502\n\u2502 bob      \u2506 [\"banana\", \"cherry\"] \u2502\n\u2502 charlie \u2506 [\"banana\", \"grape\"]  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nAnd, I have a data structure with animals and the things they like to eat:\n\n```\nanimals = [\n    ('squirrel', ('acorn', 'almond')),\n    ('parrot', ('cracker', 'grape', 'guava')),\n    ('dog', ('chicken', 'bone')),\n    ('monkey', ('banana', 'plants'))\n]\n```\n\nI want to add a new column pets in df_class, such that pets is a list of the animals that have at least one food in common with the corresponding person:\n\n```\ndf_class.with_columns(pets=???)   # <-- not sure what to do here\n\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 people            \u2506 fruits                          \u2506 pets                 \u2502\n\u2502 ---                   \u2506 ---                               \u2506 ---                     \u2502\n\u2502 str                  \u2506 list[str]                         \u2506 list[str]              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 alan               \u2506 [\"orange\", \"apple\"]      \u2506 []                       \u2502\n\u2502 bob                \u2506 [\"banana\", \"cherry\"]    \u2506 [\"monkey\"]        \u2502\n\u2502 charlie           \u2506 [\"banana\", \"grape\"]      \u2506 [\"monkey\", \"parrot\"] \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n1. I have some flexibility in the data structure for animals, in case for e.g. this is easier to do with some sort of set intersection\n2. the order of pets is unimportant\n3. pets should contain unique values\n4. I'm looking for a single expression that would achieve the desired result, so as to fit within a larger framework of a list of expressions that perform transformations on other columns of my actual dataset\n\nSide note: my title seems kind of clunky and I'm open to suggestions to reword so that it's easier to find by others that might be trying to solve a similar problem.",
    "I\u00b4ve got the following DataFrame:\n\n                        value\nA   B\n111 2024-03-22 00:00:00 1\n111 2024-03-22 01:00:00 2\n111 2024-03-22 02:00:00 3\n222 2024-03-22 00:00:00 4\n222 2024-03-22 01:00:00 5\n222 2024-03-22 02:00:00 6\nNow I want to resample and sum index B to days and would expect the following result:\n\n                        value\nA   B\n111 2024-03-22 00:00:00 6\n222 2024-03-22 00:00:00 15\nHow can I achieve something like that?\n\nAnother Example would be the following:\n\n                        value\nA   B\n111 2024-03-22 00:00:00 1\n111 2024-03-22 01:00:00 2\n111 2024-03-22 02:00:00 3\n222 2024-03-22 00:00:00 4\n222 2024-03-22 01:00:00 5\n222 2024-03-22 02:00:00 6\n333 2024-03-22 05:00:00 7\nOf which I want the following result with resampling by 1h:\n\n                        value\nA   B\n111 2024-03-22 00:00:00 1\n111 2024-03-22 01:00:00 2\n111 2024-03-22 02:00:00 3\n111 2024-03-22 03:00:00 0\n111 2024-03-22 04:00:00 0\n111 2024-03-22 05:00:00 0\n222 2024-03-22 00:00:00 4\n222 2024-03-22 01:00:00 5\n222 2024-03-22 02:00:00 6\n222 2024-03-22 03:00:00 0\n222 2024-03-22 04:00:00 0\n222 2024-03-22 05:00:00 0\n333 2024-03-22 00:00:00 0\n333 2024-03-22 01:00:00 0\n333 2024-03-22 02:00:00 0\n333 2024-03-22 03:00:00 0\n333 2024-03-22 04:00:00 0\n333 2024-03-22 05:00:00 7\nPandas Version: 2.0.1\n\nI tried using level on resample but that way I lose Index A.\n\nI have the same issue when I have two timestamps in the index and want one to be resampled to days and the other to hours.\n\nI\u00b4ve looked at other answers of related questions here but couldn\u00b4t find a way to get them working for me.",
    "My dataframe looks like\n\n```\ndata = {\n    \"ReportName\": [\"Sample cycle\", 'Message',  \"ID\", \"m1\", \"Uncertainty m1\", \"Message\", \"Sample cycle\", 'Message', \"ID\", \"m0\", \"Uncertainty m0\", \"Message\", \"ID\", \"m1\", \"Uncertainty m1\", \"Message\"],\n    \"Values\": [ \"1\",\"NO\", \"II\", None, None, \"NO\", \"1\", \"NO\", \"ID1\", \"1.8\", \"0.43\", \"NO\", \"ID2\", \"1.5\", \"0.41\", \"NO\"],\n}\n\ndf = pd.DataFrame(data)\n```\n\nI I created a new \"ID\" column with this function\n\n```\ndef extract_id(row):\n    if row['ReportName'] == 'ID':\n        return row['Values']\n    return None\n```\n\nNow I want fill Na with ID from ReportName == 'Sample cycle' to next 'Sample cycle'.\n\nDesired output\n```\n        ReportName Values    ID\n0     Sample cycle      1  None\n1          Message     NO    II\n2               ID     II    II\n3               m1   None    II\n4   Uncertainty m1   None    II\n5          Message     NO    II\n6     Sample cycle      1  None\n7          Message     NO   ID1\n8               ID    ID1   ID1\n9               m0    1.8   ID1\n10  Uncertainty m0   0.43   ID1\n11         Message     NO   ID1\n12              ID    ID2   ID2\n13              m1    1.5   ID2\n14  Uncertainty m1   0.41   ID2\n15         Message     NO   ID2\n```",
    "I wrote a bot that change name of the telegram channel every N minutes But, when name of the channel is changed telegram automaticly send message, that channel name has been changed\n\ni tried bot.delete_message command, but could't figure out how to delete that exact message",
    "I am working on a huge denormalized table on a SQL server (10 columns x 130m rows). Take this as data example :\n\n```\nimport pandas as pd\nimport numpy as np\ndata = pd.DataFrame({\n    'status' :  ['pending', 'pending','pending', 'canceled','canceled','canceled', 'confirmed', 'confirmed','confirmed'],\n    'clientId' : ['A', 'B', 'C', 'A', 'D', 'C', 'A', 'B','C'],\n    'partner' :  ['A', np.nan,'C', 'A',np.nan,'C', 'A', np.nan,'C'],\n    'product' : ['afiliates', 'pre-paid', 'giftcard','afiliates', 'pre-paid', 'giftcard','afiliates', 'pre-paid', 'giftcard'],\n    'brand' : ['brand_1', 'brand_2', 'brand_3','brand_1', 'brand_2', 'brand_3','brand_1', 'brand_3', 'brand_3'],\n    'gmv' : [100,100,100,100,100,100,100,100,100]})\n\ndata = data.astype({'partner':'category','status':'category','product':'category', 'brand':'category'})\n```\n\nAs you can see, many of it columns are categories/strings that could be factorize (replaced by a small int identification to another x.1 join).\n\nMy question is if there is a easy way to extract another \"dataframe\" from each category columns and factory factorize the main table, so the bytes transmitted over a single query could be faster! Is there any easy library for it?\n\nI would expect to get this output:\n\n```\n    data = pd.DataFrame({\n        'status' :  ['1', '1','1', '2','2','2', '3', '3','3'],\n        'clientId' : ['1', '2', '3', '1', '4', '3', '1', '2','3'],\n        'partner' :  ['A', np.nan,'C', 'A',np.nan,'C', 'A', np.nan,'C'],\n        'product' : ['afiliates', 'pre-paid', 'giftcard','afiliates', 'pre-paid', 'giftcard','afiliates', 'pre-paid', 'giftcard'],\n        'brand' : ['brand_1', 'brand_2', 'brand_3','brand_1', 'brand_2', 'brand_3','brand_1', 'brand_3', 'brand_3'],\n        'gmv' : [100,100,100,100,100,100,100,100,100]})\n    \nstatus_df = {1 : 'pending', 2:'canceled', 3:'confirmed'} \nclientid = {1 : 'A', 2:'B', 3:'C', 4:'D'}\n```",
    "Is any supertype and also a subtype of all types in TypeScript?\n\nI am teaching a class on TypeScript fundamentals and I am trying to really understand the relationships between basic TS types. In all articles I saw, they put the any type very close to the top of the type hierarchy. Either\n\n+---------+\n| unknown |\n+---------+\n     |\n     v\n  +-----+\n  | any |\n  +-----+\n     |\n     v\nall other types\nOr maybe\n\n+--------------+\n| any, unknown |\n+--------------+\n     |\n     v\nall other types\nBut I do not see it that way. You can assign value of all other types to an unknown variable but you cannot assign unknown value to anything. That puts it on top. But with any, you can assign all values of all types to any and also assign an any value to variables of all types. So it behaves as uknown and never at the same time. From this I would argue, that any stands completely aside of the type hierarchy tree not fitting anywhere in it. I would say any sidesteps the type system completely and in essence means \"turn off typechecking\"\n\nAm I wrong?",
    "Better option than pandas iterrows\n\nI have following table in pandas. the table contains time and the price of the product.\n\nFor analysis purposes, I want to have 2 columns which would contain the next time when the product is more than $100 price change & less than $100 price change.\n\ne.g. if I am at cell 09:19 cell the next price more than $100 would be 14:02 & less than $100 would be 11:39 so 14:02 & 11:39 should come in 09:19 row in respective columns.\n\nSame way against cell 09:56, next price more than $100 would be 14:02 & less than $100 would be 12:18 so these 2 values would come in against the row of 09:56.\n\n```\nTable\nTime        Price    Up_Time   Down_Time\n09:19:00    3252.25     \n09:24:00    3259.9      \n09:56:00    3199.4      \n10:17:00    3222.5      \n10:43:00    3191.25     \n11:39:00    3143        \n12:18:00    2991.7      \n13:20:00    3196.35     \n13:26:00    3176.1      \n13:34:00    3198.85     \n13:37:00    3260.75     \n14:00:00    3160.85     \n14:02:00    3450        \n14:19:00    3060.5      \n14:30:00    2968.7      \n14:31:00    2895.8      \n14:52:00    2880.7      \n14:53:00    2901.55     \n14:55:00    2885.55     \n14:57:00    2839.05     \n14:58:00    2871.5      \n15:00:00    2718.95\n```\n     \nI am using following code, which works but takes 15-20 mins for 1 dataset.\n\n```\nfor i, row in df.iterrows():\n    time_up = np.nan\n    time_down = np.nan\n\n    for j in range(i+1, len(df)):\n        diff = df.iloc[j]['Price'] - row['Price']\n        if diff > 100:\n            time_up = df.iloc[j]['Time']\n        elif diff < -100:\n            time_down = df.iloc[j]['Time']\n\n        if not pd.isna(time_up) or not pd.isna(time_down):\n            break\n\n    df.at[i, 'Up_Time'] = time_up\n    df.at[i, 'Down_Time'] = time_down\n```\n\nIs there any efficient ways to do it?",
    "Trying to interact with a contract using is function selector, how do i get the block hash?\n\nI have the below code in a index.js file, but when i run it i get an error message: The method eth_sendTransaction does not exist/is not available. Please can anyone help?\n\n```\nrequire('dotenv').config();\nrequire('events').EventEmitter.defaultMaxListeners = 0\n\nconst { ethers } = require('ethers');\n\n// Provider and contract address\nconst provider = new ethers.providers.JsonRpcProvider('https://polygon-mumbai.infura.io/v3/7d803b173d114ba8a1bffafff7ff541a');\nconst wallet = new ethers.Wallet(process.env.KEY, provider)\n//const signer = wallet.provider.getSigner(wallet.address);\nconst contractAddress = '0x57C98f1f2BC34A0054CBc1257fcc9333c1b6730c';\n\n// Function selector\nconst functionSelector = '0x838ad0ee';\n\n\n// Call the contract\nconst send = async () => {\n  try {\n    const result = await wallet.call({\n        to: contractAddress,\n        data: functionSelector\n    });\n    console.log(\"Result:\", result);\n} catch (error) {\n    console.error(\"Error:\", error);\n}\n}\n\nsend()\n```",
    "Selenium Python how to run an XPath error handling exception on loop with multiple def?\n\nis it possible to schedule my code by running it with schedule.every(10).seconds.do(example) or similar? I'm trying to schedule the Error Handling part in my code (XPath) which works with a While loop although because its in a While loop it refuses to run the other def functions, I want the XPath/error handling part to run in a loop with my Selenium window but detect and not interfere with the other def functions. it should just detect the XPath being there or not being there then run an exception if it doesn't detect.. Does anyone have a solution?\n\n```\ndef example():\r\n    options = Options()\r\n    options.add_experimental_option(\"detach\", True)\r\n\r\n    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()),\r\n                              options=options)\r\n\r\n    driver.get(\"example.com\")\r\n    driver.set_window_position(0, 0)\r\n    driver.set_window_size(750, 512)\r\n\r\n    while True:\r\n        e = driver.find_elements(By.XPATH,\"/html/body/div/div/div/div/div[2]/div/div/div[2]/div[2]/div[1]/span/button/span\")\r\n        if not e:\r\n            print(\"Element not found\")\r\n            pyautogui.moveTo(89, 56)\r\n            time.sleep(1)\r\n            pyautogui.click()\r\n\r\n        time.sleep(10)\r\n\r\n\r\ndef example2():\r\n    options = Options()\r\n    options.add_experimental_option(\"detach\", True)\r\n\r\n    driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install()))\r\n\r\n    driver.get(\"example.com\")\r\n    driver.set_window_position(750, 0)\r\n    driver.set_window_size(750, 512)\r\n\r\n    while True:\r\n        e = driver.find_elements(By.XPATH,\"/html/body/div/div/div/div/div[2]/div/div/div[2]/div[2]/div[1]/span/button/span\")\r\n        if not e:\r\n            print(\"Element not found\")\r\n            pyautogui.moveTo(850, 57)\r\n            time.sleep(1)\r\n            pyautogui.click()\r\n\r\nschedule.every().day.at(\"22:59\").do(example)\r\nschedule.every().day.at(\"22:59\").do(example2)\r\n\r\nwhile True:\r\n    schedule.run_pending()\r\n    time.sleep(1)\n```",
    "How to create an image from a string in python\n\nI'm currently having trouble creating an image from a binary string of data in my Python program. I receive the binary data via a socket but when I try the methods I read about in Imaging Library Handbook like this:\n\n\u00b7\u00b7\u00b7\nbuff = StringIO.StringIO() #buffer where image is stored\n#Then I concatenate data by doing a \nbuff.write(data) #the data from the socket\nim = Image.open(buff)\n\u00b7\u00b7\u00b7\nI get an exception to the effect of \"image type not recognized\". I know that I am receiving the data correctly because if I write the image to a file and then open a file it works:\n\n\u00b7\u00b7\u00b7\nbuff = StringIO.StringIO() #buffer where image is stored\nbuff.write(data) #data is from the socket\noutput = open(\"tmp.jpg\", 'wb')\noutput.write(buff)\noutput.close()\nim = Image.open(\"tmp.jpg\")\nim.show()\n\u00b7\u00b7\u00b7\nI figure I am probably doing something wrong in using the StringIO class but I'm not sure",
    "Retrieve bounded time periods as a step function where beginning of period returns 1, end of period returns 0\n\nI have a table in Microsoft SQL Server called Downtime that looks like this (I have omitted some irrelevant columns and many entries):\n\n```\nID        StartTime                                        EndTime\n5        2024-03-27 09:07:20.653        2024-03-27 09:09:07.690\n17        2024-03-27 09:59:50.557        2024-03-27 10:59:50.137\n24        2024-03-27 11:04:07.497        2024-03-27 11:07:02.657\n```\n\nI need to write a query that turns the above data into this format:\n\n```\nt_stamp                                   CurrentlyDown\n2024-03-27 09:07:20.653        1\n2024-03-27 09:09:07.690        0\n2024-03-27 09:59:50.557        1\n2024-03-27 10:59:50.137        0\n2024-03-27 11:04:07.497        1\n2024-03-27 11:07:02.657        0\n```\n\nIn words, this query should split each original entry into two entries (one t_stamp for StartTime and one t_stamp for EndTime) and return a value (CurrentlyDown) of 1 (if t_stamp is from the StartTime column) or 0 (if t_stamp is from the EndTime column).\n\nI can think to try two things:\n\nA self join around the ID field with a CASE statement checking the timestamp fields\nTwo CTE's (one focused on grabbing StartTimes and the other focused on EndTimes) with a final query to join these two CTE's together around the ID column. Maybe just one CTE is needed here?\n\nI am concerned with performance so I want to do this as efficiently as possible. I am far from a SQL expert, so I don't really know which path is best to take (if either).",
    "Why does JavaScript return different results for RegExp test() method with empty object?\n\nI recently came across a code snippet (a joke) where the test() method of JavaScript's RegExp object was used with an empty object as an argument. Here's the code:\n\n```\nconsole.log(new RegExp({}).test('mom')); // true\nconsole.log(new RegExp({}).test('dad')); // false\n```\n\nCan someone explain why is it happens?",
    "Problem generating causal sentences with js [closed]\n\nI am creating a sentence translation app, but I have a problem with the generation of causal sentences. I have to generate the sentences with an external url, but in my code instead of generating me a whole sentence, it only generates one character. Can you help me understand where I am going wrong?\n\n```\n<main>\n  <section class=\"panel translation\">\n    <div class=\"translation-flag\"></div>\n    <button class=\"favorites\">\u2b50</button>\n    <div class=\"translation-result\">\n      <p class=\"translation-text\">Traduzione</p>\n    </div>\n  </section>\n\n  <section class=\"panel controls\">\n    <input class=\"text-input\" type=\"text\" placeholder=\"inserisci il testo da tradurre\">\n    \n    <button class=\"lang-button\" data-lang=\"en\">\ud83c\uddec\ud83c\udde7</button>\n    <button class=\"lang-button\" data-lang=\"fr\">\ud83c\uddeb\ud83c\uddf7</button>\n    <button class=\"lang-button\" data-lang=\"es\">\ud83c\uddea\ud83c\uddf8</button>\n    <button class=\"reset-button\">\u274c</button>\n    <button class=\"random-button\">\n      <i class=\"fa-solid fa-dice icon-dice\"></i>\n    </button>\n  </section>\n\n  <div class=\"panel translate\">\n    <h1>Le tue parole preferite</h1>\n   <ul class=\"translate-favorites\">\n    \n   </ul> \n\n    </p>\n  </div>\n</main>\n\n\n\n const langButtons = document.querySelectorAll('.lang-button');\nconst textInput = document.querySelector('.text-input');\nconst translationText = document.querySelector('.translation-text');\nconst translationFlag = document.querySelector('.translation-flag');\nconst resetButton = document.querySelector('.reset-button');\nconst randomButton = document.querySelector('.random-button');\n\n\n//Funzione per aggiornare la lista delle traduzioni preferite\nfunction updateFavoriteList(translation) {\n  const translateFavorite = document.querySelector('.translate-favorites');\n  translateFavorite.innerHTML = '';\n    translation.forEach(function(translateTexts) {\n      const li = document.createElement('li');\n      li.textContent = translateTexts;\n      translateFavorite.appendChild(li);\n    });\n}\n\nasync function translate(text, lang, flag) {\n  const url = `https://api.mymemory.translated.net/get?q=${text}&langpair=it|${lang}`;\n  const response = await fetch(url);\n  const jsonData = await response.json();\n  const result = jsonData.responseData.translatedText;\n  console.log(result);\n\n  translationText.innerText = result;\n  translationFlag.innerText = flag;\n}\n\nlangButtons.forEach(function(langButton) {\n  langButton.addEventListener('click', function() {\n\n    // recupero il testo dal campo di input e rimuovo eventuali spazi extra\n    // all'inizio e alla fine della stringa inserita con il metodo .trim()\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/trim\n    const text = textInput.value.trim();\n\n    // recupero il codice lingua dal data-attribute del pulsante\n    const lang = langButton.dataset.lang;\n    // recupero la bandierina dalla testo del pulsante\n    const flag = langButton.innerText;\n\n    // se il campo di input ha effettvamente del testo\n    // invoco la funzione e faccio partire la chiamata alle API\n    if(text.length > 0) {\n      translate(text, lang, flag);\n    }\n  });\n});\n\nrandomButton.addEventListener('click', function() {\n  const randomUrls = 'https://random-word-api.herokuapp.com/word?length=5';\n  const randomIndex = Math.floor(Math.random() * randomUrls.length);\n  const randomWork = randomUrls[randomIndex];\n  console.log(randomWork);\n  textInput.value = randomWork;\n});\n\n\n\nresetButton.addEventListener('click', reset);\n```\n\nThe new code for the my question is:\n```\nasync function randomString() {\n  const response = await fetch('https://random-word-api.herokuapp.com/word?lang=it');\n  const work = await response.json();\n  console.log(work);\n  textInput.value = work;\n}\n\nrandomButton.addEventListener('click', function() {\n  randomString();\n});\n```",
    "CannotDeliverBroadcastException On Samsung devices running Android 13 (API 33)\n\nWe got lot of crash reports from Firebase regarding this crash.\n\n```\nFatal Exception: android.app.RemoteServiceException$CannotDeliverBroadcastException: can't deliver broadcast\n       at android.app.ActivityThread.throwRemoteServiceException(ActivityThread.java:2219)\n       at android.app.ActivityThread.-$$Nest$mthrowRemoteServiceException()\n       at android.app.ActivityThread$H.handleMessage(ActivityThread.java:2508)\n       at android.os.Handler.dispatchMessage(Handler.java:106)\n       at android.os.Looper.loopOnce(Looper.java:226)\n       at android.os.Looper.loop(Looper.java:313)\n       at android.app.ActivityThread.main(ActivityThread.java:8762)\n       at java.lang.reflect.Method.invoke(Method.java)\n       at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:604)\n       at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1067)\n```\n\nCrash happens only on Samsung devices running android 13 (API 33)\n\nWe followed this post CannotDeliverBroadcastException only on Pixel devices running Android 12\n\nThe thing is - we can't just silence/absorb this crash, as some of our app functionality is build on the broadcast (BroadcastReceiver, registered in Manifest).\n\nWe need to actually prevent this crash (somehow :))\n\nWe checked also this one on google issue tracker but it seems there is no solution https://issuetracker.google.com/issues/245258072\n\nAny of you found a solution for this? Thanks",
    "How to control Argo(helm) flow with Script output\n\nI have a script defined in Argo WorkflowTemplate as follows. This may either print status:true or status:false (I have simplified this)\n\n```\n- name:util-script\n    script:\n      image: python3\n      command: [\"python3\"]\n      script |\n         print(status:true)\n```\n\nIs there a way to control dag flow based on the above script output? I know helm provides flow control like Helm Doc - Flow control\n\nFollowing is what I tried so far, but this always jumps to else condition. anything Im doing wrong? Appreciate any input on this\n\n```\n{{- if contains \"status:true\" `tasks.util-script.outputs.result` }}\n  # even result is `status:true`, does not reach here\n{{ else }}\n  # always reach here\n{{ end }}\n```\n\nI have verified tasks.util-script.outputs.result indeed returns the expected result.",
    "How can I convert a PredictResponse to JSON?\n\nI have a VertexAI project I want to access. I'm currently trying two approaches, via a React frontend and via a Python backend, which I would then connect to the FE. I posted a question about making requests to VertexAI from Node here.\n\nIn the python approach, I'm able to make the request and receive the correct response. However, in order for it to be accessible by the FE, I would need to convert it to JSON. I'm struggling with how to do that.\n\nHere's the code I'm using:\n\n```\n# The AI Platform services require regional API endpoints.\nclient_options = {\"api_endpoint\": api_endpoint}\n# Initialize client that will be used to create and send requests.\n# This client only needs to be created once, and can be reused for multiple requests.\nclient = PredictionServiceClient(\n    client_options=client_options, credentials=credentials\n)\ninstance = schema.predict.instance.TextClassificationPredictionInstance(\n    content=content,\n).to_value()\ninstances = [instance]\nparameters_dict = {}\nparameters = json_format.ParseDict(parameters_dict, Value())\nendpoint = client.endpoint_path(\n    project=project_id, location=compute_region, endpoint=endpoint_id\n)\nresponse = client.predict(\n    endpoint=endpoint, instances=instances, parameters=parameters\n)\nresponse_dict = [dict(prediction) for prediction in response.predictions]\n```\n\n`response_dict` is printable, but I can't convert `response` to json using `json.dumps` because:\n\n```\nTypeError: Object of type PredictResponse is not JSON serializable\n```\nThis is the error that has been plaguing me in every attempt. DuetAI simply tells me to use `json.dumps`.\n\nEDIT\nHere's the working code using the accepted response:\n```\n    ...\n    response = client.predict(\n        endpoint=endpoint, instances=instances, parameters=parameters\n    )\n\n    predictions = MessageToDict(response._pb)\n    predictions = predictions[\"predictions\"][0]\n```",
    "How can I initialise a constexpr array with values using std::generate\n\nFor example, if I wanted a constexpr std::array<int,100> initialised with all the multiples of 3 from 1-300 at compile time how can I do this?\n\nMy first thought was to use std::generate, something like:\n\n```\nconstexpr std::array<int,100> a { std::generate(a.begin(), a.end(), [n=0]()mutable{ return n+=3; });\n```\n\nI get an error such as `<source>:9:52: error: void value not ignored as it ought to be`.\n\nand I can't use std::generate after this because of course, it's read only at that point.",
    "django add filtes in template is not work expectedly\n\nI am a Django and Python beginner, and I encountered a problem while using Django. I hope to use a filter in the template to get the string I need, but the result below is not what I expected.\n\n```\n# filter definition\n\n@register.filter\ndef to_class_name(obj):\n    return obj.__class__.__name__\n```\n\n```\n# HTML template for UpdateView (This template will be used by multiple models.)\n# object = Order()\n\n{{ object|to_class_name }} #reulst: Order\n\n{{ 'wms'|add:object|to_class_name }} #result: str, expect: object\n\n```\n\nI roughly understand that the issue lies with the order, but it seems I can't add parentheses to modify it.\n\n```\n{{ 'wms'|add:(object|to_class_name) }} #cause SyntaxError\n```\n\nIs there any way to solve this problem? Or is there a better way to determine the page data I need to output based on the model class when multiple models share one template? Thank you all.",
    "Saving a scipy.sparse matrix directly as a regular txt file\n\nI have a scipy.sparse matrix (csr_matrix()). But I need to save it to a file not in the .npz format but as a regular .txt or .csv file. My problem is that I don't have enough memory to convert the sparse matrix into a regular np.array() and then save it to a file. Is there a way to have the data as a sparse matrix in memory but save it directly as a regular matrix to the disk? Or is there a way to \"unzip\" a .npz file without loading it into memory inside Python?",
    "dbms_random.value() in Snowflake - Oracle to snowflake conversion\n\nBelow is the oracle sql query that I got to convert to snowflake. In here, i am blocked in creating dbms_random.value() in snowflake\n\n```\nselect emp_id, emp_name, emp_mob,\n(case when dbms_random.value() >= 0.85 then 'Y' else 'N' end) as tag\nfrom eds_dwg.employee_data\n```\n\nCan someone help me on this?\n\nThanks",
    "Inconsistent delay when using RegisterHotkey and PeekMessagew In Go\n\nI'm trying to write a simple Go program that will listen for global windows hotkeys while in the background and send API calls when specific ones have been pressed. This is my first time learning how to work with Windows messages so this is probably just me not understanding how they work.\n\nMy calls to PeekMessageW often return 0 even though hotkeys are being pressed, and then after a minute or so suddenly returns them all at once. Is this just expected behaviour?\n\nI'm doing everything on the same goroutine. First I create a new window and save the HWND like this:\n\n```\nfunc createWindow(\n    user32 *syscall.DLL,\n    dwExStyle uint32,\n    lpClassName, lpWindowName *uint16,\n    dwStyle uint32,\n    x, y, nWidth, nHeight int,\n    hWndParent, hMenu, hInstance uintptr,\n    lpParam unsafe.Pointer,\n) uintptr {\n    procCreateWindowEx := user32.MustFindProc(\"CreateWindowExW\")\n\n    ret, _, _ := procCreateWindowEx.Call(\n        uintptr(dwExStyle),\n        uintptr(unsafe.Pointer(lpClassName)),\n        uintptr(unsafe.Pointer(lpWindowName)),\n        uintptr(dwStyle),\n        uintptr(x),\n        uintptr(y),\n        uintptr(nWidth),\n        uintptr(nHeight),\n        hWndParent,\n        hMenu,\n        hInstance,\n        uintptr(lpParam),\n    )\n    return ret\n}\n\nfunc GiveSimpleWindowPls(user32 *syscall.DLL) uintptr {\n    var hwnd uintptr\n    className, _ := syscall.UTF16PtrFromString(\"STATIC\")\n    windowName, _ := syscall.UTF16PtrFromString(\"Simple Window\")\n\n    hwnd = createWindow(\n        user32,\n        0,\n        className,\n        windowName,\n        0,\n        0,\n        0,\n        0,\n        0,\n        0,\n        0,\n        0,\n        nil,\n    )\n\n    if hwnd != 0 {\n        fmt.Println(\"HWND:\", hwnd)\n    } else {\n        fmt.Println(\"Could not create window\")\n    }\n    return hwnd\n}\n```\n\nI then register my hotkeys:\n\n```\nfunc Register(user32 *syscall.DLL, hwnd uintptr) (map[int]*Hotkey, error) {\n    reghotkey := user32.MustFindProc(\"RegisterHotKey\")\n\n    // Hotkeys to listen to:\n    // (hardcoded for now)\n    keys := map[int]*Hotkey{\n        6:  {6, ModAlt + ModCtrl + ModShift, '6'},\n        7:  {7, ModAlt + ModCtrl + ModShift, '7'},\n        8:  {8, ModAlt + ModCtrl + ModShift, '8'},\n        9:  {9, ModAlt + ModCtrl + ModShift, '9'},\n        10: {10, ModAlt + ModCtrl + ModShift, '0'},\n    }\n\n    // Register hotkeys:\n    for _, v := range keys {\n        r1, _, err := reghotkey.Call(hwnd, uintptr(v.Id), uintptr(v.Modifiers), uintptr(v.KeyCode))\n        if r1 != 1 {\n            return nil, fmt.Errorf(\"error registering hotkey %#v: %w\", v, err)\n        }\n    }\n    return keys, nil\n}\n```\n\nAnd finally call PeekMessageW in a loop:\n\n```\nconst WM_HOTKEY = 0x0312\n\nfunc Listen(keys map[int]*Hotkey, switcher Switcher, hwnd uintptr) {\n    peekmsg := user32.MustFindProc(\"PeekMessageW\")\n\n    for {\n        var msg = &MSG{}\n        a, _, _ := peekmsg.Call(uintptr(unsafe.Pointer(msg)), hwnd, WM_HOTKEY, WM_HOTKEY, 1)\n        fmt.Printf(\"%#v %d \\n\", msg, a)\n\n        if a == 0 {\n            time.Sleep(time.Millisecond * 50)\n            continue\n        }\n\n        if key, ok := keys[int(msg.WPARAM)]; ok {\n            fmt.Println(\"Hotkey was pressed:\", key)\n\n            switcher.Switch(key.Id) // for now this just does nothing and returns\n        }\n    }\n}\n```\n\nAnd at first this seems to work perfectly, but every minute or so PeekMessageW starts to only return 0 even though I am pressing my hotkeys. Then after a while, it returns all the messages one after the other, as if the queue had congested for a while and finally gets released.\r\n\r\nAm I wrong in expecting to be able to peek WM_HOTKEY messages immediately (or at least within a couple seconds) after the hotkey is pressed? The program sometimes stops receiving these messages for up to a minute at a time, and then suddenly processes them all at once. Is the queue being blocked by some other process I have running that Windows gives priority?\r\n\r\nThis is my first time trying to figure out how this works, but I've spent hours searching for a solution online and can't see where I'm going wrong.",
    "Command-line to reverse byte order/change endianess\n\nI'm hacking around in some scripts trying to parse some data written by Javas `DataOutputStream#writeLong(...)`. Since java always seems to write big endian, I have a problem feeding the bytes to `od`. This is due to the fact that `od` always assumes that the endianess matches the endianess of the arch that you are currently on, and I'm on a little endian machine.\n\nI'm looking for an easy one-liner to reverse the byte order. Let's say that you know that the last 8 bytes of a file is a long written by the aforementioned `writeLong(...)` method. My current best attempt to print this long is\n\n```\ntail -c 8 file | tac | od -t d8\n```\n\n, but `tac` only seems to work on text (fair enough). I've found some references to `dd conv=swab`, but this only swaps bytes in pairs, and cannot reverse these eight bytes.\n\nDoes anyone know a good one-liner for this?",
    "How to disable Swagger ui documentation in Fastapi for production server?\n\nHow to disable Swagger ui documentation in Fastapi for production server? i need disable fastapi documentation",
    "Django-Forms with json fields\n\nI am looking to accept json data in a form field and than validate it using some database operations. The data will mostly consist of an array of integers. So can you please help me as to how can i do so.\n\nI have tried to google this but didn't get any decent answer. Please help.",
    "Vectorization with multiple rows and columns of dataframe instead of one\n\nCurrently working on building a csv file that include historical stock info, while not only includes historical prices, but momentum indicators. I've successfully added indicators by looping through an entire dataframe (w/ > 25,000,000 rows), but it takes too long (30 - 36 h).\n\nWhat I'm trying to accomplish: I'd like start with the the 3 day high:\n\n```\nhigh = stock_df.loc[x+1:x+4, \"High\"].max(axis=0)\n```\n\nand divide that by the day 0 low:\n```\nlow =  stock_df.loc[x, \"Low\"] \n```\n\nwithout iterating through entire loop like as shown below:\n```\nstock_ticker_list = df.Symbol.unique()\nfor ticker in stock_ticker_list:\n    #return dataframe thats historical infor for one stock\n    print(ticker)\n    stock_df = df.loc[df.Symbol == ticker]\n    start = stock_df.index[stock_df['Symbol'] == ticker][0]\n    for x in range(start, start + len(stock_df) - 2):\n        try:\n            high = stock_df.loc[x+1:x+4, \"High\"].max(axis=0)  \n            low =  stock_df.loc[x, \"Low\"] \n            df2.loc[x,\"H/L\"] = high/low\n        except:\n            df2.loc[x,\"H/L\"] = pd.NA\n```\n\nI've look through the documentation and found methods like pandas.Series.pct_change and pandas.Series.div but it does not appear as though these functions will work without me also creating a column for the 3 day high. I tried to create a column for the three day high\n\n```\ns = stock_df[\"High\"] \nstock_df['Three_day_high'] = max([s.diff(-1),s.diff(-2),s.diff(-3)]) + s\n```\n\nbut got a ValueError (`ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().`)",
    "What effect does the `virtual` modifier have on an interface member?\n\nSay I have an interface like interface IThing { virtual string A => \"A\"; }. What effect does the virtual keyword have on implementing types here? Surprisingly, I couldn't find anything regarding this on either SO, dotnet GitHub pages and discussions, nor on learn.microsoft.com, possibly buried under all the unrelated content where the words interface and virtual appear in any combination. From my quick testing it doesn't appear to have any sensible effect. My intuition tells me to expect from the implementing classes' hierarchy to have been introduced the given virtual members, as if the base implementing class has declared them itself, but it's not the case.\n\nFor example:\n```\nclass Thing: IThing\n{   \n}   \n    \nclass Thing2: Thing\n{\n    override public string A => \"!\"; // ERROR: No suitable method found to override.\n}\n```\n\nIf I declare the A property on Thing, but do not declare it explicitly as virtual, it still won't compile. I also have the freedom apparently to just define them w/o the modifier despite it being present in the interface and it compiles. And code using IThing only sees the default implementation of A regardless of what I do unless the class implements the interface directly and not through inheritance in this setup.\n\nCan somebody clarify the use of the virtual modifier on interface members? I use the latest stable language version of C#.",
    "Child component not re-rendering after parent component gets updated\n\nI have 1 parent(Container) and 2 (List, SelectedItem) child components, Initially I render all data to Container and send all data to list and first item as selectedItem to selected Item component. So ar so good\n\nWhen a user clicks an item in the List component, it updates the selected item of the Parent through a function, the parent is able to update state, But it is not re-rendering selected item component.\n\nList Component:\n```\n import \"./SelectedImage.css\"\n\nfunction ListSection({items, updateSelectedItem}) {\n  return (\n    <div className=\"list-section\">\n      <ul>\n        {\n          (items).map((item) => {\n            return <li key={item.id} onClick={() => updateSelectedItem(item.id)}>{item.name}</li>\n          })\n        }\n      </ul>\n    </div>\n  );\n}\n\nexport default ListSection;\n```\n\nContainer Component\n```\nimport LeftSection from './LeftSection';\nimport logo from './logo.svg';\nimport RightSection from './RightSection ';\nimport SelectedItem from './SelectedItem';\nimport \"./App.css\";\nimport ListSection from './ListSection';\nimport { Component, useState } from 'react';\n\nconst products = [\n  {id: 1, name: \"Lime\", size: [\"large\", \"medium\", \"small\"], category: \"Juice\", image: \"lime-juice.jpg\"},\n  {id: 2, name: \"Orange\", size: [\"large\", \"medium\", \"small\"], category: \"Juice\", image: \"orange-juice.jpg\"},\n  {id: 3, name: \"Mango\", size: [\"large\", \"medium\", \"small\"], category: \"Juice\", image: \"mango-juice.jpg\"},\n]\n\nfunction Container() {\n  let [selectItem, setSelectItem] = useState(products[0]);\n\n  function chooseSelectedItem(id) {\n    let item = products.filter((value) => {\n      console.log(value.id);\n      return (value.id == id)\n    })\n    setSelectItem(item[0]);\n    console.log(item[0]);\n  }\n\n  return (\n    <div className=\"Container\">\n      <ListSection items={products} updateSelectedItem={chooseSelectedItem}/>\n      <SelectedItem CurrentSelectedItem={selectItem}/>\n    </div>\n  );\n}\n\nexport default Container;\n```\n\nSelectedItemComponent\n\n```\nimport QuantityBar from \"./QuantityBar\";\nimport \"./SelectedImage.css\"\nimport { useState } from \"react\";\n\nfunction SelectedItem({CurrentSelectedItem}) {\n  let [item, setItem] = useState(CurrentSelectedItem);  \n\n  return (\n    <div className=\"selected-item\">\n      {/* <img src={item.image} className=\"selected-image\" /> */}\n      {item.name}\n      {/* <QuantityBar itemCount={0} /> */}\n    </div>\n  );\n}\n\nexport default SelectedItem;\n```",
    "How to show python/openCV outcome images on ssh-client, not in ssh server?\n\nI am connected to a ssh server using ssh -Y username@adress. On the server I run python2.7 using IDLE. If I use matplotlib I can see the outcome graphs on client. This suggests the graphical forwarding has no problem. However, when I am using OpenCV:\n\n```\ncv2.imshow('img_final', img_final)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n```\n\nIt opens and show the image in the ssh server screen, not in the client ssh computer.\n\nI did search and research, and in response of typical trobleshooting: - On my computer running client-ssh, echo $DISPLAY responds :0. It runs xterm. -On my server ssh computer, My sshd_config file seems to be ok (X11Forwarding yes). echo $DISPLAY shows localhost:10.0.\n\nMoreover, I can use imageviewer such as 'feh' and shows images on client without any problem.\n\nI do not think I have a configuration problem, because server is able to display graphics on client.\n\nIs there a way to execute python scripts on server, and show outcome images from OpenCV directly on client (as MAtplotlib does) ?\n\nThanks",
    "Selenium code working fine on main laptop, but not on my other one\n\nI wrote some code in Pycharm last year, to loop through VAT numbers entered into the Gov website, to make sure they were still valid. It still works fine on the original laptop, but not on my other laptop, even thought the code is exactly the same (the only adjustment was for the location of the spreadsheet). I have given my code down below. When I try to run it on my other laptop, it comes up with the following error.\n\n```\nTraceback (most recent call last): File \"C:\\Users\\neils\\Documents\\Pycharm Projects\\VATChecker\\VATChecker.py\", line 30, in VAT = web.find_element_by_xpath('//*[@id=\"target\"]') ^^^^^^^^^^^^^^^^^^^^^^^^^ AttributeError: 'WebDriver' object has no attribute 'find_element_by_xpath'\n\nProcess finished with exit code 1\n```\n\nOne thing I also notice, is that the import sys and import datetime are both greyed out. I guess that's because it crashed before these imports were used?\n\nI should mention, the version of Chrome is the same for both laptops (version 123), and I have the same chromedriver installed for both. Both laptops are windows 64 bit, in case you're thinking that might be the issue.\n\nAre you able to advise me what the problem is please? Many thanks in advance.\n\n```\nimport datetime\nimport sys\n\nfrom selenium import webdriver\nfrom openpyxl import workbook, load_workbook\nfrom datetime import date\n\nweb = webdriver.Chrome()\n\nwb = load_workbook('C:\\\\Users\\\\neils\\\\Documents\\\\NSO\\\\Self Billing agreements\\\\VATMusiciansCheckerUK.xlsx', data_only=True, read_only=False)\n\nws = wb.active\nx=2\ny=1\ncurrent_datetime = datetime.datetime.now()\ncurrent_datetime.strftime('%x %X')\n\ninvalid = \"\"\n\nwhile ws.cell(x,1).value !=None:\n\n    ws.cell(x,9).value = \"\"\n\n    web.get(\"https://www.tax.service.gov.uk/check-vat-number/enter-vat-details\")\n\n    web.implicitly_wait(10)\n\n    VatNumber = ws.cell(x,4).value\n\n    VAT = web.find_element_by_xpath('//*[@id=\"target\"]')\n    VAT.send_keys(VatNumber)\n\n    VAT.submit()\n\n    web.implicitly_wait(4)\n\n    registered = web.find_element_by_xpath('/html/body/div[2]')\n    if (registered.text.find(\"Invalid\")) > 0:\n        ws.cell(x,9).value = \"Invalid VAT number\"\n        invalid = invalid + str(y) + \" \" + ws.cell(x,1).value + \" \" + ws.cell(x,2).value + \", \"\n        y=y+1\n    else:\n        ws.cell(x,9).value = \"Valid VAT number\"\n\n        ws.cell(x,6).value = current_datetime\n\n    x=x+1\n\nif invalid == \"\":\n\n    print(\"All VAT records are correct\")\nelse:\n   print(\"Invalid VAT records are \" + invalid)\n\n\nwb.save('C:\\\\Users\\\\neils\\\\Documents\\\\NSO\\\\Self Billing agreements\\\\VATMusiciansCheckerUK.xlsx')\n```",
    "Getting a list of occurrences for a given vCalendar\n\nI'm trying to use vobject, without success, to get a list of datetime objects for all event occurrences (see the RRULE paramether that sets the event to be repeated daily until a date) for a given vCalendar, which seems to be well-formatted (apparently):\n\n```\nBEGIN:VCALENDAR\nCALSCALE:GREGORIAN\nPRODID:iCalendar-Ruby\nVERSION:2.0\nBEGIN:VEVENT\nDTEND:20110325T200000\nDTSTAMP:20110926T135132\nDTSTART:20110325T080000\nEXDATE:\nRRULE:FREQ=DAILY;UNTIL=20110331;INTERVAL=1\nSEQUENCE:0\nUID:2011-09-26T13:51:32+02:00_944954531@cultura0306.gnuine.com\nEND:VEVENT\nEND:VCALENDAR\n```\n\nDocumentation is not really friendly, and google results are scarce...Any idea or example? (the example can be for vobject or any other library or method).\n\nThanks!\n\nH.",
    "Issue with Passing Retrieved Documents to Large Language Model in RetrievalQA Chain\n\nI'm currently enrolled in a course on Coursera where I'm learning to implement a retrieval-based question-answering (RetrievalQA) system in Python. The course provides code that utilizes the RetrievalQA.from_chain_type() method to create a RetrievalQA chain with both a large language model (LLM) and a vector retriever.\n\nUpon reviewing the provided code, it's evident that relevant documents are retrieved from the vector store using vectordb.similarity_search(). However, there doesn't appear to be a clear step for explicitly passing these retrieved documents to the LLM for question-answering within the RetrievalQA chain.\n\nMy understanding is that in a typical RetrievalQA process, relevant documents retrieved from the vector store are subsequently passed to the LLM. This ensures that the LLM can utilize the retrieved information to generate accurate responses to user queries.\n\nI'm seeking clarification on the proper methodology for integrating the retrieved documents into the RetrievalQA chain to ensure effective utilization by the LLM. Any insights, suggestions, or code examples on how to achieve this integration would be greatly appreciated. Thank you for your assistance!\n\n```\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings.openai import OpenAIEmbeddings\npersist_directory = 'docs/chroma/'\nembedding = OpenAIEmbeddings()\nvectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\nquestion = \"What are major topics for this class?\"\ndocs = vectordb.similarity_search(question,k=3)\nlen(docs)\nfrom langchain.chat_models import ChatOpenAI\nllm = ChatOpenAI(model_name=llm_name, temperature=0)\nfrom langchain.chains import RetrievalQA\n\nqa_chain = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever()\n)result = qa_chain({\"query\": question})\nresult[\"result\"]\n```",
    "How i can send TOO MANY requests to DEFFERENT sites and get responses?\n\nHow can I send a lot of requests to DIFFERENT sites, I have a database of sites (1kk) and need to check whether they are alive or not, conditionally if you just do it through grequests(python) chunks of software (100 requests in 10 threads ~128second) it will take 12.5 days, but for me it's too long and I I am sure that this can be done much faster. Can you tell me what I can use in this case? I'm just collecting information about the main page of the sites.\r\n\r\nHere is my code, I want to improve it somehow, what can you recommend? I tried to throw every request into the stream, but it feels like something is blocking it, I will use a proxy so that my IP is not blocked due to more requests Help who can!\n\n```\ndef start_parting(urls:list,chunk_num,chunks):\r\n    if len(urls)>0:\r\n        chunk_num+=1\r\n        print(f'Chunck [{Fore.CYAN}{chunk_num}/{chunks}{Style.RESET_ALL}] started! Length: {len(urls)}')\r\n        headers = {\r\n            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"}\r\n        rs = [grequests.get(url.split(' ')[0].strip(), headers=headers,timeout=10) for url in urls]\r\n        responses = grequests.map(rs)\r\n        for response in responses:\r\n            if response is None:\r\n                continue\r\n            if response.status_code == 200:\r\n                check_pattern = r'(pat1|pat2)'\r\n                match = re.search(check_pattern, response.text, re.IGNORECASE)\r\n                if match:\r\n                    site = match.group(1)\r\n                    print(f'Site {site}')\r\n        print(f'Chunck [{Fore.LIGHTCYAN_EX}{chunk_num}/{chunks}{Style.RESET_ALL}] ended!')\r\n\r\ndef test_sites_for_file(file,num_threads = 10,chunk_size=100):\r\n    print('Start check!')\r\n    urls = file.readlines()\r\n    with ThreadPoolExecutor(max_workers=num_threads) as executor:\r\n        parts = [urls[i:i + chunk_size] for i in range(0, len(urls), chunk_size)]\r\n        finals = [executor.submit(start_parting, part , part_num,len(parts)) for part_num,part in enumerate(parts)]\r\n        t = time.time()\r\n        for final in as_completed(finals):\r\n            pass\r\n        print(f'Resultate: {time.time()-t}')\n```",
    "How can I observe the attribute lookup chain in Python?\n\nI am trying to delve into Python's class descriptors, and have come across an article explaining the lookup chain of class attributes. Namely, it is said that the first priority is the __get__ method of the data descriptor (that is, a class that implements __set__ or __delete__ method. Then comes the dict of the object followed by get method of non-data descriptor.\n\nThis seems extremely confusing to me, and I am hopeless to find a real example demonstrating how, say, data descriptors come before dict lookup of an instance. I would really appreciate a minimum example with prints that illustrates this theoretical stuff.",
    "EF Core ignore column when requesting a list, but include when getting by Id\n\nI have a list of invoices, which have generated files which are stored in the database.\n\nI want to avoid loading the file data itself when retrieving a list of the invoices, but load it when the user clicks the download button for it.\n\nIs there a way to achieve this? I saw the ignore for fluent configuration but it ignores it all the time.\n\nExample code:\n\nClass:\n```\npublic class InvoiceFile\n{\n    public Guid Id { get; set; }\n    public string FileName { get; set; }\n    public byte[] File { get; set; }\n\n    public Guid InvoiceId { get; set; }\n    public Invoice Invoice { get; set; }\n}\n```\n\nI want the File property to be ignored in the first query, but loaded in the second:\n\n```\nvar invoices = await _payoutDbContext.Invoices\n    .Include(x => x.InvoiceFiles)\n    .AsNoTracking()\n    .AsSplitQuery()\n    .ToListAsync();\nvar file - await _payoutDbContext.InvoiceFiles\n    .Where(x => x.Id == invoiceId)\n    .AsNoTracking()\n    .FirstOrDefaultAsync();\n```",
    "Static data member of template class type: constexpr vs. const constinit\n\nI have a class:\n\n```\n#include <array>\n\ntemplate<class T, std::size_t N>\n    requires std::is_arithmetic_v<T> && (N >= 1)\nclass Vector\n{\n    static constexpr std::size_t Dimension = N;\n    std::array<T, Dimension> Elements;\n\npublic:\n    constexpr Vector() noexcept : Elements{} {}\n    constexpr ~Vector() = default;\n    static constexpr Vector ZeroVector{};\n};\n\nint main()\n{\n    Vector<float, 7> boo = Vector<float, 7>::ZeroVector;\n}\n```\n\nThe above fails to compile on compiler explorer with MSVC and Clang (trunk) with C++23 compiler flags, but it compiles on GCC (trunk) with C++23 compiler flags.\n\nClang gives the following error:\n\n```\n<source>:13:29: error: constexpr variable cannot have non-literal type 'const Vector<float, 7>'\n   13 |     static constexpr Vector ZeroVector{};\n      |                             ^\n<source>:18:28: note: in instantiation of template class 'Vector<float, 7>' requested here\n   18 |     Vector<float, 7> boo = Vector<float, 7>::ZeroVector;\n      |                            ^\n<source>:13:29: note: incomplete type 'const Vector<float, 7>' is not a literal type\n   13 |     static constexpr Vector ZeroVector{};\n      |                             ^\n<source>:5:7: note: definition of 'Vector<float, 7>' is not complete until the closing '}'\n    5 | class Vector\n      |       ^\n1 error generated.\nCompiler returned: 1\n```\n\nMSVC gives the following error:\n```\n<source>(13): error C2027: use of undefined type 'Vector<float,7>'\n<source>(5): note: see declaration of 'Vector<float,7>'\n<source>(13): note: the template instantiation context (the oldest one first) is\n<source>(18): note: see reference to class template instantiation 'Vector<float,7>' being compiled\nCompiler returned: 2\n```\n\nWhen I change constexpr to const constinit for ZeroVector, this compiles on all three major compilers when the definition is moved outside the class like so:\n\n```\ntemplate<class T, size_t N> requires std::is_arithmetic_v<T> && (N >= 1)\nconst constinit Vector<T, N> Vector<T, N>::ZeroVector{};\n```\n\nSo why does constexpr compile only on GCC and const constinit compiles on all three major compilers?",
    "What is \"Verbose_name\" and \"Ordering\" in class Meta? And please explain a little about Meta Class in django\n\n```\nfrom django.db import models\r\nimport uuid\r\nclass Book(models.Model):\r\n    name=models.CharField(max_length=100)\r\n    isbn=models.UUIDField(default=uuid.uuid4, \r\n    primary_key=True)\r\n    writer=models.CharField(max_length=100)\r\n    \r\n    class Meta:\r\n        ordering=['name']\r\n        ordering='User MetaData\n```",
    "Next.js (react) to format date and time using moment or not\n\nwhat is best for my next front-end app to handle date format using Moment.js or JS functions? Data come from the backend in the date type and I want it to appear in a readable format according to performance and loading time.\n\n```\nMon Apr 01 2024 14:47:56 GMT+0300 (GMT+03:00) \n```\nThis must format to:\n```\n01/04/2024 02:48 pm\n```",
    "What is the purpose of leading slash in HTML URLs?\n\nI have noticed that some blogs posts have links using a value starting with / in the href.\n\nFor example:\n```\n<a href=\"/somedir/somepage.html\">My Page</a>\n\nDoes the leading `/` mean the path is starting from the site root?\r\n\r\nIn other words, if the site URL is `www.mysite.com`, the effective `href` value is `www.mysite.com/somedir/somepage.html`?\r\n\r\nIs this a convention accepted in all browsers?",
    "Why does ExecuteNonQuery() always return -1?\n\nIve used this method before to return the amount of rows changed. I am it to run an insert method, the insert runs fine in the stored procedure, but the return value from `ExecuteNonQuery()` always returns `-1`.\n\nHere is my C# code:\n\n```\nint ret = 0;\r\n\r\nusing (SqlConnection conn = new SqlConnection(this.ConnectionString))\r\n{\r\n    using (SqlCommand cmd = new SqlCommand(QueryName, conn))\r\n    {\r\n        conn.Open();\r\n\r\n        if (Params != null)\r\n            cmd.Parameters.AddRange(Params);\r\n\r\n        cmd.CommandType = CommandType.StoredProcedure;\r\n        \r\n        ret = cmd.ExecuteNonQuery();\r\n\r\n        conn.Close();\r\n    }\r\n}\r\n\r\nreturn ret;\n```\nWhy do I get -1 instead of the actual number of rows changed?",
    "SharePoint Online Error: The remote server returned an error: (403) Forbidden\n\nI would like to connect a SharePoint Online with the current user on .NET with Single Sign On. I don't want to specify a username and password in my code. Unfortunately, I've the following error message on ExecuteQuery():\n\nThe remote server returned an error: (403) Forbidden\n\nMy code:\n```\nstring siteCollectionUrl = \"https://xxx.sharepoint.com/teams/yyyy\";\r\nSystem.Net.ICredentials credentials = System.Net.CredentialCache.DefaultNetworkCredentials;\r\nSharePoint.ClientContext context = new SharePoint.ClientContext(siteCollectionUrl);\r\ncontext.Credentials = credentials;\r\nSharePoint.Web web = context.Web;\r\ncontext.Load(web);\r\ncontext.ExecuteQuery();\r\nstring tt = web.Title;\n```",
    "Accessing user provided env variables in cloudfoundry in Spring Boot application\n\nI have the following user provided env variable defined for my app hosted in cloudfoundry/pivotal webservices:\n\n```\nMY_VAR=test\n```\nI am trying to access like so:\n```\nSystem.getProperty(\"MY_VAR\")\n```\nbut I am getting null in return. Any ideas as to what I am doing wrong would be appreciated.",
    "Container on custom network - can't reach from host machine\n\nI created two Docker images and ran them. One is a simple Flask application (for testing purposes only) and the other is a PostgreSQL.\nI attached the code, Dockerfiles, and commands I use to run them below.\nI have tested simple commands like curl from the Flask container interactive mode, it communicates with the DB container successfully and does what it needs to do.\nBut here's the problem - whenever I try to reach it using the host machine (and I tried this on both MacOS and Ubuntu machines), by using localhost:8080 or 127.0.0.1:8080 or even the network's IP (the network I created, command is below), it simply won't reach the Flask container. Meaning I can't even check the container's logs to see what is happening because it doesn't get there.\nI checked the firewall to make sure nothing is blocked and I have tried mapping the container to a different port on my machines... didn't work.\nWould love some help trying to understand why is that happening.\n\napp.py:\n\n```\nfrom flask import Flask, request, jsonify\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_migrate import Migrate\n\napp = Flask(__name__)\napp.config['SQLALCHEMY_DATABASE_URI'] = 'postgresql://postgres:postgres@my-postgres-container:5432/db'\n\ndb = SQLAlchemy(app)\n\nmigrate = Migrate(app, db)\n\nclass MyUser(db.Model):\n    id = db.Column(db.Integer, primary_key=True)\n    name = db.Column(db.String(50), unique=True, nullable=False)\n\n@app.route('/users', methods=['POST'])\ndef create_user():\n    data = request.get_json()\n    new_user = MyUser(name=data['name'])\n    db.session.add(new_user)\n    db.session.commit()\n    return jsonify({'message': 'New user created!'})\n\n@app.route('/users', methods=['GET'])\ndef get_all_users():\n    users = MyUser.query.all()\n    output = []\n    for user in users:\n        user_data = {'id': user.id, 'name': user.name}\n        output.append(user_data)\n    return jsonify({'users': output})\n\nif __name__ == '__main__':\n    app.run(debug=True, host='0.0.0.0')\n```\n\nDockerfile-app:\n\n```\nFROM python:3.8-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\n\nEXPOSE 5000\n\nENTRYPOINT [\"bash\", \"-c\"]\nCMD [\"flask db init && flask db migrate && flask db upgrade && flask run\"]\n```\n\nDockerfile-db:\n```\nFROM postgres:latest\n\nENV POSTGRES_USER postgres\nENV POSTGRES_PASSWORD postgres\nENV POSTGRES_DB db\n\nEXPOSE 5432\n\nCMD [\"postgres\"]\n```\nrequirements.txt:\n```\nalembic==1.13.1\nblinker==1.7.0\nclick==8.1.7\nFlask==3.0.2\nFlask-Migrate==4.0.7\nFlask-SQLAlchemy==3.1.1\nitsdangerous==2.1.2\nJinja2==3.1.3\nMako==1.3.2\nMarkupSafe==2.1.5\npsycopg2-binary==2.9.9\nSQLAlchemy==2.0.29\ntyping_extensions==4.10.0\nWerkzeug==3.0.1\n```\n\nCommands I use to run them:\n```\ndocker network create my-network\ndocker volume create my-volume\ndocker build -t my-postgres -f Dockerfile-db .\ndocker run -d -p 5432:5432 --name my-postgres-container --network my-network -v my-volume:/var/lib/postgresql/data my-postgres\ndocker build -t my-app -f Dockerfile-app .\ndocker run -d -p 8080:5000 --name my-app-container --network my-network my-app\n```",
    "R piping: object not found. What am I missing?\n\nSo this is really a basic question, however I am stuck with trying to use the following basic code:\n\n```\ndc_test |> table(testVar)\n```\n\nIt leads to:\n```\nError: Object 'testVar' not found\n```\ndc_test is a data.frame. The column testVar is \"character\" class.\r\n\r\nIt works without an error if i directly use the table() function, however this is not as handy for including filtering and other operations:\n```\ntable(dc_test$testVar)\n```\n-> I get the table without an error.\r\n\r\nDoes the table() function not work with piping or am I using it wrong?\r\n\r\nI tried\n```\ndc_test |> table(testVar)\r\ndc_test |> table(data = _$testVar)\n```",
    "Getting error \"Get-LMFunctionList : The security token included in the request is invalid\" when using PowerShell function Get-LMFunctionList\n\nI am trying to run the PowerShell command Get-LMFunctionList -Region \"eu-west-1\" after importing the module AWS.Tools.Lambda. I am using PowerShell version 5.1 and AWS.Tools.Lambda version 4.1.530.\n\nWhen I run the command I get the error message\n```\nGet-LMFunctionList : The security token included in the request is invalid\n```\n\nIf I try to run the equivalent command via the AWS CLI (i.e. aws lambda list-functions --region eu-west-1) everything runs fine and I get a list of functions with their details. So it looks like this is specific to the PowerShell command.\n\nI have tried all the suggestions listed in the Stack Overflow article How can I resolve the error \"The security token included in the request is invalid\" when running aws iam upload-server-certificate? but none of these answers have solved my issue.\n\n1. I created a new access key and secret key and added them to the credentials file\n2. I regenerated the .aws\\credentials file using the command aws configure\n3. I have restarted the session multiple times\n4. I am not using a session key to connect\n5. It is not a profile problem because it works when I use the AWS CLI\n6. There were no cache files at ~\\.aws\\cli\\cache\\",
    "Quantization and torch_dtype in huggingface transformer\n\nNot sure if its the right forum to ask but.\r\n\r\nAssuming i have a gptq model that is 4bit. how does using from_pretrained(torch_dtype=torch.float16) work? In my understanding 4 bit meaning changing the weights from either 32-bit precision to 4bit precision using quantization methods.\r\n\r\nHowever, calling it the torch_dtype=torch.float16 would mean the weights are in 16 bits? Am i missing something here.",
    "Is it possible to sort a ES6 map object?\n\nIs it possible to sort the entries of a es6 map object?\n```\nvar map = new Map();\r\nmap.set('2-1', foo);\r\nmap.set('0-1', bar);\n```\n\nresults in:\r\n```\nmap.entries = {\r\n    0: {\"2-1\", foo },\r\n    1: {\"0-1\", bar }\r\n}\n```\n\nIs it possible to sort the entries based on their keys?\r\n```\nmap.entries = {\r\n    0: {\"0-1\", bar },\r\n    1: {\"2-1\", foo }\r\n}\n```",
    "Count number of items in an array with a specific property value\n\nI have a Person() class:\n```\nclass Person : NSObject {\n\n    var firstName : String\n    var lastName : String\n    var imageFor : UIImage?\n    var isManager : Bool?\n\n    init (firstName : String, lastName: String, isManager : Bool) {\n        self.firstName = firstName\n        self.lastName = lastName\n        self.isManager = isManager\n    }\n}\n```\n\nI have an array of Person()\n```\nvar peopleArray = [Person]()\n```\n\nI want to count the number of people in the array who have\n```\nisManager: true\n```\n\nI feel this is out there, but I can;t find it, or find the search parameters.\r\n\r\nThanks.",
    "Refreshing UI with FutureBuilder or StreamBuilder\n\nI have been using a FutureBuilder to read data from an api, and update the UI when it completes. All good, but now I want to refresh this every 5 minutes. I thought I could do this with a Timer. My code\n\n```\nclass _MyTileState extends State<MyTile> {\n\n  late Future<MyData?> myFuture = fetchMyData();\n\n  @override\n  Widget build(BuildContext context) {\n    return Column(\n      children: [\n        FutureBuilder<MyData?>(\n          future: myFuture, \n          builder: (BuildContext context, AsyncSnapshot<MyData?> snapshot) {\n            if (snapshot.connectionState == ConnectionState.waiting) {\n              return CircularProgressIndicator();\n            } else if (snapshot.hasError) {\n              return Text('Error: ${snapshot.error}');\n            } else {\n              return Text(snapshot.data.title);\n            }\n          },\n        ),\n      ],\n    );\n  }\n\n  Future<MyData?> fetchMyData() async {\n    var myData = await readMyData();\n    return myData;\n  }\n```\n\nIf I add a timer I get an error message : The instance member 'fetchMyData' can't be accessed in an initializer\n```\nTimer timer = Timer(Duration(minutes: 5), () {\n    myFuture = fetchMyData();\n    setState(() {});\n});\n```\n\nWhile trying to sort this, it has become apparent that FutureBuilder should not be used to refresh. Instead use a StreamBuilder. But this just displays the CircularProgressIndicator and only appears to run once\n```\n  StreamBuilder<MyData>(\n    stream: fetchMyDataStream(),\n    builder: (context, snapshot) {\n    if (snapshot.connectionState == ConnectionState.active) {\n      return Text(snapshot.data.title);\n    }\n\n    return CircularProgressIndicator();\n    }\n  ),\n\n\n  Stream<MyData> get fetchMyDataStream() async* {\n    print(\"start fetch my data stream\");\n    \n    await Future.delayed(Duration(seconds: 5)); // set to seconds for testing\n\n    var myData = await readMyData();\n    yield myData;\n  }\n}\n```\nI am trying to work out which way I should be going - FutureBuilder or StreamBuilder? And for the preferred option, what I am doing wrong.",
    "What is the best way to slice a dataframe up to the first instance of a mask?\n\nThis is my DataFrame:\n```\nimport pandas as pd\ndf = pd.DataFrame(\n    {\n        'a': [10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70],\n        'b': [1, 1, 1, -1, -1, -2, -1, 2, 2, -2, -2, 1, -2],\n    }\n)\n```\n\nThe mask is:\n```\nmask = (\n    (df.b == -2) &\n    (df.b.shift(1) > 0)\n)\n```\n\nExpected output: slicing df up to the first instance of the mask:\n```\n   a  b\n0  10  1\n1  15  1\n2  20  1\n3  25 -1\n4  30 -1\n5  35 -2\n6  40 -1\n7  45  2\n8  50  2\n```\n\nThe first instance of the mask is at row 9. So I want to slice the df up to this index.\n\nThis is what I have tried. It works but I am not sure if it is the best way:\n```\nidx = df.loc[mask.cumsum().eq(1) & mask].index[0]\nresult = df.iloc[:idx]\n```",
    "Is there a reason why I am getting a null-related error in this code\n\n```\ndata class Person(val name: String, val age: Int)\n\nfun checkNameOccurrence(people: List<Person>): Map<String, Int>{\n    // The map has a key that represents a name and a value of how many times that name is repeated\n    val namesMap: MutableMap<String, Int> = mutableMapOf()\n    for(person in people){\n        if(person.name in namesMap.keys){\n            namesMap[person.name] += 1\n        }\n        namesMap[person.name] = 1\n    }\n    return namesMap\n}\n```\n\nI don't understand the reason for the null-related error in the code. Isn't that code block only meant to run if the key is found in the map, how is there still be a null error. I'm partly new to Kotlin and I've only worked on python before (there weren't any issues with null values in python)",
    "How can we check the format of the date coming in Payload using Dataweave\n\nWe have a requirement where the source is a file and it has a date field that can contain different date format. For example MM/dd/yyyy or MM/dd/yy or MM-dd-yyyy or MM-dd-yy. This date field we want to finally convert into MM-dd-yyyy\n\nHow can we check the date format from source and accordingly transform it into required format? or is there a way where we can transform any date format into desired format?\n\nInput:\n```\n[\n    {\n        \"date\": \"01-03-2023\"\n    },\n    {\n        \"date\": \"01-03-23\"\n    },\n    {\n        \"date\": \"01/03/2023\"\n    },\n    {\n        \"date\": \"01/03/23\"\n    }\n]\n```\n\nExpected Output: format \"MM-dd-yyyy\"\n```\n[\n    {\n        \"date\": \"01-03-2023\"\n    },\n    {\n        \"date\": \"01-03-2023\"\n    },\n    {\n        \"date\": \"01-03-2023\"\n    },\n    {\n        \"date\": \"01-03-2023\"\n    }\n]\n```",
    "How to print the result from a loop in one line on the console in Javascript\n\nI'm trying to print out the result from a loop onto the console but it keeps printing on a new line instead of printing everything on the same line.\n\nThis is the output I'm expecting:\n```\n...17\u00b0C in 1 days ... 21\u00b0C in 2 days ... 21\u00b0C in 3 days\n```\n\nBut this is the output I keep getting:\n```\n... 17\u00b0C in 1 days\n\n... 21\u00b0C in 2 days\n\n... 23\u00b0C in 3 days\n```\n\nI've tried most of the answers I found but they are not working.\n```\nconst arr =[17, 21, 23];\n\nfunction printForcast(arr) {  \n  for (let i = 0; i < arr.length; i++) {\n    let days = i;\n\n    if(i <= days){\n      days +=1;\n    }\n\n    console.log(`... ${arr[i]}\u00b0C in ${days} days`); \n  }\n  return arr;\n}\n\nprintForcast(arr);\n<!DOCTYPE html>\n```",
    "Do GTK file chooser dialogs come with localized strings for buttons and titles?\n\nOn Windows and macOS, file chooser dialogs are built into the operating system, and there is a way for an application to tell the dialog to localize the text on buttons and titles to the system language (usually by not explicitly setting the button and title text).\n\nOn Linux, while there is no system file chooser dialog, the vast majority of applications use GTK. However, GTK's file chooser dialogs require users to provide strings for the button and title text:\n\n```\ndialog = gtk_file_chooser_dialog_new (\"Open File\",\n                                      parent_window,\n                                      action,\n                                      \"_Cancel\",\n                                      GTK_RESPONSE_CANCEL,\n                                      \"_Open\",\n                                      GTK_RESPONSE_ACCEPT,\n                                      NULL);\n```\n\nLeaving those strings empty or null leads to the buttons and title having no text at all, instead of having some default text.\n\nDoes GTK have its own set of localized default button and title text that application developers can tap into?\n\nNote that many Linux applications use the gettext internationalization library, but that depends on the application to provide a translation database for every language they wish to support, which is not what I'm looking for. I'm looking for a way for my application to show proper dialog text in every language that GTK knows about, even if my application doesn't have translated strings for them.\n\nNote also that that GTK message dialogs created with `gtk_message_dialog_new` can have correctly translated button text, assuming that the user has installed the correct language packs, as no text is explicitly specified (you just pass `GTK_BUTTONS_OK_CANCEL` to it to get correctly translated \"OK\" and \"Cancel\" buttons), but there seems to be no equivalent for file chooser dialogs.",
    "invalid hook call, one works but the other does not\n\nI am trying to modularise my code so im trying to separate the data that is being read\n\nhere is my previous code that works without error:\n\n```\nfunction Home({navigation, route}): React.JSX.Element {\n   const [showAddBillModal, setShowAddBillModal] = useState(false)\n   const isDarkMode = useColorScheme() === 'dark';\n   const backgroundStyle = {\n      backgroundColor: isDarkMode ? Colors.darker : Colors.lighter,\n    };\n\n    const toggleShowAddBillModal = () => {\n       setShowAddBillModal(!showAddBillModal)\n  }\n\n   // const user = getLoggedInUser() //works\n\n    return (...)\n```\n\nbut when i try to modularise it by separating the user data read into another file/class:\n\nlogin page:\n```\nconst login = (text, navigation) =>{\nlet userData = getLoggedInUser(text)\nif(userData !== null || userData !== undefined){\n    () => navigation.navigate('Home', {user: userData})\n}\n}\n\nfunction Login({ navigation }): React.JSX.Element {\nconst [name, onChangeNameText] = React.useState('');\nconst isDarkMode = useColorScheme() === 'dark';\nconst backgroundStyle = {\n    backgroundColor: isDarkMode ? Colors.darker : Colors.lighter,\n};\n\n// const user = getLoggedInUser()\nreturn (....\n                <Pressable\n                    style={[styles.button, styles.buttonClose]}\n                    onPress={() => login(name, navigation)}\n                    >...\n)\n}\n```\n\nfile to read data:\n```\nexport default getLoggedInUser = async (name) => {\nconst [userData, setUserData] = useState(null)\n// const userData = null\ntry{\n    console.log(\"test\")\n    await firestore()\n        .collection('users')\n        .get()\n        .then(querySnapshot => {\n            querySnapshot.forEach(doc => {\n                if (doc.data().name == name) {\n                    setUserData(doc)\n                    // return doc\n                    // userData = doc\n                    // return userData\n                }\n            });\n        });\n        return userData\n}\ncatch(error){\n    console.log(error)\n}\n}\n```\n\ni get invalid hook call here i have tried normally doing \"function name() {hook ....}\" but it also gives the same error, its working everywhere except this part",
    "Why Send requires Sync in this case?\n\nOn this very simple example, I require `OnConsume` to be a `Send` function so I can send it to threads.\n\n```\nuse std::sync::Arc;\n\ntrait EncodedPacket {}\n\npub type OnConsume = Arc<dyn Fn() -> Option<Box<dyn EncodedPacket>> + Send>;\n\npub trait Decoder: Send{}\n\npub struct DummyDecoder {\n    pub on_consume: Option<OnConsume>,\n}\n\nimpl Decoder for DummyDecoder {}\n```\n\nI'm getting this error about `Sync` though.\n\nError:\n```\nerror[E0277]: `(dyn Fn() -> Option<Box<(dyn EncodedPacket + 'static)>> + Send + 'static)` cannot be shared between threads safely\n  --> src/lib.rs:14:6\n   |\n7  | pub trait Decoder: Send\n   |                    ---- required by this bound in `Decoder`\n...\n14 | impl Decoder for DummyDecoder {\n   |      ^^^^^^^ `(dyn Fn() -> Option<Box<(dyn EncodedPacket + 'static)>> + Send + 'static)` cannot be shared between threads safely\n   |\n   = help: the trait `Sync` is not implemented for `(dyn Fn() -> Option<Box<(dyn EncodedPacket + 'static)>> + Send + 'static)`\n   = note: required because of the requirements on the impl of `Send` for `Arc<(dyn Fn() -> Option<Box<(dyn EncodedPacket + 'static)>> + Send + 'static)>`\n   = note: required because it appears within the type `Option<Arc<(dyn Fn() -> Option<Box<(dyn EncodedPacket + 'static)>> + Send + 'static)>>`\nnote: required because it appears within the type `DummyDecoder`\n  --> src/lib.rs:10:12\n   |\n10 | pub struct DummyDecoder {\n```\n\nWhy is it that it requires `Sync` for `(dyn Fn() -> Option<Box<(dyn EncodedPacket + 'static)>> + Send + 'static)`?",
    "Vector in a HashMap [duplicate]\n\nI know how to use, String I know how to use, Vector But I am facing issue to use HashMap\n\n```\n#[derive(Serialize)]\npub struct TestStructs {\n    pub ttStrngg: String,\n    pub ttVctorr: Vec<String>,\n    pub ttHshMpp: HashMap<String, Vec<String>>,\n}\n```\n\nHere is what I am trying\n\nDon't have any issues with String\n```\nttStrngg: \"Stringgg\".to_string()\n```\n\nDon't have any issues with Vector\n```\nttVctorr: vec![\"VecStr1\".to_string(), \"VecStr2\".to_string()]\n```\n\nBut do have an issue with HashMap\n```\nttHshMpp: \"HMK1\".to_string(), vec![\"K1V1\".to_string(), \"K1V2\".to_string()]\n```\n\nI've shared what I tried and now looking for that missing thing in HashMap\n\nHere is the Rust Playground link to try your own\n\nAnd here is the error\n\n```\n    Compiling playground v0.0.1 (/playground)\nerror: expected one of `,`, `:`, or `}`, found `!`\n --> src/main.rs:9:46\n  |\n6 |     let ttStrctts = TestStructs {\n  |                     ----------- while parsing this struct\n...\n9 |             ttHshMpp: \"HMK1\".to_string(), vec![\"K1V1\".to_string(), \"K1V2\".to_string()]\n  |                                           ---^ expected one of `,`, `:`, or `}`\n  |                                           |\n  |                                           while parsing this struct field\n\nerror[E0308]: mismatched types\n --> src/main.rs:9:23\n  |\n9 |             ttHshMpp: \"HMK1\".to_string(), vec![\"K1V1\".to_string(), \"K1V2\".to_string()]\n  |                       ^^^^^^^^^^^^^^^^^^ expected `HashMap<String, Vec<String>>`, found `String`\n  |\n  = note: expected struct `HashMap<std::string::String, Vec<std::string::String>>`\n             found struct `std::string::String`\n```",
    "Type of an object that contains CSS properties\n\nI have a function that takes an element on the page and adds CSS to its style attribute. I want the argument that is passed to it to be an object with keys such as height, minWidth, flexDirection, etc.\n\n```\nfunction addStyle (el: HTMLElement, style: Style): void {\n  for (const property in style) {\n    el.style[property] = style[property]\n  }\n}\n```\n\nMy problem is in typing this object. It's obviously not feasible to define every single CSS property myself. I'm pretty sure that TypeScript should be able to do this itself, I'm just not sure how. This is my best guess:\n```\ntype Style = Partial<CSSStyleDeclaration>\n```\n\n...but that results in the error \"Type 'string | undefined' is not assignable to type 'string'\"\n\nThat specific error can be easily overridden, but I'm wary that it indicates I'm doing something wrong or unintuitive.\n\nIs there a standard way to type an object that contains CSS properties?",
    "Docker Swarm with image versions externalized to .env file\n\nI used to externalized my image versions to my .env file. This make it easy to maintain and I don't modify my docker-compose.yml file just to upgrade a version, so I'm sure I won't delete a line by mistake or whatever.\n\nBut when I try to deploy my services with stack to the swarm, docker engine complains that my image is not a correct reposity/tag, with the exact following message :\n\n```\nError response from daemon: rpc error: code = 3 desc = ContainerSpec: \"GROUP/IMAGE:\" is not a valid repository/tag\n```\n\nTo fix this, I can fix the image version directly in the docker-compose.yml file. Is there any logic here or it that a bug? But this mixes fix part of the docker-compose and variable ones.\n\nCheers, Olivier\n\n",
    "Sort tbody list which is populated with Javascript getList?\n\nI have a router with a DHCP page which is not sorted by the internal IP number, instead it is fully random. I have full access to the html and javascript, and I can modify this without any issues. However I cannot figure out how to make the list sorted by IP-address by default. I have no need to be able to manually click and sort, I just want the list to always be sorted by IP-address.\n\nI cannot figure out if it is possible to sort a getList, or if it has to be done in the randerBandlist function.\n\nThe list html:\n```\n                <table class=\"table\">\n                <thead>\n                    <tr>\n                        <th width=\"30\"></th>\n                        <th><%:\u8bbe\u5907\u540d\u79f0%></th>\n                        <th><%:IP\u5730\u5740%></th>\n                        <th><%:MAC\u5730\u5740%></th>\n                        <th width=\"150\" class=\"center\"><%:\u64cd\u4f5c%></th>\n                    </tr>\n                </thead>\n                <tbody id=\"bandlist\">\n                    <tr>\n                        <td class=\"center\" colspan=\"5\"><%:\u67e5\u8be2\u4e2d...%></td>\n                    </tr>\n                </tbody>\n            </table>\n```\n\nThis is the part that handles the list in question:\n```\ngetList = function( callback ){\n        $.getJSON('<%=luci.dispatcher.build_url(\"api\", \"xqnetwork\",\"macbind_info\")%>',{},function(rsp){\n            if ( rsp.code != 0 ) {\n                return;\n            }\n            callback( rsp );\n        });\n    },\n    randerBandlist = function( rsp ){\n        var tpl = $( '#tplbandlist' ).html(),\n            container = $( '#bandlist' ),\n            bandlistdata = rsp.list,\n            tpldata = [],\n            mac, ip, dname;\n        currentList = {};\n        if ( bandlistdata.length > 0 ) {\n            for (var i = 0; i < bandlistdata.length; i++) {\n                mac = bandlistdata[i].mac.toUpperCase();\n                ip = bandlistdata[i].ip;\n                dname = StringH.encode4Html( bandlistdata[i].name );\n                tpldata.push({\n                    dname: dname,\n                    ip: ip,\n                    mac: mac\n                });\n                currentList[ip] = 1;\n            }\n        }\n        container.html( tpl.tmpl( {bandlist: tpldata} ) );\n    },\nreturn {\n    init: function(){\n        getList( randerBandlist );\n        addEvent();\n    }\n}\n```\n\nAlso included the full function, however I think the function above is the one that needs modifying:\n```\nvar ModelDhcpband = (function(){\nvar lanIP = '<%=lanip%>',\n    ipprefix = (function(ip){\n        var arr = ip.split('.');\n        arr.pop();\n        return arr.join('.') + '.';\n    })(lanIP),\n    currentList = {},\n    // get repeat set\n    getRepeat = function( data ){\n        data = data || [];\n        var repeat = [];\n        var _currentList = $.extend( {}, currentList);\n        for (var i = 0; i < data.length; i++) {\n            var v = data[i];\n            if ( typeof( _currentList[v] ) == 'undefined' ) {\n                _currentList[v] = 1;\n            } else {\n                repeat.push(v);\n            }\n        }\n        return repeat;\n    },\n    getList = function( callback ){\n        $.getJSON('<%=luci.dispatcher.build_url(\"api\", \"xqnetwork\",\"macbind_info\")%>',{},function(rsp){\n            if ( rsp.code != 0 ) {\n                return;\n            }\n            callback( rsp );\n        });\n    },\n    randerBandlist = function( rsp ){\n        var tpl = $( '#tplbandlist' ).html(),\n            container = $( '#bandlist' ),\n            bandlistdata = rsp.list,\n            tpldata = [],\n            mac, ip, dname;\n        currentList = {};\n        if ( bandlistdata.length > 0 ) {\n            for (var i = 0; i < bandlistdata.length; i++) {\n                mac = bandlistdata[i].mac.toUpperCase();\n                ip = bandlistdata[i].ip;\n                dname = StringH.encode4Html( bandlistdata[i].name );\n                tpldata.push({\n                    dname: dname,\n                    ip: ip,\n                    mac: mac\n                });\n                currentList[ip] = 1;\n            }\n        }\n        container.html( tpl.tmpl( {bandlist: tpldata} ) );\n    },\n    randerDevlist = function( rsp ){\n        var tpl = $( '#tpldevlist' ).html(),\n            devlistdata = rsp.devicelist,\n            tpldata = [],\n            randerDom,\n            mac, ip, dname, tag;\n        if ( devlistdata.length > 0 ) {\n            for (var i = 0; i < devlistdata.length; i++) {\n                mac = devlistdata[i].mac.toUpperCase();\n                ip = devlistdata[i].ip;\n                iplast = (function( ip ){\n                    var arr = ip.split('.');\n                    return arr[arr.length - 1];\n                })( ip );\n                dname = StringH.encode4HtmlValue( devlistdata[i].name );\n                tag = devlistdata[i].tag;\n                if ( tag != 2 ) {\n                    tpldata.push({\n                        dname: dname,\n                        ip: iplast,\n                        mac: mac\n                    });\n                }\n            }\n        }\n        randerDom = tpl.tmpl( {\n            devlist: tpldata,\n            ipprefix: ipprefix\n        } );\n        $.dialog({\n            title: '<%:\u7ed1\u5b9a\u8bbe\u5907%>',\n            content: randerDom,\n            lock: true,\n            width: 828,\n            padding: '30px'\n        });\n        $.pub( 'done', {id: '#addlist'} );\n    },\n    serializeForm = function( form ){\n        var ips = $( '.ip', form ),\n            dnames = $( '.dname', form ),\n            macs = $( '.mac', form ),\n            data = [],\n            item;\n        ips.each(function( idx, el ){\n            item = {\n                ip: ipprefix + $.trim( el.value ),\n                mac: $.trim( macs.eq( idx ).val() ),\n                name: $.trim( dnames.eq( idx ).val() )\n            };\n            data.push( item );\n        });\n\n        return ObjectH.stringify( data );\n    }\n    unbind = function( e, mac ){\n        e.preventDefault();\n        var that = this,\n            $this = $(that),\n            requestURL = '<%=luci.dispatcher.build_url(\"api\", \"xqnetwork\", \"mac_unbind\")%>',\n            requestData = {\n                mac: mac\n            };\n        $.pub( 'loading:start' );\n        $.ajax({\n            url: requestURL,\n            type: 'POST',\n            data: requestData,\n            dataType: 'json',\n            success: function( rsp ){\n                if ( rsp.code !== 0 ) {\n                    $.alert( rsp.msg );\n                } else {\n                    getList( randerBandlist );\n                    $( '#dellist' ).hide();\n                }\n                $.pub( 'loading:stop' );\n            }\n        });\n    },\n    addEvent = function(){\n        // unband\n        $('body').delegate( '.btn-unband' ,'click', function( e ){\n            var that = this,\n                $this = $( that ),\n                mac = $this.attr('data-mac'),\n                ok = function(){\n                    unbind.call( that, e, mac );\n                };\n            $.confirm( '<%:\u4f60\u786e\u5b9a\u8981\u89e3\u9664\u6b64\u9879\u7ed1\u5b9a\uff1f%>', ok );\n        });\n        // band\n        $( 'body' ).delegate( '#addbandlist', 'submit', function( e ){\n            e.preventDefault();\n            var form = e.target,\n                formName = form.name,\n                formels = $( 'input', form ),\n                requestURL = '<%=luci.dispatcher.build_url(\"api\", \"xqnetwork\", \"mac_bind\")%>',\n                requestData,\n                rules,\n                name,\n                display,\n                validator,\n                formdata,\n                iplist = [],\n                formdata,\n                formdataojb,\n                repeatIP,\n                validerules = [];\n\n            validator = Valid.checkAll( $('#addbandlist')[0] );\n\n            if ( validator) {\n                formdata = serializeForm( form );\n                formdataojb = StringH.evalExp( formdata );\n                for (var i = 0; i < formdataojb.length; i++) {\n                    iplist.push(formdataojb[i]['ip']);\n                }\n                repeatIP = getRepeat( iplist );\n                if ( repeatIP.length !== 0 ) {\n                    $.alert( '<%:\u5b58\u5728IP\u51b2\u7a81\uff0c\u8bf7\u68c0\u67e5\u8f93\u5165\u9879%>' + repeatIP.join(' , ') );\n                    return;\n                }\n\n                requestData = {\n                    data: formdata\n                };\n                $.pub( 'wait', {id: '#submitbandlist'} );\n                $.ajax({\n                    url: requestURL,\n                    data: requestData,\n                    type: 'POST',\n                    dataType: 'json',\n                    success: function( rsp ){\n                        if ( rsp.code == 0 ) {\n                            location.reload( 1 );\n                        } else {\n                            $.alert( rsp.msg );\n                        }\n                        $.pub( 'done', {id: '#submitbandlist'} );\n                    }\n                });\n            }\n\n        });\n\n        // add a item\n        $( 'body' ).delegate( '#addoneitem', 'click', function( e ){\n            e.preventDefault();\n            var tpl = $( '#tpldevitem' ).html(),\n                form = $( '#banditems' ),\n                btnSubmit = $( '#submitbandlist' ),\n                lastidx = (function(){\n                    if ( form.find('tr').length > 0 ) {\n                        return form.find('tr:last').attr( 'data-idx' );\n                    }\n                    return 0;\n                }()),\n                lastidx = parseInt( lastidx, 10 ),\n                item = tpl.tmpl({\n                    idx: lastidx + 1,\n                    ipprefix: ipprefix\n                });\n            if ( !isNaN( lastidx ) ) {\n                form.append( item );\n                if ( form.find( 'tr' ).length > 0 ) {\n                    btnSubmit.show();\n                } else {\n                    btnSubmit.hide();\n                }\n            } else {\n                $.alert('<%:\u51fa\u73b0\u5f02\u5e38\uff0c\u8bf7\u5237\u65b0\u9875\u9762%>');\n            }\n        } );\n\n        // del a item\n        $( 'body' ).delegate( '.btn-del-item', 'click', function( e ){\n            e.preventDefault();\n            var tar = e.target,\n                tr = $( tar ).parents( 'tr' ),\n                form = $( '#banditems' ),\n                btnSubmit = $( '#submitbandlist' ),\n                isEmpty = (function(){\n                    var empty = true;\n                    tr.find('input').each(function(){\n                        if ( this.value !== '') {\n                            empty = false;\n                            return false;\n                        }\n                    });\n                    return empty;\n                }()),\n                ok = function(){\n                    tr.remove();\n                    if ( form.find( 'tr' ).length > 0 ) {\n                        btnSubmit.show();\n                    } else {\n                        btnSubmit.hide();\n                    }\n                };\n            if ( isEmpty ) {\n                ok();\n            } else {\n                $.confirm( '<%:\u786e\u5b9a\u8981\u5220\u9664\u8fd9\u9879\u6570\u636e\u5417%>', ok );\n            }\n        } );\n\n        // open add dlg\n        $( '#addlist' ).click(function( e ){\n            e.preventDefault();\n            $.pub( 'wait', {id: '#addlist'} );\n            getList( randerDevlist );\n        });\n\n        // check for del\n        $( 'body' ).delegate( '.bandmac', 'click', function( e ){\n            if ( $('.bandmac:checked').length > 0 ) {\n                $( '#dellist' ).show();\n            } else {\n                $( '#dellist' ).hide();\n            }\n        } );\n\n        // del all\n        $( '#dellist' ).on( 'click', function( e ){\n            e.preventDefault();\n            if ( $('.bandmac:checked').length == 0 ) {\n                $.alert( '<%:\u4f60\u8fd8\u672a\u9009\u62e9\u4efb\u4f55\u8bbe\u5907%>' );\n                return;\n            }\n            var that = this,\n                $this = $(that),\n                mac = (function(){\n                    var tmp = [];\n                    $('.bandmac:checked').each(function(){\n                        tmp.push( this.value );\n                    });\n                    return tmp.join( ';' );\n                }()),\n                ok = function(){\n                    unbind.call( that, e, mac );\n                };\n\n            $.confirm( '<%:\u786e\u8ba4\u8981\u89e3\u9664\u9009\u4e2d\u9879\u76ee\u7684\u7ed1\u5b9a\u5173\u7cfb\uff1f%>', ok );\n        } );\n    };\n\ncurrentList[lanIP] = 1;\n\nreturn {\n    init: function(){\n        getList( randerBandlist );\n     \n```",
    "setattr for `__call__` method of an object doesn't work in Python\n\nI though that for python object `obj()` is equivalent to `obj.__call__()`. But it looks like it doesn't hold when `setattr` was used.\n\n```\nIn [46]: class A:\n    ...:     def __call__(self):\n    ...:         return 1\n    ...:\n\nIn [47]: a = A()\n\nIn [48]: a()\nOut[48]: 1\n\nIn [49]: a.__call__()\nOut[49]: 1\n\nIn [50]: getattr(a, '__call__')\nOut[50]: <bound method A.__call__ of <__main__.A object at 0x10a3d2a00>>\n\nIn [51]: setattr(a, '__call__', lambda: 100)\n\nIn [52]: a()\nOut[52]: 1\n\nIn [53]: a.__call__()\nOut[53]: 100\n```\n\nWhy is it so? And how I can set the `call` method in runtime?\n\nNotice in Python version is 3.9.18 and 3.11.4\n\nThe snippet of code above, I'd expected a() returns 100",
    "How to replace all CRLF of a text file with ; with W10 cmd batch file that can use Sed, Awk (Gnuwin32)\n\nI have this input with CRLF line endings:\n```\n1019\n1020\n1028\n1021\n```\n\nI want to remove `CRLF` at end of each lines using `sed`, (or `awk`) from `Gnuwin32` using a Windows 10 batch script, (not Powershell).\n\nI want to get the following result inside a text file, without any semicolon or CRLF at the end:\n```\n1019;1020;1028;1021\n```\n\nIt doesn't work with the following lines in the batch file, (it seems there is a problem with GNUwin32 Sed that adds new CRLF at end of each processed line):\n```\nREM This to generate the input example :\n(echo 1019& echo 1020& echo 1028& echo 1021) > test_in.txt\n\nREM This is the first try for getting the desired 1-line output with semicolumn :\n(echo 1019& echo 1020& echo 1028& echo 1021) | .\\GnuWin32\\bin\\sed -e \"s/ *$//g\" | .\\GnuWin32\\bin\\sed -e \"s/\\r\\n/;/\" > test_out.txt\n\nREM This is the second try for getting the desired 1-line output with semicolumn :\nREM (echo 1019& echo 1020& echo 1028& echo 1021) | .\\GnuWin32\\bin\\sed -e \"s/ *$//g\" | .\\GnuWin32\\bin\\sed -b -e \"s/\\x0d\\x0a/;/g\" > test_out.txt\n\nREM This is the third try for getting the desired 1-line output with semicolumn :\nREM (echo 1019& echo 1020& echo 1028& echo 1021) | .\\GnuWin32\\bin\\sed -e \"s/ *$//g\" | .\\GnuWin32\\bin\\awk \"{gsub(\\\"\\\\\\\\r\\\\\\\\n\\\",\\\";\\\")};1\" > test_out.txt\n\nREM This is the fourth try for getting the desired 1-line output with semicolumn :\nREM (echo 1019& echo 1020& echo 1028& echo 1021) | .\\GnuWin32\\bin\\sed -e \"s/ *$//g\" | .\\GnuWin32\\bin\\awk -v FS=\"\\r\\n\" -v OFS=\";\" -v RS=\"\\\\$\\\\$\\\\$\\\\$\" -v ORS=\"\\r\\n\" \"{$1=$1}1\" > test_out.txt\n```",
    "GitHub Actions: how can I run a workflow created on a non-'master' branch from the 'workflow_dispatch' event?\n\nFor actions working on a third party repository, I would like to be able to create an action on a branch and execute it on the workflow_dispatch event. I have not succeeded in doing this, but I have discovered the following:\n\nThe Action tab will change the branch where it finds workflows and action code based on the branch relating to the last executed workflow. e.g. if some workflow is executed from the Action tab using the Run Workflow button and the Use Workflow From dropdown is set to some branch, Branch-A, then the contents of the Workflows panel on the left hand side of the Actions tab will be taken from Branch-A's version of .github/.\nThe This workflow has a workflow_dispatch event trigger. text does not change with the branch. It seems to be taken from master. Alternatively, it may be being taken from the last set of results. I have not tested for that because either way it is not helpful behaviour.\nThe workaround is the execute on a push event which is OK, but that seems out of kilter with GitHub's high standards of design.\n\nDoes the above sound a) about right and b) whichever way you look at it, not optimal behaviour? Or, is there a better approach to building and testing actions?",
    "Trying to delete entries gives: Inconsistent datatypes: expected %s got %s\" in Oracle\n\nI am trying to delete some entries based on 'name'. I have a table t1 with different columns, one of them being name and of type NCLOB. I have a method to delete these entries in Java, and I am using a named query. My question is, how can I solve the NCLOB issue so I'll be able to remove the data. I don't want to change the column type. The name query looks like this: `DELETE FROM table1 t1 WHERE t1.name = :name` How can I solve this?",
    "How to keep the shell window open after running a PowerShell script?\n\nI have a very short PowerShell script that connects to a server and imports the AD module. I'd like to run the script simply by double clicking, but I'm afraid the window immediately closes after the last line.\n\nHow can I sort this out?",
    "Typing a function param to be any JSON serializable object\n\nwhat would be the best type for this function?\nI want basically any input type that` json.dumps` can process (with or without `JSONEncoder`)\n\nFor now i'm using `Union[List[Any], Dict[Any, Any]]` but it's not exhaustive and mypy complains `Explicit \"Any\" is not allowed`.\n\n```\nimport json\nfrom typing import List, Dict\nfrom datetime import date\n\n\ndef my_function_doing_stuff_then_serializing(input: Union[List[Any], Dict[Any, Any]], **kwargs) -> None:\n    json.dumps(input, **kwargs)\n```\n\nso I can do this\n\n```\nimport json\nfrom datetime import date\nfrom somewhere import my_function_doing_stuff_then_serializing\n\n\nclass DateEncoder(json.JSONEncoder):\n    def default(self, obj: Any) -> Any:\n        if isinstance(obj, date):\n            return obj.isoformat()\n        return super().default(obj)\n\nmy_function_doing_stuff_then_serializing([date.today()], cls=DateEncoder)\n```",
    "Hamcrest matcher for checking return value of method in collection\n\n`hasProperty` can be used with `hasItem` to check for the value of a given property, eg:\n```\nMatcher hasName = Matchers.<Person>hasProperty(\"name\", is(\"Winkleburger\"));\nassertThat(names, hasItem(hasName));\n```\n\nThis is fine when name is a property, ie: there is a method called `getName()`.\n\nIs there a matcher that will check a method that isn't a property? ie: in this case, it will check the return value of the method `name()` rather than `getName()`, for items in the collection.",
    "Can javascript sort like windows?\n\nI need a way in Javascript to sort strings as in Windows but it seems it's impossible.\n\nWindows explorer sorts like this:\n```\n1.jpg - 2.jpg - 3.jpg - ....\n```\n\nWhile Javascript sorts like this:\n```\n1.jpg - 10.jpg - 11.jpg - 2.jpg -...\n```\n\nWindows sorts based on the numeral value in the filename while Javascript just sorts by a characters' ASCII code.\n\nSometimes filenames aren't just numbers or text but a combination of both, e.G.:\n```\n\"mark 01 in school.jpg\"\n\"mark 02 in school.jpg\"\n\"john 05 in theater.jpg\"\n```\n\nWhat I need is a Javascript function that sorts like shown above.\n\nMy question is: is there a function in JS or how can I implement one on my own?",
    "How can I subtract a number from string elements in R?\n\nI have a long string. The part is\n```\nx <- \"Text1 q10_1 text2 q17 text3 q22_5 ...\"\n```\n\nHow can I subtract 1 from each number after \"q\" letter to obtain the following?\n```\ny <- \"Text1 q9_1 text2 q16 text3 q21_5 ...\"\n```\n\nI can extract all my numbers from x:\n```\nnumbers <- stringr::str_extract_all(x, \"(?<=q)\\\\d+\")\nnumbers <- as.integer(numbers[[1]]) - 1\n```\n\nBut how can I update x with these new numbers?\n\nThe following is not working\n```\nstringr::str_replace_all(x, \"(?<=q)\\\\d+\", as.character(numbers))\n```",
    "Model translation in Django Rest Framework\n\nI'm developing an API with Django Rest Framework, and I'd need some models with a few fields that should support translation in multiple languages then, of course, serializers should have to retrieve the field with the expected language. I've thought about two options: adding extra fields to the model (one field for language) or creating another model with all texts in every language. On the other hand, I've seen that there are some libraries such as django-modeltranslation that are intended to solve that issue, however, I'd like to know some opinions about them. What do you think? What would you recommend to me?\n\nThank you very much",
    "Lossy compression method: uint16 to a uint8?\n\nI'm looking for suggestions on lossy data compression methods. I need to compress a uint16 to a uint8 such that the resolution loss increases with increasing uint16 values. I am currently using the following:\n\n```\ndef log2_compress(x: np.uint16) -> np.uint8:\n    # Add l to avoid log2(0)\n    y = math.log2(x + 1)\n    # log2(1) = 0.\n    # log2(65536) = 16.\n    # Scale from [0,16] to [0,255].\n    return np.uint8((y / 16) * 255)\n```\n\nThis is simple but has the downside that it is wasteful on the `uint8` side, namely\n\n```\nlog2_compress(0) = 0\nlog2_compress(1) = 15\nlog2_compress(2) = 25\n```\nso `[1,14]`, `[16,24]`, etc. aren't used. Can someone suggest a method similar to `log2_compress` but uses more (all?) of the `uint8` bits? I am not really concerned about performance either.",
    "How can I get LLM to only respond in JSON strings?\n\nThis is how I am defining the executor\n```\nconst executor = await initializeAgentExecutorWithOptions(tools, model, {\n  agentType: 'chat-conversational-react-description',\n  verbose: false,\n});\n```\n\nWhenever I prompt the AI I have this statement at the end.\n```\ntype SomeObject = {\n  field1: number,\n  field2: number,\n}\n\n- It is very critical that you answer only as the above object and JSON stringify it as a single string.\n  Don't include any other verbose explanatiouns and don't include the markdown syntax anywhere.\n```\n\nThe `SomeObject` is just an example. Usually it will have a proper object type. When I use the `executor` to get a response from the AI, half the time I get the proper JSON string, but the other half the times are the AI completely ignoring my instructions and gives me a long verbose answer in just plain English...\n\nHow can I make sure I always get the structured data answer I want? Maybe using the `agentType: 'chat-conversational-react-description'` isn't the right approach here?",
    "Enqueue javascript with type=\"module\"\n\nI want to use `countUp.js` on my custom theme in Wordpress.\n\nWhen I add the file with `wp_enqueue_script()`, I get an error:\n\n```\nUncaught SyntaxError: Unexpected token 'export'\n```\n\nI've read that it can be fixed by setting `type=\"module\"` on the `<script>` tag, but I don't know how to do that as that option doesn't exist in `wp_enqueue_script()`...\n\nCan anyone help me?",
    "python packages installing order\n\nwhen we install python packages using pip, sometimes it installs some other packages. for example installing torch requires installing numpy. imagine in a requirements.txt file there are packages with their versions, but not in a right order. how can we realize the right order? (for example if numpy version is specified as 1.1 but previous package in the list automatically installs numpy of last version!)\n\nI installed librosa==0.9.2 which installed scipy 1.10 during its installation. but after that there is scipy=1.8 in the list. doesn't it make a conflict?",
    "Is there a fiber api in .net?\n\nOut of more curiosity than anything I've been looking for a set of C#/.net classes to support fibers/co-routines (the win32 version) and haven't had any luck.\n\nDoes anybody know of such a beast?",
    "How do I compare strings in Java?\n\nI've been using the `==` operator in my program to compare all my strings so far. However, I ran into a bug, changed one of them into `.equals()` instead, and it fixed the bug.\n\nIs `==` bad? When should it and should it not be used? What's the difference?",
    "Event binding on dynamically created elements?\n\nI have a bit of code where I am looping through all the select boxes on a page and binding a .hover event to them to do a bit of twiddling with their width on mouse on/off.\n\nThis happens on page ready and works just fine.\n\nThe problem I have is that any select boxes I add via Ajax or DOM after the initial loop won't have the event bound.\n\nI have found this plugin (jQuery Live Query Plugin), but before I add another 5k to my pages with a plugin, I want to see if anyone knows a way to do this, either with jQuery directly or by another option.",
    "How to access the correct `this` inside a callback\n\nI have a constructor function which registers an event handler:\n```\nfunction MyConstructor(data, transport) {\n    this.data = data;\n    transport.on('data', function () {\n        alert(this.data);\n    });\n}\n\n// Mock transport object\nvar transport = {\n    on: function(event, callback) {\n        setTimeout(callback, 1000);\n    }\n};\n\n// called as\nvar obj = new MyConstructor('foo', transport);\n```\n\nHowever, I'm not able to access the `data` property of the created object inside the callback. It looks like `this` does not refer to the object that was created, but to another one.\n\nI also tried to use an object method instead of an anonymous function:\n```\nfunction MyConstructor(data, transport) {\n    this.data = data;\n    transport.on('data', this.alert);\n}\n\nMyConstructor.prototype.alert = function() {\n    alert(this.name);\n};\n```\n\nbut it exhibits the same problems.\n\nHow can I access the correct object?",
    "How can I disable UWP WebView2's drag and drop?\n\nIn my `UWP` application, I use a webview2 (from \"Microsoft.UI.Xaml.Controls\"). And the web content shown inside of it can be drag-and-drop.\n\nI want to disable this \"drag-and-drop\" feature, and I tried a lot of ways, but all failed. E.g., `AllowDrop=\"False\" CanDrag=\"False\"`\n\nHow can I do it?\n\nXAML code:\n```\nxmlns:controls=\"using:Microsoft.UI.Xaml.Controls\"\n\n <controls:WebView2 x:Name=\"_WebView2\" Height=\"370\" Width=\"792\"\n     NavigationStarting=\"WebView2_NavigationStarting\"/>\n```\n\nC#:\n```\nawait _WebView2.EnsureCoreWebView2Async();\n_WebView2.CoreWebView2.Navigate(sourceStr);\n```",
    "java.lang.OutOfMemoryError: Java heap space\n\nI am getting the following error on execution of a multi-threading program\n```\njava.lang.OutOfMemoryError: Java heap space\n```\n\nThe above error occured in one of the threads.\n\n1. Upto my knowledge, Heap space is occupied by instance variables only. If this is correct, then why this error occurred after running fine for sometime as space for instance variables are alloted at the time of object creation.\n\n2. Is there any way to increase the heap space?\n\n3. What changes should I made to my program so that It will grab less heap space?",
    "Getting Error during build: RollupError: expression expected after migrating from vue-cli to vite\n\nI just migrated from vue-cli to vite. Serving locally works fine, but during the build, I got the following error:\n```\nx Build failed in 221ms\nerror during build:\nRollupError: Expression expected\n    at getRollupError (file:///home/pc/Desktop/proj/node_modules/rollup/dist/es/shared/parseAst.js:379:41)\n    at ParseError.initialise (file:///home/pc/pc/proj/node_modules/rollup/dist/es/shared/node-entry.js:11172:28)\n    at convertNode (file:///home/officeubuntu23/pc/proj/node_modules/rollup/dist/es/shared/node-entry.js:12914:10)\n    at convertProgram (file:///home/officeubuntu23/pc/proj/node_modules/rollup/dist/es/shared/node-entry.js:12234:12)\n    at Module.setSource (file:///home/officeubuntu23/pc/proj/node_modules/rollup/dist/es/shared/node-entry.js:14073:24)\n    at async ModuleLoader.addModuleSource (file:///home/pc/Desktop/proj/node_modules/rollup/dist/es/shared/node-entry.js:18712:13)\n```\n\nI have tried updating node and npm, reinstalling rollup and doing `npm update` and `npm install`.",
    "r convert month year to ordered numeric\n\nI have a dataset with column where the values are month year in format like this\n```\n M_Yr\n March 1990\n April 1990\n May   1990\n June  1990\n July  1990\n Aug   1990\n Sept  1990\n Oct   1990\n Nov   1990\n Dec   1990\n Jan   1991\n Feb   1991\n March 1991\n April 1991\n May   1991\n June  1991\n July  1991\n Aug   1991\n Sept  1991\n Oct   1991\n Nov   1991\n Dec   1991\n```\n\nI tried this approach.\n```\ndf$Col1 <- as.numeric(df$M_Yr)\n```\n\nThis does converts the `month Year` variable to numeric but the order is scrambled and not in right sequence. So I am wondering what is an efficient way to create this numeric variable without writing a lengthy `case_when` statement.\n\nAny suggestion is much appreciated. Thanks.",
    "Calculate weighted average by date in R\n\nI'm new to R and having some difficulty aggregating by date. I have time-series data with multiple price and quantity entries per date. The actual data is more complex, but it looks something like this:\n```\nprice<-c(1.50,3,1.50,3,3,2.90,3)\nquantity<-c(10,5,10,5,5,5,5)\ndate<-c('01/09/21','01/09/21','01/16/21','01/16/21','01/23/21','01/30/21','01/30/21')\ndf<-data.frame(date,price,quantity)\n```\n\n```\ndate        price        quantity\n01/09/21        1.5        10\n01/09/21        3        5\n01/16/21        1.5        10\n01/16/21        3        5\n01/23/21        3        5\n01/30/21        2.9        5\n01/30/21        3        5\n```\n\nI'd like to create a new data frame with only the four individual dates and a single price value for each. To do so, I'm trying to calculate the weighted average of price on each individual date, similar to the example below:\n```\ndate        price_weighted\n01/09/21        2\n01/16/21        2\n01/23/21        3\n01/30/21        2.95\n```\n\nI've tried using `price_weighted<-aggregate(price~date,df,weighted.mean)`, which returns something similar to what I want, but for some reason it's calculating the average price rather than the weighted average. Any suggestions would be appreciated!",
    "How to convert MJD time in UTC (only date, no time) in order to make a plot\n\nI have a list of MJD time. I need to convert it in list UTC but only the date (year/month/day) and no time, so a list that I can use to make a plot with time in x-axis. Thanks\n\nI tried with astropy and the command Time('list',forma='mjd').iso but i have also the time, and I am not able to delete.",
    "applying strsplit on data.frame results in unexpected output\n\nI have one dataframe an two functions:\n\nMy dataframe:\n```\ns_words<-c(\"one,uno\",\"two,dos\",\"three,tres\",\"four,cuatro\")\nn_nums<-c(10,20,30,40)\ndf1 <- data.frame(n_nums,s_words) \n> df1\n  n_nums     s_words\n1     10     one,uno\n2     20     two,dos\n3     30  three,tres\n4     40 four,cuatro\n```\n\nMy two functions:\n```\nf_op1 <- function(s_input) {\n  s_ret = paste0(\"***\",s_input,\"***\")\n  return(s_ret)\n}\n\n\nf_op2 <- function(s_input) {\n    a_segments=unlist(strsplit(s_input,split=\"\\\\W+\"))\n    s_eng = a_segments[1]\n    s_spa = a_segments[2]\n    s_ret = paste0(\"*\",s_eng,\"***\",s_spa,\"*\")\n  return(s_ret)\n}\n```\n\nWhen I apply my functions on the dataframe ....\n```\ndf1$s_op1 <- f_op1(df1$s_words)\ndf1$s_op2 <- f_op2(df1$s_words)\n```\n\nI get this:\n```\n> df1\n  n_nums     s_words             s_op1       s_op2\n1     10     one,uno     ***one,uno*** *one***uno*\n2     20     two,dos     ***two,dos*** *one***uno*\n3     30  three,tres  ***three,tres*** *one***uno*\n4     40 four,cuatro ***four,cuatro*** *one***uno*\n```\n\nBut I need this, something like:\n```\n> df1\n  n_nums     s_words             s_op1           s_op2\n1     10     one,uno     ***one,uno***     *one***uno*\n2     20     two,dos     ***two,dos***     *two***dos*\n3     30  three,tres  ***three,tres***  *three***tres*\n4     40 four,cuatro ***four,cuatro*** *four***cuatro*\n```\n\nf_op2 is only for demonstration purposes, in reality it is more complex and uses \"strsplit\". I think there is some problem with strsplit, but I'm not sure, I'm begginer in R language. Thanks in advance for your explanations.\n\nI have searched a lot for help but I can't find the solution.",
    "Trying to subscribe to oneSignal in a React Native App\n\nHello I have created a new 17.1 ReactNative app and have incorporated OneSignal.\n\nAccording to the example it should subscribe but it does not.\n\nI am also testing this on a physical device.\n\nThis runs, no errors and i get the prompt the first time to allow notifications.\n\nBut the user is not subscribed.\n\nI tried adding\n```\nOneSignal.sendTag('my app id', true);\n```\n\nbut got the error sendTag is undefined\n\nmy code looks like\n```\nconst App = () => {\n\n // Remove this method to stop OneSignal Debugging\n OneSignal.Debug.setLogLevel(LogLevel.Verbose);\n\n // OneSignal Initialization\n OneSignal.initialize(\"ONESIGNAL_APP_ID\");\n\n // requestPermission will show the native iOS or Android notification permission prompt.\n // We recommend removing the following code and instead using an In-App Message to prompt for notification permission\n OneSignal.Notifications.requestPermission(true);\n\n // Method for listening for notification clicks\n OneSignal.Notifications.addEventListener('click', (event) => {\n   console.log('OneSignal: notification clicked:', event);\n });\n\n const isDarkMode = useColorScheme() === 'dark';\n const backgroundStyle = {\n    backgroundColor: isDarkMode ? Colors.darker : Colors.lighter,\n };\n\n return (\n   <SafeAreaView style={backgroundStyle}>\n      <StatusBar\n         barStyle={isDarkMode ? 'light-content' : 'dark-content'}\n         backgroundColor={backgroundStyle.backgroundColor}\n      />\n    <ScrollView\n    contentInsetAdjustmentBehavior=\"automatic\"\n    style={backgroundStyle}>\n    <Header />\n    <View\n      style={{\n        backgroundColor: isDarkMode ? Colors.black : Colors.white,\n      }}>\n      <Button\n        title=\"Press me\"\n        onPress={subscribe}\n      />\n      <LearnMoreLinks />\n    </View>\n    </ScrollView>\n   </SafeAreaView>\n );\n };\n```",
    "Bot renaming user by user's command\n\nI've been having a problem with some project I 've been doing for the last 3-4 days on discord. It has to do with bots of course and the language I chose is javascript (discord.js).\n\nSo, the thing seems kinda simple but I am really stuck in this cause I have only a little experience with javascript.\n\nThe bot is supposed to read two values on a message, those values are a string and a number. The bot will simply nickname you the string and that number.\n\nexample: User says: john123 40 bot: renaming the user as \" John123 | 40 \"\n\nThe nicknaming command and such are the easy part, the hard one for me is how should I tell the bot \"take the string, put it left of the \"|\", take the number, put it right of the \"|\" \". I mean the bot can't even read them. Here is my try:\n\n```\nvar name = message.content.includes(String)\nvar number = message.content.includes(\"1\"|| \"2\"|| \"3\"|| \"4\"|| \"5\"|| \"6\"|| \"7\"|| \"8\"|| \"9\"|| \"10\"|| \"11\"|| \"12\"|| \"13\"|| \"14\"|| \"15\"|| \"16\"|| \"17\"|| \"18\"|| \"19\"|| \"20\"|| \"21\"|| \"22\"|| \"23\"|| \"24\"|| \"25\"|| \"26\"|| \"27\"|| \"28\"|| \"29\"|| \"30\"|| \"31\"|| \"32\"|| \"33\"|| \"34\"|| \"35\"|| \"36\"|| \"37\"|| \"38\"|| \"39\"|| \"40\")\n\nfunction theNaming (name, number){\nmessage.member.setNickname('name'|' number')\n.then(console.log)\n.catch(console.error);\n}\n```\n\n(the level is supposed to not go higher than 40 so, I thought it may work inside the include)",
    "undefined kafka components for Go kafka\n\nI was trying to install one of my go files. But I bumped into this error\n```\nC:\\mygoproject>go install kafkapublisher.go\n\n\\#command-line-arguments\n.\\kafkapublisher.go:8:65: undefined: kafka.Message\n\n.\\kafkapublisher.go:10:19: undefined: kafka.NewProducer\n\n.\\kafkapublisher.go:10:38: undefined: kafka.ConfigMap\n\n.\\kafkapublisher.go:17:31: undefined: kafka.Event\n\n.\\kafkapublisher.go:19:26: undefined: kafka.Message\n```\n\nOn my kafkapublisher.go file, I already imported the kafka dependency:\n```\n    import (\n        \"github.com/confluentinc/confluent-kafka-go/kafka\"\n        \"log\"\n    )\n```\n\neven on my `go.mod` file\n```\n    module mymodule\n    \n    go 1.12\n    \n    require (\n        github.com/aws/aws-lambda-go v1.15.0\n        github.com/confluentinc/confluent-kafka-go v1.3.0\n    )\n```",
    "Python requests module with multithread\n\nCurrently, I am developing the astrophotometric software for multiple telescopes. For this, I constructed a mother computer connected with multiple telescopes and these telescopes can be controlled by HTTP protocol. For synchronized operation, I am trying to control these multiple telescopes simultaneously with multithreading.\nHowever, when I retrieve image data (110MB for each, ~1.2GB for total) from multiple telescopes (10 telescopes), the data transfer speed is much slower than I expected. For seamless operation, we have 10G connection with the mother computer, and 1G connection with 10 telescopes. I expected ~9Gbps data transfer speed when 10 telescopes transfer the data simultaneously, but only 1.5Gbps achieved.\n\nFor simple test, I extracted the part of the code and check the time consumption.\n```\nimport requests\nimport time\nfrom astropy.time import Time\ndef request_imagearray(cam):\n    client_trans_id = 1\n    client_id = 1\n    attribute = 'imagearray'\n\n    url = f\"{cam.device.base_url}/{attribute}\"\n    hdrs = {'accept' : 'application/imagebytes'}\n    # Make Host: header safe for IPv6\n    if(cam.device.address.startswith('[') and cam.device.address.startswith('[::1]')):\n        hdrs['Host'] = f'{cam.device.address.split(\"%\")[0]}]'\n    pdata = {\n            \"ClientTransactionID\": f\"{client_trans_id}\",\n            \"ClientID\": f\"{client_id}\" \n            }         \n\n    print('START:',Time.now(), cam.device.address)\n    start = time.time()\n    response = requests.request(\"GET\",\"%s/%s\" % (cam.device.base_url, attribute), params=pdata, headers=hdrs, verify = False)\n\n    print('consumed time:', time.time() - start, cam.device.address)\n# %%\n\nunitnumlist = [1,2,3,5,6,7,8,9,10,11]\ncamlist = []\nfor unitnum in unitnumlist:\n    #camlist.append(mainCamera(unitnum))\n    Thread(target = request_imagearray, kwargs = dict(cam = mainCamera(unitnum))).start()\n#%% \n```\n\nand the output is\n```\nSTART: 2024-04-15 07:49:59.067946 10.0.106.6:11111\nSTART: 2024-04-15 07:49:59.382973 10.0.106.7:11112\nSTART: 2024-04-15 07:49:59.541495 10.0.106.8:11113\nSTART: 2024-04-15 07:49:59.647055 10.0.106.10:11111\nSTART: 2024-04-15 07:49:59.788433 10.0.106.11:11111\nSTART: 2024-04-15 07:49:59.897876 10.0.106.12:11111\nSTART: 2024-04-15 07:50:00.009254 10.0.106.13:11111\nSTART: 2024-04-15 07:50:00.157893 10.0.106.14:11111\nSTART: 2024-04-15 07:50:00.347704 10.0.106.16:11111\nSTART: 2024-04-15 07:50:00.544626 10.0.106.9:11111\nconsumed time: 5.96204686164856 10.0.106.6:11111\nconsumed time: 7.304373502731323 10.0.106.7:11112\nconsumed time: 7.58618688583374 10.0.106.8:11113\nconsumed time: 7.617574453353882 10.0.106.10:11111\nconsumed time: 7.678117990493774 10.0.106.11:11111\nconsumed time: 7.76300311088562 10.0.106.12:11111\nconsumed time: 7.636215925216675 10.0.106.14:11111\nconsumed time: 7.785021066665649 10.0.106.13:11111\nconsumed time: 7.338518857955933 10.0.106.9:11111\nconsumed time: 11.309057235717773 10.0.106.16:11111\n```\n\nThe comsumed time is much longer than I expected. I expected ~3sec for all data transferred. It seems that multithreads starts to request \"request.get\" at the same time, but all the data is not transferred at the same time.",
    "writing code to determine how many pages will be printed based on the string of p\n\nI am programming a printer like program in python and the question write a function \"count_pages(p) that returns how many pages will be printed based on the string p\n\nI tried doing the count_pages function to return how many pages. the arguments and return value are\n\n\"5-7, 2\" 4\n\n\"12-18, 20-20\" 8\n\n\"18-12, 20-20, 5-6\"\n\nI ran into the error of:\n```\nTraceback (most recent call last):\n  File \"C:/Users/19013/Desktop/1900/printer_party.py\", line 19, in <module>\n    print(count_pages('5-7, 2'))  # Expected output: 4\n  File \"C:/Users/19013/Desktop/1900/printer_party.py\", line 11, in count_pages\n    start, end = map(int, r.split('-'))\nValueError: not enough values to unpack (expected 2, got 1)\n```\n\n```\ndef count_pages(p):\n    # Split the input string by commas\n    ranges = p.split(', ')\n    \n    # Initialize the total page count\n    total_pages = 0\n    \n    # Iterate through each range\n    for r in ranges:\n        # Split the range by hyphen\n        start, end = map(int, r.split('-'))\n        \n        # Add the number of pages in this range to the total\n        total_pages += end - start + 1\n    \n    return total_pages\n\n# Example usage\nprint(count_pages('5-7, 2'))  # Expected output: 4\nprint(count_pages('12-18, 20-20'))  # Expected output: 8\nprint(count_pages('18-12, 20-20, 5-6'))  # Expected output: 10\n```",
    "Pydantic - How to subclass a builtin type\n\nI'm trying to make a subclass of timedelta that expects to receive milliseconds instead of seconds, but it's not currently working.\n\nAm I going against the grain? Is there a \"right\" way to achieve this with Pydantic? Or do I somehow need to tell Pydantic that `MillisecondTimedelta` is just a `timedelta`..\n\n```\nfrom datetime import timedelta\n\nfrom pydantic import BaseModel\n\n\nclass MillisecondTimedelta(timedelta):\n    @classmethod\n    def __get_validators__(cls):\n        # timedelta expects seconds\n        yield lambda v: v / 1000\n        yield cls\n\n\nclass MyModel(BaseModel):\n    td: MillisecondTimedelta\n\ndata = {\n    \"td\": 7598040,\n}\n\nprint(MyModel(**data))\n```\n\nResults in:\n```\nTraceback (most recent call last):\n  File \"main.py\", line 14, in <module>\n    class MyModel(BaseModel):\n  File \"pydantic/main.py\", line 262, in pydantic.main.ModelMetaclass.__new__\n  File \"pydantic/fields.py\", line 315, in pydantic.fields.ModelField.infer\n  File \"pydantic/fields.py\", line 284, in pydantic.fields.ModelField.__init__\n  File \"pydantic/fields.py\", line 362, in pydantic.fields.ModelField.prepare\n  File \"pydantic/fields.py\", line 541, in pydantic.fields.ModelField.populate_validators\n  File \"pydantic/class_validators.py\", line 255, in pydantic.class_validators.prep_validators\n  File \"pydantic/class_validators.py\", line 238, in pydantic.class_validators.make_generic_validator\n  File \"/usr/lib/python3.8/inspect.py\", line 3105, in signature\n    return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n  File \"/usr/lib/python3.8/inspect.py\", line 2854, in from_callable\n    return _signature_from_callable(obj, sigcls=cls,\n  File \"/usr/lib/python3.8/inspect.py\", line 2384, in _signature_from_callable\n    raise ValueError(\nValueError: no signature found for builtin type <class '__main__.MillisecondTimedelta'>\n```",
    "Loading external javascript file in index.html of React App\n\nI have this React app in which I load my external javascript file inside the tag as below index.html:\n```\n....\n<script type=\"text/javascript\" src=\"../src/assets/externalJavascript.js\"></script>\n</head>\n```\n\nInside externalJavascript.js, I have this below:\n```\nlet queryParams = window.location.search.substring(1);\n\nconsole.log(\"Query: \", queryParams)\n\nwindow.loadFunc = function loadFunc() {\n            console.log(\"Script Loaded!\");\n          };\n```\n\nI access this loadFunc() inside my desired component using window.loadFunc()\n\nAll this is not working but if I make the js file inline in the index.html, it's working! Like this below:\n```\n<script>\n      (function () {\n          let queryParams = window.location.search.substring(1);\n\n          console.log(\"Query: \", queryParams);\n\n          window.loadFunc = function loadFunc() {\n            console.log(\"Script Loaded!\");\n          };\n      })()\n    </script>\n```\n\nWhen my app loads, I get the query in console log and also I can access the loadFunc() only when it is inline script.\n\nPlease help me to solve this.\n\nThank you!",
    "DAX RLS Function using LOOKUPVALUE Parsing but not working\n\nI have a table that I'm trying to implement RLS on using a secondary table with a structure below:\n\nEmployeeTable\n```\nEmployeeID        EmployeeEmail\n1        1234@email.com\n2        4567@email.com\n```\n\nFilterTable\n```\nEmployeeID        ManagerHierarchy\n1        3&4&5\n2        6&7&4&5\n```\n\nThe ManagerHierarchy column is a string that shows all managers of an employee concatenated together and separated by \"&\".\n\nThe goal of the RLS is to create a filter that allows any manager to view the report and have their data only display employeeIDs wherein their own ID exists within the ManagerHierarchy column and thus only showing their subordinates.\n\nI have the below DAX expression applied on EmployeeTable that I thought would work and parses in the expression builder, but it is giving me errors:\n```\n[EmplID]=\nLOOKUPVALUE(\nFilterTable[EmployeeID], FilterTable[ManagerHIERARCHY],\n\nLOOKUPVALUE( //This is to return the viewer's own employeeID to be crossed over into the FilterTable\n[EmployeeID], [EmployeeEmail], USERPRINCIPALNAME())\n)\n```\n\nThe Report it gives is as follows:\n\nAn error was encoutnered during the evaluation of the row level security defined on EmployeeTable. Function 'LOOKUPVALUE' does not support values of type Text with values of type integer. Consider using the VALUE or FORMAT function to convert one of the values.\n\nI've tried re-shuffling my DAX expression with to convert it as such, but I haven't been able to make it work as intended.",
    "Consume InputIterator with C++ ranges\n\nWith an input iterator, I can consume different sub-ranges out of it, e.g.\n```\nvoid test(std::input_iterator auto it) {\n  while (*it < 1) ++it; // drop_while\n  int n = *it++; // take(1)\n  int sum = 0; while (n-- > 0) sum += (1 + *it++); // fold_left(take(n) | transform)\n  int prd = 1; while (int x = *it++ / 2) prd *= x; // fold_left(transform | take_while)\n  std::cout << sum << ' ' << prd << '\\n';\n}\n\nint main() {\n    test(std::begin({0, 0, 0, 3, 400, 30, 2, 4, 6, 0}));\n}\n```\n\nIs there a way to do the same with `std::ranges`/`std::views`?",
    "Storing Binary String in DynamoDb\n\nI am trying to store a binary string in DynamoDB using Java. However, the builder is converting the bytes somehow. My original string is a zipped string. If I pass:\n\nH4sIAAAAAAAAA7LJKMnNsePlsslITUyxsynJLMlJtTMxMFXwyy9RcMzJyS9PTbHRhwjb6IMVARUn5adUKiSlJ+fn5BfZKpVnZJakKoHEk1PzSlKL7GwyDDHNAIrZ6EMVgOwDKoPy8tIz8yr0DfUMDfVMkZXog6wBM6COBAAAAP//AwBuTqCXrQAAAA==\n\nThe value in the database is converted to: SDRzSUFBQUFBQUFBQTdMSktNbk5zZVBsc3NsSVRVeXhzeW5KTE1sSnRUTXhNRlh3eXk5UmNNekp5UzlQVGJIUmh3amI2SU1WQVJVbjVhZFVLaVNsSitmbjVCZlpLcFZuWkpha0tvSEVrMVB6U2xLTDdHd3lEREhOQUlyWjZFTVZnT3dES29QeTh0SXo4eXIwRGZVTURmVk1rWlhvZzZ3Qk02Q09CQUFBQVAvL0F3QnVUcUNYclFBQUFBPT0=\n```\nObject responseMap = mMap.get(\"Response\");\nLinkedHashMap<String, String> responseMapped = (LinkedHashMap<String, String>)responseMap;\n\nString status = statusMapped.get(\"N\");\nString response = responseMapped.get(\"B\");\n\nSdkBytes bytes = SdkBytes.fromUtf8String(response);\n\nhistoryValueMap.put(\"Status\", AttributeValue.builder().n(status).build());\nhistoryValueMap.put(\"Response\", AttributeValue.builder().b(bytes).build());\n\nhistoryMap.put(historyKey, AttributeValue.builder().m(historyValueMap).build());\n```\n\nI also tried to convert the byte array to a base64 but that didn't work either.\n```\nString status = statusMapped.get(\"N\");\nbyte[] response = responseMapped.get(\"B\").getBytes();\n\nbyte[] base64Response = Base64.getEncoder().encode(response);\nSdkBytes responseAsSdk = SdkBytes.fromByteArray(base64Response);\n\nhistoryValueMap.put(\"Status\", AttributeValue.builder().n(status).build());\nhistoryValueMap.put(\"Response\", AttributeValue.builder().b(responseAsSdk).build());\n```",
    "How can I pass a variable from CSV file to Oracle SQL query fetch in Python?\n\nI have the following piece of code where I read a csv file and connect to the database. then I want to pass two columns from CSV file as variable to my query and eventually convert the result to a pd database.\n\nI have tried different ways of binding and converted columns to list but I was unsuccessful. with this piece of code I get the following Error:\n```\nDatabaseError: DPY-4010: a bind variable replacement value  \nfor placeholder \":HOUR\" was not provided\n```\n\nor I get below error when I add this part to execute():\n```\nres = connection.cursor().execute(\"SELECT HOUR,UNITSCHEDULEID,VERSIONID,MINRUNTIME FROM \n int_Stg.UnitScheduleOfferHourly WHERE  Hour in :1 AND UnitScheduleId in :2\", hour, unitid)\n```\n```\nTypeError: Cursor.execute() takes from 2 to 3 positional arguments but 4 were given\n```\n\nthe following is the code I execute:\n```\nimport pandas as pd\nimport numpy as np\n\ndf = pd.read_csv(r\"csv.csv\") \n\ndf=df.dropna()\n\nunitid=df['UNITSCHEDULEID'].unique()\nhour=df['GMT_DATETIME'].unique()\n\nimport os, oracledb, csv, pyodbc\nTNS_Admin = os.environ.get('TNS_Admin', r'\\\\corp.xxx\\oracle')\noracledb.defaults.config_dir = TNS_Admin\npw = input(f'Enter password: ')\nconnection = oracledb.connect(user='xxxxx', password= pw, dsn=\"World\")\n\nres = connection.cursor().execute(\"SELECT HOUR,UNITSCHEDULEID,VERSIONID,MINRUNTIME FROM \n int_Stg.UnitScheduleOfferHourly WHERE  Hour in :Hour AND UnitScheduleId in :unitid\").fetchall()\nprint(res)\n\nconnection.close()\n```",
    "How to save a xml structure using python tree.write(file_name)?\n\nI wanted to add Element with Subelements to my xml file using Python. But after changing file the Element and Subelement looks like a line, not like a xml-tree.\n\nI do this:\n```\ntree = ET.parse('existing_file.xml')\nroot = tree.getroot()\nnew_object = ET.SubElement(root, 'object')\nname = ET.SubElement(new_object, 'name')\nname.text = 'car'\ncolor = ET.SubElement(new_object, 'color')\ncolor.text = 'Red'\nnew_tree = ET.ElementTree(root)\nnew_tree.write('new_file.xml')\n```\n\nBut after this I've got file without structure like this:\n```\n<object><name>car</name><color>red</color></object>\n```\n\nBut i need this:\n```\n<object>\n     <name>car</name>\n     <color>red</color>\n</object>\n```\n\nwhat do I do wrong?",
    "How can I build a firestore query for Android with whereGreaterthan() filters for two different fields?\n\nI need to filter the list of my documents which I am fetching from `firestore` in my android `app`. this is the query.\n```\n  query = FirebaseFirestore.getInstance()\n            .collection(\"students\")\n            .whereLessThan(\"mAge\",25)\n            .whereGreaterThan(\"mAge\",20)\n            .whereGreaterThan(\"mGrades\",20);\n```\n\nbut, I get an error in the log:\n```\njava.lang.RuntimeException: Unable to start activity ComponentInfo{dsardy.in.acchebacche/dsardy.in.acchebacche.MainActivity}: java.lang.IllegalArgumentException: All where filters other than whereEqualTo() must be on the same field. But you have filters on 'mAge' and 'mGrades'\n```\n\nCan this be achieved? a filter with two or more fields greater than some values is an important and general query, `firestore` must have something to tackle this.",
    "How to make MudSelect show text of selected option instead of value?\n\n```\n<MudSelect MultiSelection=\"true\" @bind-SelectedValues=\"ViewModel.Model.GlobalSalaryAccessUserIds\">\n                @foreach (var salaryAccessUser in ViewModel.GlobalSalaryAccessUsers)\n                {\n                    <MudSelectItem Value=\"@salaryAccessUser.Id\">@GenerateSalaryAccessUserDisplayString(salaryAccessUser)</MudSelectItem>\n                }\n            </MudSelect>\n```\n\nNow instead of string which generates in `GenerateSalaryAccessUserDisplayString` it shows a value of the option, which is id, when I've selected a few of them . How can I change it to show the generated string?",
    "How to record audio and video corss platform with electron\n\nSo i was making a electron project that records your screen and your desktop or selected app's audio with desktopCapture. I got the screen record, and at one point even got the mic to work, but at no point, no matter what i tried, i couldn't record desktop audio nor any app's audio. After some research i found that you cannot record any desktop nor app's audio with chromium on linux.\n\nSo what could be the solution or some other ways to try to record desktop audio. Maybe there is some way to record desktop audio with a different library and then combine the video with audio somehow.\n\nAny suggestions would be appreciated.\n\nCode for the screen recorder itself:\n```\nvideoSelectBtn.onclick = getVideoSources;\n\nasync function getVideoSources() {\n  const inputSources = await desktopCapturer.getSources({\n    types: [\"window\", \"screen\", \"audio\"],\n  });\n\n  inputSources.forEach((source) => {\n    if (source.name === \"Screen 1\") {\n      selectSource(source);\n    } else {\n      console.log(source);\n    }\n  });\n}\n\nasync function selectSource(source) {\n  videoSelectBtn.innerText = source.name;\n\n  const constraints = {\n    audio: {\n      mandatory: {\n        chromeMediaSource: \"desktop\",\n      },\n    },\n    video: {\n      mandatory: {\n        chromeMediaSource: \"desktop\",\n      },\n    },\n  };\n\n  const stream = await navigator.mediaDevices.getUserMedia(constraints);\n```",
    "My api request in my asyncThunk function in slice file doesn't work when I put a dispatch method before that\n\nI have this asyncThunk action and everything was fine until I put a `dispatch` call before sending request. As a result every code after this `dispatch` call doesn't work anymore. 'first' goes in log but 'second' no. I don't know why this dispatch blocks next codes in my asyncThunk function.\n\nMy slice file:\n```\nexport const postLoginData = createAsyncThunk(\n  'login/postLoginData',\n  async (allData) => {\n    const { dispatch, params } = allData;\n\n    let loginResponse = '';\n\n    console.log('first')\n    dispatch(setStatus({type: 'loading', payload: 'wait'}))\n    console.log('second')\n\n    await postRequest('/o/token/coach', params)\n      .then(response => {\n        loginResponse = response.data\n        const data = response.data;\n        if (data.access_token) {\n          dispatch(loginSuccess(data))\n          localStorage.setItem('Authentication', JSON.stringify(data));\n        }\n      })\n      .catch(err => {\n        if (err.response.status === 400) {\n          loginResponse = { error: '400 Error' }\n        }\n      })\n    dispatch(setStatus({ type: 'loading', payload: false }))\n    console.log(loginResponse)\n    return loginResponse\n  }\n)\n```",
    "Gorm preload doesn't follow the Join conditions\n\nSo I'm trying to make a complex queries with a lot of joins and nested structs. I need to load the structs but Preload is not following related Joins with their conditions and its keep doing its own queries.\n\nHow can I make this work?\n\nMy joins are pretty complicated and I don't want to do the same join twice.\n```\ntype Assetinfo struct {\n    Uid           string\n    MapPolicyApps []MapPolicyApps `gorm:\"foreignKey:app_id;references:uid;AssociationForeignKey:pol_id\"`\n}\ntype MapPolicyApps struct {\n    Id           int\n    PolID        string       `gorm:\"column_name:pol_id;foreignKey:Uid\"`\n    PolicyPolicy PolicyPolicy `gorm:\"foreignKey:Uid;references:PolID;AssociationForeignKey:uid\"`\n    AppType      string    // This can be application or category\n    AppId        string    `gorm:\"column_name:app_id;foreignKey:Uid\"`  // this can be app id or application id (bad naming i know)\n    Asset        Assetinfo `gorm:\"foreignKey:AppId;references:Uid\"`\n    CreatedAt    string\n}\n\ntype PolicyPolicy struct {\n    Uid               string `gorm:\"primaryKey\"`\n    IsEnabled         bool\n    MapPolicyProfiles []MapPolicyProfiles `gorm:\"foreignKey:PolID;references:Uid\"`\n}\n\nvar assets []*Assetinfo \n\nerr := Db.Table(\"application_application apps\").\n    Select(\"Distinct apps.*, apps.avatar as icon, profile_asset.address as ip, apps.is_health_check as is_need_request\").\n    Joins(\"LEFT JOIN map_policy_identities ON map_policy_identities.assign_type = 'user' AND map_policy_identities.assign_id = ?\", userid).\n    Joins(\"LEFT JOIN policy_policy ON map_policy_identities.pol_id = policy_policy.uid AND policy_policy.is_enabled = true\").\n    Joins(\"LEFT JOIN map_policy_apps ON map_policy_identities.pol_id = map_policy_apps.pol_id\").\n    Joins(\"LEFT JOIN map_category_apps ON map_category_apps.category_id = map_policy_apps.app_id\").\n    Joins(\"LEFT JOIN map_app_assets ON apps.uid = map_app_assets.app_id\").\n    Joins(\"LEFT JOIN profile_asset ON profile_asset.uid = map_app_assets.asset_id\").\n    Where(\"map_policy_apps.app_id = apps.uid OR apps.uid = map_category_apps.app_id\").\n    Where(\"apps.is_enabled = true AND apps.is_visibled = true\").\n    Preload(\"MapPolicyApps.PolicyPolicy.MapPolicyProfiles.ProfileAddr\").\n    Preload(\"MapPolicyApps.PolicyPolicy.MapPolicyProfiles.ProfileTimerange\").\n    Preload(\"MapPolicyApps.PolicyPolicy.MapPolicyProfiles.ProfilePosturecheck\").\n    Find(&assets).Error\n```\n\nAnd Gorm can't load the structs without Preload, So if it's possible to load all nested structs with joins and without Preload, I would appreciate to know how.",
    "Copy and delete files from SFTP folder\n\nI have to pick (remove) the files with file mask `FileName_A_*` and `FileName_B_*` from SFTP location and place them in an sharedrive.\n\nI tried using WinSCP. I have created an `HourlyFile.txt` file with below code and placed it under `C:\\Program Files (x86)\\WinSCP`. Another batch file `HourlyFile.bat` to execute the script from HourlyFile.txt\n\nHourlyFile.txt:\n```\noption batch abort\noption confirm off\nopen sftp..........\nget -filemask=\"FileName_A_*\" /outbound/test/* \\\\sharedrive\nget -filemask=\"FileName_B_*\" /outbound/test/* \\\\sharedrive\ndel /outbound/test/FileName_A_*\ndel /outbound/test/FileName_B_* \nexit\n```\n\nHourlyFile.bat:\n```\nwinscp.com /script=HourlyFile.txt\npause\n```\n\nI tried with below options to delete the file but got the error message \"Unknown command\". Also the above code is copying subfolder from `/outbound/test/` , which it should not.\nCommands tried:\n```\ndel /outbound/test/FileName_A_*\n-del /outbound/test/FileName_A_*\ndelete /outbound/test/FileName_A_*\ndelete /outbound/test/FileName_A_20190604_090002\ndelete /outbound/test/FileName_A_20190604_090002.csv\n```",
    "useState set method not changing my state - react native\n\nI'm working on a part of an application dealing with a deck of cards. For however many cards a player is supposed to have, I am looping through a deck of cards held in a state, randomly picking a card, assigning it to that player and then removing it from the deck. This all works correctly but when the deck is empty (.length === 0), I want to invoke a shuffle() method that will set the deck equal to the discard pile which is also an array held in a useState. The discard pile is also working as expected but for some reason when trying to set the currentDeck to the discard pile, using setCurrentDeck(discardPile), the currentDeck array remains empty. (I've also tried setCurrentDeck([...discardPile])).\n\nI know this mostly likely has to do with how React handles batching hook calls, and that the value of currentDeck is not what I think it is because of the other setCurrentDeck() calls, but I'm still not able to figure out what's going on.\n\nMy code (simplified):\n```\nconst [currentDeck, setCurrentDeck] = useState(deck) // 'deck' is a hard coded array of cards\nconst [discardPile, setDiscardPile] = useState([])\nconst [faceUpCard, setFaceUpCard] = useState(null)\n\n  useEffect(() => {\n    if (currentDeck.length === 0) {\n      const temp = discardPile;\n      setCurrentDeck([...temp]);\n      setDiscardPile([]);\n    }\n  }, [currentDeck]);\n\n  function deal() {\n    if (readyToDeal) {\n      for (let i = 0; i < round + 2; i++) {\n        for (let j = 0; j < players.length; j++) {\n          const rand = Math.floor(Math.random() * currentDeck.length);\n          // players are assigned cards\n          currentDeck.splice(rand, 1); // card that was assigned is removed from deck\n          setCurrentDeck([...currentDeck]);\n        }\n      }\n      const rand = Math.floor(Math.random() * currentDeck.length);\n      setFaceUpCard(currentDeck[rand]);\n      currentDeck.splice(rand, 1);\n      setCurrentDeck([...currentDeck]);\n      setReadyToDeal(false);\n    }\n  }\n```\n\nI have also tried setting currentDeck with a shuffle method like this:\n```\n  function shuffle() {\n    const temp = discardPile;\n    setCurrentDeck([ ...temp]);\n    setDiscardPile([]);\n  }\n\n  function deal() {\n    if (readyToDeal) {\n      for (let i = 0; i < round + 2; i++) {\n        for (let j = 0; j < players.length; j++) {\n          if (currentDeck.length === 0) {\n            shuffle();\n          }\n          const rand = Math.floor(Math.random() * currentDeck.length);\n          // players are assigned cards\n          currentDeck.splice(rand, 1); // card that was assigned is removed from deck\n          setCurrentDeck([...currentDeck]);\n        }\n      }\n      const rand = Math.floor(Math.random() * currentDeck.length);\n      setFaceUpCard(currentDeck[rand]);\n      currentDeck.splice(rand, 1);\n      setCurrentDeck([...currentDeck]);\n      setReadyToDeal(false);\n    }\n  }\n```\n\nbut still no luck. Any help or advice would be appreciated. Thank you!",
    "eslint configuration not read in my project\n\nI have setup a project using nx and I have the following config\n\n.eslintrc.base.json\n```\n{\n  \"root\": true,\n  \"ignorePatterns\": [\"**/*\"],\n  \"plugins\": [\"@nx\", \"unused-imports\", \"import\"],\n  \"overrides\": [\n    {\n      \"files\": [\"*.ts\", \"*.tsx\", \"*.js\", \"*.jsx\"],\n      \"rules\": {\n\n        \"import/no-duplicates\": \"warn\"\n      }\n    },\n    {\n      \"files\": [\"*.ts\", \"*.tsx\"],\n      \"extends\": [\"plugin:@nx/typescript\"],\n      \"rules\": {}\n    },\n    {\n      \"files\": [\"*.js\", \"*.jsx\"],\n      \"extends\": [\"plugin:@nx/javascript\"],\n      \"rules\": {}\n    },\n    {\n      \"files\": [\"*.spec.ts\", \"*.spec.tsx\", \"*.spec.js\", \"*.spec.jsx\"],\n      \"env\": {\n        \"jest\": true\n      },\n      \"rules\": {}\n    }\n  ]\n}\n```\n\nthen .eslintrc.json\n```\n{\n  \"ignorePatterns\": [\"!**/*\"],\n  \"overrides\": [\n    {\n      \"files\": [\"*.ts\", \"*.tsx\"],\n      \"rules\": {}\n    },\n    {\n      \"files\": [\"*.js\", \"*.jsx\"],\n      \"rules\": {}\n    },\n    {\n      \"files\": [\"*.spec.ts\", \"*.spec.tsx\", \"*.spec.js\", \"*.spec.jsx\"],\n      \"env\": {\n        \"jest\": true\n      },\n      \"rules\": {}\n    }\n  ],\n  \"extends\": [\"./.eslintrc.base.json\"]\n}\n```\n\nthen I pureposely did this in my app\n```\nimport { Response } from 'express';\nimport { Request } from 'express';\n```\n\nThis should trigger a warning, but nothing appear in vscode.\n\nmy setting is currently\n```\n{\n  \"editor.formatOnSave\": true,\n  \"editor.defaultFormatter\": \"esbenp.prettier-vscode\",\n  \"editor.codeActionsOnSave\": {\n    \"source.fixAll.eslint\": \"always\",\n    \"source.fixAll.stylelint\": \"always\"\n  },\n  \"typescript.tsdk\": \"node_modules/typescript/lib\"\n}\n```\n\nWhat am I missing ? I tried other rules they also dont work.",
    "Using discrete colors for map fill in mapboxgl instead of default interpoolated colors?\n\nThe way I've typically seen mapboxgl fill properties work on choropleth maps is something like this:\n```\nmap.on('load', function () {\n      map.addSource('bb', { type: 'geojson', data: data, generateId: true});\n      map.addLayer({\n        'id': 'berlin',\n        'type': 'fill',\n        'source': 'bb',\n        'paint': {\n          'fill-color': {\n          'property': some_numeric_val,\n          'stops': [[4, '#feebe2'], [8, '#fbb4b9'], [12, '#f768a1'], [16, '#c51b8a'], [20, '#7a0177']]\n          },\n        'fill-opacity': .65\n          }\n      });\n      map.addLayer({\n        'id': 'berlin-stroke',\n        'type': 'line',\n        'source': 'bb',\n        'paint': {\n          'line-color': '#000',\n          'line-width': [\n          'case',\n            ['boolean', ['feature-state', 'hover'], false],\n            2,\n            .5\n          ]\n        }\n      });\n    });\n```\n\ni.e. the colors are created based on a property that the user selects. However, it seems like mapboxgl's default behavior is to interpolate colors. For example, if one of my geographic units has a value is somewhere between the breakpoints, mapboxgl will interpolate the color, resulting in a gradient of colors.\n\nIs there a way to make the colors distinct (non-interpolated)? i.e. if value is 4 or less, the color is #feebe2, if the value is 8 or less, the color is '#fbb4b9', for a total of 5 discrete colors in the example I have here.\n\nI have not been able to find an answer to this anywhere. Thanks.",
    "How can I list exported values from all of my CloudFormation templates?\n\nI'm exporting the name of the stack and the URL of my Lambda function in my CloudFormation template.\n```\nOutputs:\n  LambdaInvokeURL:\n    Value: !GetAtt Myurl.FunctionUrl \n    Export:\n      Name: !Sub \"${AWS::StackName}\"\n```\n\nI have 8 to 10 stacks exporting similar outputs.\n\nHow can I list all exported names & values across all stacks in my AWS account?\n\nShould I write a new CloudFormation template or a Lambda function to list them?",
    "How to upload folders to react with special characters in the name\n\nI have a problem with my javascript uploading: I am using this code:\n```\nconst handleParameterSearchUpload = async (event) => {\n    const files = event.target.files;\n    console.log(files);\n    const folders = {};\n\n    for (let i = 0; i < files.length; i++) {\n      const file = files[i];\n      const filePath = file.webkitRelativePath;\n      const pathParts = filePath.split('/');\n\n      // If the file is in a subfolder, add the file to the folder's list\n      if (pathParts.length > 2) {\n        const folderName = encodeURIComponent(pathParts[1]);\n        if (!folders[folderName]) {\n          folders[folderName] = [];\n        }\n        folders[folderName].push(file);\n      }\n    }\n    console.log(folders.length);\n    // Call processFiles for each folder\n    for (const folderName in folders) {\n      const folderFiles = folders[folderName];\n      await processFiles(folderFiles, true);\n      console.log(\"Processed\", folderName);\n    }\n    parameterSearchInputRef.current.value = \"\";\n  };\n```\n\nto process the files in a folder.\n\nThis code is used here:\n```\n<input\n  type=\"file\"\n  webkitdirectory=\"true\"\n  style={{ display: 'none' }\n  ref={parameterSearchInputRef} \n  onChange={handleParameterSearchUpload} \n/>\n```\n\nNow in this folder there are files and subfolders which are not empty. Unfortunately I have a problem. When I upload the folder the files are uploaded, but not the subfolders. The code is not the problem, because when I rename the folder it works fine, but with this folder name which I upload:\n```\n20240118-165159[param.defaults]CombinationParamSearch{sheets.l4_cortex_inh.params.cell.params.v_thresh_[-57.5, -58],sheets.l4_cortex_exc.AfferentConnection.base_weight_[0.0013, 0.0016, 0.0018]}\n```\n\nit doesn't work.\n\nUnfortunately I will always upload these types of folders to the webpage, how to resolve the issue? The subfolders have the following name:\n```\nSelfSustainedPushPull_ParameterSearch_____base_weight_0.0013_v_thresh_-57.5 SelfSustainedPushPull_ParameterSearch_____base_weight_0.0013_v_thresh_-58\n```\n\nand so on\n\nUnfortunately the base problem is that the subfolders seem like are not getting uploaded, because if I log the console, the subfolders nor the contents inside them are not getting logged. I really don't know how to resolve this issue, without using packages like `fs` or `path`. Any ideas? Unfortunately I can't just ask the users to rename the folders, because these folder names are generated from another software.",
    "Substituting number of simulations (\"n\") in rnorm() using a list of predetermined values (in R)\n\nI'm using rnorm() but instead of substituting the number of simulations \"n\" with just one variable, I would like to do this multiple times with \"n\" having predetermined values from a series of values. (In my project, I will need to do this 11,600+ times as there are 11,600+ predetermined values which I need to use rnorm() for - but the mean and standard deviation will be constant. To simplify everything for this discussion, I will just assume I have 10 predetermined values representing the number of simulations I would like to do.)\n\nunit.cost <- rnorm(728, mean = 8403.86, sd = 1000)\n\nInstead of just using \"728\" as the number of simulations (\"n\"), I would want to automatically substitute iteratively using these series of values: 728, 628, 100, 150, 99, 867, 934, 11, 67, 753. (I also want to use these series of values in the same order - and not just randomly using them, as the expected output should be a data frame listing the unit.cost using the predetermined values of n. Note that both mean and sd are constant.)\n\nWhat I've tried:\n\nI am very much beginner in R, so upon search, it looks like for loop would be an ideal candidate to do this setup?"
]